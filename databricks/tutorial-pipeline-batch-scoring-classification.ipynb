{"cells":[{"cell_type":"markdown","source":["Copyright (c) Microsoft Corporation. All rights reserved.  \nLicensed under the MIT License."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"91950559-237a-4fb2-aecd-3dedb287e244"}}},{"cell_type":"markdown","source":["![Impressions](https://PixelServer20190423114238.azurewebsites.net/api/impressions/MachineLearningNotebooks/tutorials/machine-learning-pipelines-advanced/tutorial-pipeline-batch-scoring-classification.png)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1065aba1-0089-4c4b-aadd-f6e0e701f10d"}}},{"cell_type":"markdown","source":["# Use Azure Machine Learning Pipelines for batch prediction\nIn this tutorial, you use Azure Machine Learning service pipelines to run a batch scoring image classification job. The example job uses the pre-trained [Inception-V3](https://arxiv.org/abs/1512.00567) CNN (convolutional neural network) Tensorflow model to classify unlabeled images. Machine learning pipelines optimize your workflow with speed, portability, and reuse so you can focus on your expertise, machine learning, rather than on infrastructure and automation. After building and publishing a pipeline, you can configure a REST endpoint to enable triggering the pipeline from any HTTP library on any platform.\n\nIn this tutorial, you learn the following tasks:\n\n> * Configure workspace and download sample data\n> * Create data objects to fetch and output data\n> * Download, prepare, and register the model to your workspace\n> * Provision compute targets and create a scoring script\n> * Use ParallelRunStep to do batch scoring\n> * Build, run, and publish a pipeline\n> * Enable a REST endpoint for the pipeline\n\nIf you don't have an Azure subscription, create a free account before you begin. Try the [free or paid version of Azure Machine Learning service](https://aka.ms/AMLFree) today."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5af6705b-a355-4a6d-bcd2-154341dfba6f"}}},{"cell_type":"markdown","source":["## Prerequisites\n\n* Complete the [setup tutorial](https://docs.microsoft.com/azure/machine-learning/service/tutorial-1st-experiment-sdk-setup) if you don't already have an Azure Machine Learning service workspace or notebook virtual machine.\n* After you complete the setup tutorial, open the **tutorials/tutorial-pipeline-batch-scoring-classification.ipynb** notebook using the same notebook server.\n\nThis tutorial is also available on [GitHub](https://github.com/Azure/MachineLearningNotebooks/tree/master/tutorials) if you wish to run it in your own [local environment](how-to-configure-environment.md#local). Run `pip install azureml-sdk[notebooks] azureml-pipeline-core azureml-pipeline-steps pandas requests` to get the required packages."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1c79ceed-a23e-40c5-9e20-09c82937310c"}}},{"cell_type":"markdown","source":["### Install required libraries\n\nRun the following cell to install required libraries."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f1f9e3dd-f236-4252-bcce-5d25ef7b63b6"}}},{"cell_type":"code","source":["pip install azureml-sdk[notebooks] azureml-pipeline-core azureml-pipeline-steps pandas requests"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8c1f10ed-2213-44dd-8af2-01d9cbe45e5b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Python interpreter will be restarted.\nCollecting azureml-sdk[notebooks]\n  Downloading azureml_sdk-1.17.0-py3-none-any.whl (4.4 kB)\nCollecting azureml-pipeline-core\n  Downloading azureml_pipeline_core-1.17.0-py3-none-any.whl (303 kB)\nCollecting azureml-pipeline-steps\n  Downloading azureml_pipeline_steps-1.17.0-py3-none-any.whl (60 kB)\nRequirement already satisfied: pandas in /databricks/python3/lib/python3.7/site-packages (1.0.1)\nRequirement already satisfied: requests in /databricks/python3/lib/python3.7/site-packages (2.22.0)\nCollecting azureml-train~=1.17.0\n  Downloading azureml_train-1.17.0-py3-none-any.whl (3.3 kB)\nCollecting azureml-pipeline~=1.17.0\n  Downloading azureml_pipeline-1.17.0-py3-none-any.whl (3.7 kB)\nCollecting azureml-dataset-runtime[fuse]~=1.17.0\n  Downloading azureml_dataset_runtime-1.17.0-py3-none-any.whl (3.4 kB)\nCollecting azureml-train-automl-client~=1.17.0\n  Downloading azureml_train_automl_client-1.17.0-py3-none-any.whl (108 kB)\nCollecting azureml-core~=1.17.0\n  Downloading azureml_core-1.17.0-py3-none-any.whl (2.1 MB)\nCollecting azureml-widgets~=1.17.0; extra == &#34;notebooks&#34;\n  Downloading azureml_widgets-1.17.0-py3-none-any.whl (14.1 MB)\nCollecting azureml-contrib-notebook~=1.17.0; extra == &#34;notebooks&#34;\n  Downloading azureml_contrib_notebook-1.17.0-py3-none-any.whl (29 kB)\nCollecting azureml-train-core~=1.17.0\n  Downloading azureml_train_core-1.17.0-py3-none-any.whl (8.6 MB)\nRequirement already satisfied: python-dateutil&gt;=2.6.1 in /databricks/python3/lib/python3.7/site-packages (from pandas) (2.8.1)\nRequirement already satisfied: numpy&gt;=1.13.3 in /databricks/python3/lib/python3.7/site-packages (from pandas) (1.18.1)\nRequirement already satisfied: pytz&gt;=2017.2 in /databricks/python3/lib/python3.7/site-packages (from pandas) (2019.3)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /databricks/python3/lib/python3.7/site-packages (from requests) (2020.6.20)\nRequirement already satisfied: idna&lt;2.9,&gt;=2.5 in /databricks/python3/lib/python3.7/site-packages (from requests) (2.8)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,&lt;1.26,&gt;=1.21.1 in /databricks/python3/lib/python3.7/site-packages (from requests) (1.25.8)\nRequirement already satisfied: chardet&lt;3.1.0,&gt;=3.0.2 in /usr/lib/python3/dist-packages (from requests) (3.0.4)\nRequirement already satisfied: pyarrow&lt;2.0.0,&gt;=0.17.0 in /databricks/python3/lib/python3.7/site-packages (from azureml-dataset-runtime[fuse]~=1.17.0-&gt;azureml-sdk[notebooks]) (1.0.1)\nCollecting azureml-dataprep&lt;2.5.0a,&gt;=2.4.0a\n  Downloading azureml_dataprep-2.4.2-py3-none-any.whl (28.2 MB)\nCollecting fusepy&lt;4.0.0,&gt;=3.0.1; extra == &#34;fuse&#34;\n  Downloading fusepy-3.0.1.tar.gz (11 kB)\nCollecting azureml-telemetry~=1.17.0\n  Downloading azureml_telemetry-1.17.0-py3-none-any.whl (30 kB)\nCollecting azureml-automl-core~=1.17.0\n  Downloading azureml_automl_core-1.17.0-py3-none-any.whl (181 kB)\nCollecting azure-mgmt-resource&lt;15.0.0,&gt;=1.2.1\n  Downloading azure_mgmt_resource-10.3.0-py2.py3-none-any.whl (1.0 MB)\nCollecting jsonpickle\n  Downloading jsonpickle-1.4.1-py2.py3-none-any.whl (36 kB)\nCollecting azure-mgmt-authorization&lt;1.0.0,&gt;=0.40.0\n  Downloading azure_mgmt_authorization-0.61.0-py2.py3-none-any.whl (94 kB)\nCollecting backports.tempfile\n  Downloading backports.tempfile-1.0-py2.py3-none-any.whl (4.4 kB)\nCollecting contextlib2\n  Downloading contextlib2-0.6.0.post1-py2.py3-none-any.whl (9.8 kB)\nCollecting azure-mgmt-containerregistry&gt;=2.0.0\n  Downloading azure_mgmt_containerregistry-2.8.0-py2.py3-none-any.whl (718 kB)\nCollecting azure-graphrbac&lt;1.0.0,&gt;=0.40.0\n  Downloading azure_graphrbac-0.61.1-py2.py3-none-any.whl (141 kB)\nCollecting PyJWT\n  Downloading PyJWT-1.7.1-py2.py3-none-any.whl (18 kB)\nCollecting ndg-httpsclient\n  Downloading ndg_httpsclient-0.5.1-py3-none-any.whl (34 kB)\nCollecting azure-mgmt-storage&lt;16.0.0,&gt;=1.5.0\n  Downloading azure_mgmt_storage-11.2.0-py2.py3-none-any.whl (547 kB)\nCollecting ruamel.yaml&gt;=0.15.35\n  Downloading ruamel.yaml-0.16.12-py2.py3-none-any.whl (111 kB)\nCollecting azure-mgmt-keyvault&lt;7.0.0,&gt;=0.40.0\n  Downloading azure_mgmt_keyvault-2.2.0-py2.py3-none-any.whl (89 kB)\nCollecting docker\n  Downloading docker-4.3.1-py2.py3-none-any.whl (145 kB)\nRequirement already satisfied: jmespath in /databricks/python3/lib/python3.7/site-packages (from azureml-core~=1.17.0-&gt;azureml-sdk[notebooks]) (0.10.0)\nRequirement already satisfied: pyopenssl&lt;20.0.0 in /databricks/python3/lib/python3.7/site-packages (from azureml-core~=1.17.0-&gt;azureml-sdk[notebooks]) (19.1.0)\nCollecting SecretStorage\n  Downloading SecretStorage-3.1.2-py3-none-any.whl (14 kB)\nCollecting pathspec\n  Downloading pathspec-0.8.0-py2.py3-none-any.whl (28 kB)\nCollecting adal&gt;=1.2.0\n  Downloading adal-1.2.5-py2.py3-none-any.whl (55 kB)\nCollecting msrestazure&gt;=0.4.33\n  Downloading msrestazure-0.6.4-py2.py3-none-any.whl (40 kB)\nCollecting msrest&gt;=0.5.1\n  Downloading msrest-0.6.19-py2.py3-none-any.whl (84 kB)\nRequirement already satisfied: cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.* in /databricks/python3/lib/python3.7/site-packages (from azureml-core~=1.17.0-&gt;azureml-sdk[notebooks]) (2.8)\nCollecting azure-common&gt;=1.1.12\n  Downloading azure_common-1.1.25-py2.py3-none-any.whl (12 kB)\nCollecting ipywidgets&gt;=7.0.0\n  Downloading ipywidgets-7.5.1-py2.py3-none-any.whl (121 kB)\nRequirement already satisfied: ipykernel in /databricks/python3/lib/python3.7/site-packages (from azureml-contrib-notebook~=1.17.0; extra == &#34;notebooks&#34;-&gt;azureml-sdk[notebooks]) (5.1.4)\nCollecting nbconvert&lt;6\n  Downloading nbconvert-5.6.1-py2.py3-none-any.whl (455 kB)\nCollecting papermill&lt;2\n  Downloading papermill-1.2.1-py2.py3-none-any.whl (31 kB)\nRequirement already satisfied: ipython in /databricks/python3/lib/python3.7/site-packages (from azureml-contrib-notebook~=1.17.0; extra == &#34;notebooks&#34;-&gt;azureml-sdk[notebooks]) (7.12.0)\nCollecting azureml-train-restclients-hyperdrive~=1.17.0\n  Downloading azureml_train_restclients_hyperdrive-1.17.0-py3-none-any.whl (18 kB)\nRequirement already satisfied: six&gt;=1.5 in /databricks/python3/lib/python3.7/site-packages (from python-dateutil&gt;=2.6.1-&gt;pandas) (1.14.0)\nCollecting azure-identity&lt;2.0.0,&gt;=1.2.0\n  Downloading azure_identity-1.4.1-py2.py3-none-any.whl (86 kB)\nCollecting azureml-dataprep-native&lt;25.0.0,&gt;=24.0.0\n  Downloading azureml_dataprep_native-24.0.0-cp37-cp37m-manylinux1_x86_64.whl (1.3 MB)\nCollecting azureml-dataprep-rslex&lt;1.3.0a,&gt;=1.2.0dev0\n  Downloading azureml_dataprep_rslex-1.2.2-cp37-cp37m-manylinux2010_x86_64.whl (7.9 MB)\nCollecting cloudpickle&lt;2.0.0,&gt;=1.1.0\n  Downloading cloudpickle-1.6.0-py3-none-any.whl (23 kB)\nCollecting dotnetcore2&lt;3.0.0,&gt;=2.1.14\n  Downloading dotnetcore2-2.1.17-py3-none-manylinux1_x86_64.whl (28.7 MB)\nCollecting applicationinsights\n  Downloading applicationinsights-0.11.9-py2.py3-none-any.whl (58 kB)\nCollecting importlib-metadata\n  Downloading importlib_metadata-2.0.0-py2.py3-none-any.whl (31 kB)\nCollecting backports.weakref\n  Downloading backports.weakref-1.0.post1-py2.py3-none-any.whl (5.2 kB)\nCollecting pyasn1&gt;=0.1.1\n  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\nCollecting ruamel.yaml.clib&gt;=0.1.2; platform_python_implementation == &#34;CPython&#34; and python_version &lt; &#34;3.9&#34;\n  Downloading ruamel.yaml.clib-0.2.2-cp37-cp37m-manylinux1_x86_64.whl (547 kB)\nCollecting websocket-client&gt;=0.32.0\n  Downloading websocket_client-0.57.0-py2.py3-none-any.whl (200 kB)\nCollecting jeepney&gt;=0.4.2\n  Downloading jeepney-0.4.3-py3-none-any.whl (21 kB)\nCollecting isodate&gt;=0.6.0\n  Downloading isodate-0.6.0-py2.py3-none-any.whl (45 kB)\nCollecting requests-oauthlib&gt;=0.5.0\n  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\nRequirement already satisfied: cffi!=1.11.3,&gt;=1.8 in /databricks/python3/lib/python3.7/site-packages (from cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*-&gt;azureml-core~=1.17.0-&gt;azureml-sdk[notebooks]) (1.14.0)\nCollecting nbformat&gt;=4.2.0\n  Downloading nbformat-5.0.8-py3-none-any.whl (172 kB)\nRequirement already satisfied: traitlets&gt;=4.3.1 in /databricks/python3/lib/python3.7/site-packages (from ipywidgets&gt;=7.0.0-&gt;azureml-widgets~=1.17.0; extra == &#34;notebooks&#34;-&gt;azureml-sdk[notebooks]) (4.3.3)\nCollecting widgetsnbextension~=3.5.0\n  Downloading widgetsnbextension-3.5.1-py2.py3-none-any.whl (2.2 MB)\nRequirement already satisfied: tornado&gt;=4.2 in /databricks/python3/lib/python3.7/site-packages (from ipykernel-&gt;azureml-contrib-notebook~=1.17.0; extra == &#34;notebooks&#34;-&gt;azureml-sdk[notebooks]) (6.0.3)\nRequirement already satisfied: jupyter-client in /databricks/python3/lib/python3.7/site-packages (from ipykernel-&gt;azureml-contrib-notebook~=1.17.0; extra == &#34;notebooks&#34;-&gt;azureml-sdk[notebooks]) (5.3.4)\nCollecting pandocfilters&gt;=1.4.1\n  Downloading pandocfilters-1.4.3.tar.gz (16 kB)\nCollecting testpath\n  Downloading testpath-0.4.4-py2.py3-none-any.whl (163 kB)\nRequirement already satisfied: entrypoints&gt;=0.2.2 in /databricks/python3/lib/python3.7/site-packages (from nbconvert&lt;6-&gt;azureml-contrib-notebook~=1.17.0; extra == &#34;notebooks&#34;-&gt;azureml-sdk[notebooks]) (0.3)\nCollecting mistune&lt;2,&gt;=0.8.1\n  Downloading mistune-0.8.4-py2.py3-none-any.whl (16 kB)\nRequirement already satisfied: jupyter-core in /databricks/python3/lib/python3.7/site-packages (from nbconvert&lt;6-&gt;azureml-contrib-notebook~=1.17.0; extra == &#34;notebooks&#34;-&gt;azureml-sdk[notebooks]) (4.6.1)\nRequirement already satisfied: pygments in /databricks/python3/lib/python3.7/site-packages (from nbconvert&lt;6-&gt;azureml-contrib-notebook~=1.17.0; extra == &#34;notebooks&#34;-&gt;azureml-sdk[notebooks]) (2.5.2)\nCollecting bleach\n  Downloading bleach-3.2.1-py2.py3-none-any.whl (145 kB)\nCollecting defusedxml\n  Downloading defusedxml-0.6.0-py2.py3-none-any.whl (23 kB)\nCollecting jinja2&gt;=2.4\n  Downloading Jinja2-2.11.2-py2.py3-none-any.whl (125 kB)\nCollecting tenacity\n  Downloading tenacity-6.2.0-py2.py3-none-any.whl (24 kB)\nCollecting click\n  Downloading click-7.1.2-py2.py3-none-any.whl (82 kB)\nCollecting tqdm&gt;=4.32.2\n  Downloading tqdm-4.51.0-py2.py3-none-any.whl (70 kB)\nCollecting pyyaml\n  Downloading PyYAML-5.3.1.tar.gz (269 kB)\nCollecting future\n  Downloading future-0.18.2.tar.gz (829 kB)\nCollecting ansiwrap\n  Downloading ansiwrap-0.8.4-py2.py3-none-any.whl (8.5 kB)\nRequirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,&lt;3.1.0,&gt;=2.0.0 in /databricks/python3/lib/python3.7/site-packages (from ipython-&gt;azureml-contrib-notebook~=1.17.0; extra == &#34;notebooks&#34;-&gt;azureml-sdk[notebooks]) (3.0.3)\nRequirement already satisfied: pexpect; sys_platform != &#34;win32&#34; in /databricks/python3/lib/python3.7/site-packages (from ipython-&gt;azureml-contrib-notebook~=1.17.0; extra == &#34;notebooks&#34;-&gt;azureml-sdk[notebooks]) (4.8.0)\nRequirement already satisfied: decorator in /databricks/python3/lib/python3.7/site-packages (from ipython-&gt;azureml-contrib-notebook~=1.17.0; extra == &#34;notebooks&#34;-&gt;azureml-sdk[notebooks]) (4.4.1)\nRequirement already satisfied: jedi&gt;=0.10 in /databricks/python3/lib/python3.7/site-packages (from ipython-&gt;azureml-contrib-notebook~=1.17.0; extra == &#34;notebooks&#34;-&gt;azureml-sdk[notebooks]) (0.14.1)\nRequirement already satisfied: setuptools&gt;=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython-&gt;azureml-contrib-notebook~=1.17.0; extra == &#34;notebooks&#34;-&gt;azureml-sdk[notebooks]) (45.2.0)\nRequirement already satisfied: pickleshare in /databricks/python3/lib/python3.7/site-packages (from ipython-&gt;azureml-contrib-notebook~=1.17.0; extra == &#34;notebooks&#34;-&gt;azureml-sdk[notebooks]) (0.7.5)\nRequirement already satisfied: backcall in /databricks/python3/lib/python3.7/site-packages (from ipython-&gt;azureml-contrib-notebook~=1.17.0; extra == &#34;notebooks&#34;-&gt;azureml-sdk[notebooks]) (0.1.0)\nCollecting msal&lt;2.0.0,&gt;=1.3.0\n  Downloading msal-1.6.0-py2.py3-none-any.whl (50 kB)\nCollecting msal-extensions~=0.2.2\n  Downloading msal_extensions-0.2.2-py2.py3-none-any.whl (15 kB)\nCollecting azure-core&lt;2.0.0,&gt;=1.0.0\n  Downloading azure_core-1.8.2-py2.py3-none-any.whl (122 kB)\nCollecting distro&gt;=1.2.0\n  Downloading distro-1.5.0-py2.py3-none-any.whl (18 kB)\nCollecting zipp&gt;=0.5\n  Downloading zipp-3.4.0-py3-none-any.whl (5.2 kB)\nCollecting oauthlib&gt;=3.0.0\n  Downloading oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\nRequirement already satisfied: pycparser in /databricks/python3/lib/python3.7/site-packages (from cffi!=1.11.3,&gt;=1.8-&gt;cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*-&gt;azureml-core~=1.17.0-&gt;azureml-sdk[notebooks]) (2.19)\nCollecting jsonschema!=2.5.0,&gt;=2.4\n  Downloading jsonschema-3.2.0-py2.py3-none-any.whl (56 kB)\nRequirement already satisfied: ipython-genutils in /databricks/python3/lib/python3.7/site-packages (from nbformat&gt;=4.2.0-&gt;ipywidgets&gt;=7.0.0-&gt;azureml-widgets~=1.17.0; extra == &#34;notebooks&#34;-&gt;azureml-sdk[notebooks]) (0.2.0)\nCollecting notebook&gt;=4.4.1\n  Downloading notebook-6.1.4-py3-none-any.whl (9.5 MB)\nRequirement already satisfied: pyzmq&gt;=13 in /databricks/python3/lib/python3.7/site-packages (from jupyter-client-&gt;ipykernel-&gt;azureml-contrib-notebook~=1.17.0; extra == &#34;notebooks&#34;-&gt;azureml-sdk[notebooks]) (18.1.1)\nCollecting webencodings\n  Downloading webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\nCollecting packaging\n  Downloading packaging-20.4-py2.py3-none-any.whl (37 kB)\nCollecting MarkupSafe&gt;=0.23\n  Downloading MarkupSafe-1.1.1-cp37-cp37m-manylinux1_x86_64.whl (27 kB)\nCollecting textwrap3&gt;=0.9.2\n  Downloading textwrap3-0.9.2-py2.py3-none-any.whl (12 kB)\nRequirement already satisfied: wcwidth in /databricks/python3/lib/python3.7/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,&lt;3.1.0,&gt;=2.0.0-&gt;ipython-&gt;azureml-contrib-notebook~=1.17.0; extra == &#34;notebooks&#34;-&gt;azureml-sdk[notebooks]) (0.1.8)\nRequirement already satisfied: ptyprocess&gt;=0.5 in /databricks/python3/lib/python3.7/site-packages (from pexpect; sys_platform != &#34;win32&#34;-&gt;ipython-&gt;azureml-contrib-notebook~=1.17.0; extra == &#34;notebooks&#34;-&gt;azureml-sdk[notebooks]) (0.6.0)\nRequirement already satisfied: parso&gt;=0.5.0 in /databricks/python3/lib/python3.7/site-packages (from jedi&gt;=0.10-&gt;ipython-&gt;azureml-contrib-notebook~=1.17.0; extra == &#34;notebooks&#34;-&gt;azureml-sdk[notebooks]) (0.5.2)\nCollecting portalocker~=1.0; platform_system != &#34;Windows&#34;\n  Downloading portalocker-1.7.1-py2.py3-none-any.whl (10 kB)\nCollecting pyrsistent&gt;=0.14.0\n  Downloading pyrsistent-0.17.3.tar.gz (106 kB)\nCollecting attrs&gt;=17.4.0\n  Downloading attrs-20.2.0-py2.py3-none-any.whl (48 kB)\nCollecting prometheus-client\n  Downloading prometheus_client-0.8.0-py2.py3-none-any.whl (53 kB)\nCollecting argon2-cffi\n  Downloading argon2_cffi-20.1.0-cp35-abi3-manylinux1_x86_64.whl (97 kB)\nCollecting Send2Trash\n  Downloading Send2Trash-1.5.0-py3-none-any.whl (12 kB)\nCollecting terminado&gt;=0.8.3\n  Downloading terminado-0.9.1-py3-none-any.whl (13 kB)\nRequirement already satisfied: pyparsing&gt;=2.0.2 in /databricks/python3/lib/python3.7/site-packages (from packaging-&gt;bleach-&gt;nbconvert&lt;6-&gt;azureml-contrib-notebook~=1.17.0; extra == &#34;notebooks&#34;-&gt;azureml-sdk[notebooks]) (2.4.6)\nBuilding wheels for collected packages: fusepy, pandocfilters, pyyaml, future, pyrsistent\n  Building wheel for fusepy (setup.py): started\n  Building wheel for fusepy (setup.py): finished with status &#39;done&#39;\n  Created wheel for fusepy: filename=fusepy-3.0.1-py3-none-any.whl size=10503 sha256=87da0f8442ddb6179583cb5d5f94bea942a46cc985ac79c8fe1572a866bae706\n  Stored in directory: /root/.cache/pip/wheels/89/07/84/a5ebfafeefbbc56ceda9d6935a54a8be7a4eccf4ea7e9bf980\n  Building wheel for pandocfilters (setup.py): started\n  Building wheel for pandocfilters (setup.py): finished with status &#39;done&#39;\n  Created wheel for pandocfilters: filename=pandocfilters-1.4.3-py3-none-any.whl size=7991 sha256=0805ad10776ebdcf6dc639d068a4f383ea75b03e6b1e00946c3f265579fb7259\n  Stored in directory: /root/.cache/pip/wheels/42/81/34/545dc2fbf0e9137811e901108d37fc04650e81d48f97078000\n  Building wheel for pyyaml (setup.py): started\n  Building wheel for pyyaml (setup.py): finished with status &#39;done&#39;\n  Created wheel for pyyaml: filename=PyYAML-5.3.1-cp37-cp37m-linux_x86_64.whl size=44619 sha256=60ea44b3876b59a0a28e65f920969be1ef0940c1fe86b6c7b8ac482e3d999811\n  Stored in directory: /root/.cache/pip/wheels/5e/03/1e/e1e954795d6f35dfc7b637fe2277bff021303bd9570ecea653\n  Building wheel for future (setup.py): started\n  Building wheel for future (setup.py): finished with status &#39;done&#39;\n  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491058 sha256=a8e081c521177e61346dc6068c8f57cd9c6b91b4b0b7418de38e67c8a5ff9799\n  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n  Building wheel for pyrsistent (setup.py): started\n  Building wheel for pyrsistent (setup.py): finished with status &#39;done&#39;\n  Created wheel for pyrsistent: filename=pyrsistent-0.17.3-cp37-cp37m-linux_x86_64.whl size=98033 sha256=1efcf8b51cad95c4eed9ca0e9877d588137dc6cd869408ad49b4837f4cec84da\n  Stored in directory: /root/.cache/pip/wheels/a5/52/bf/71258a1d7b3c8cbe1ee53f9314c6f65f20385481eaee573cc5\nSuccessfully built fusepy pandocfilters pyyaml future pyrsistent\nInstalling collected packages: applicationinsights, azure-common, isodate, oauthlib, requests-oauthlib, msrest, PyJWT, adal, msrestazure, azure-mgmt-resource, zipp, importlib-metadata, jsonpickle, azure-mgmt-authorization, backports.weakref, backports.tempfile, contextlib2, azure-mgmt-containerregistry, azure-graphrbac, pyasn1, ndg-httpsclient, azure-mgmt-storage, ruamel.yaml.clib, ruamel.yaml, azure-mgmt-keyvault, websocket-client, docker, jeepney, SecretStorage, pathspec, azureml-core, azureml-telemetry, azureml-train-restclients-hyperdrive, azureml-train-core, azureml-train, azureml-pipeline-core, msal, portalocker, msal-extensions, azure-core, azure-identity, azureml-dataprep-native, azureml-dataprep-rslex, cloudpickle, distro, dotnetcore2, azureml-dataprep, fusepy, azureml-dataset-runtime, azureml-automl-core, azureml-train-automl-client, azureml-pipeline-steps, azureml-pipeline, pyrsistent, attrs, jsonschema, nbformat, MarkupSafe, jinja2, prometheus-client, pandocfilters, testpath, mistune, webencodings, packaging, bleach, defusedxml, nbconvert, argon2-cffi, Send2Trash, terminado, notebook, widgetsnbextension, ipywidgets, azureml-widgets, tenacity, click, tqdm, pyyaml, future, textwrap3, ansiwrap, papermill, azureml-contrib-notebook, azureml-sdk\nSuccessfully installed MarkupSafe-1.1.1 PyJWT-1.7.1 SecretStorage-3.1.2 Send2Trash-1.5.0 adal-1.2.5 ansiwrap-0.8.4 applicationinsights-0.11.9 argon2-cffi-20.1.0 attrs-20.2.0 azure-common-1.1.25 azure-core-1.8.2 azure-graphrbac-0.61.1 azure-identity-1.4.1 azure-mgmt-authorization-0.61.0 azure-mgmt-containerregistry-2.8.0 azure-mgmt-keyvault-2.2.0 azure-mgmt-resource-10.3.0 azure-mgmt-storage-11.2.0 azureml-automl-core-1.17.0 azureml-contrib-notebook-1.17.0 azureml-core-1.17.0 azureml-dataprep-2.4.2 azureml-dataprep-native-24.0.0 azureml-dataprep-rslex-1.2.2 azureml-dataset-runtime-1.17.0 azureml-pipeline-1.17.0 azureml-pipeline-core-1.17.0 azureml-pipeline-steps-1.17.0 azureml-sdk-1.17.0 azureml-telemetry-1.17.0 azureml-train-1.17.0 azureml-train-automl-client-1.17.0 azureml-train-core-1.17.0 azureml-train-restclients-hyperdrive-1.17.0 azureml-widgets-1.17.0 backports.tempfile-1.0 backports.weakref-1.0.post1 bleach-3.2.1 click-7.1.2 cloudpickle-1.6.0 contextlib2-0.6.0.post1 defusedxml-0.6.0 distro-1.5.0 docker-4.3.1 dotnetcore2-2.1.17 fusepy-3.0.1 future-0.18.2 importlib-metadata-2.0.0 ipywidgets-7.5.1 isodate-0.6.0 jeepney-0.4.3 jinja2-2.11.2 jsonpickle-1.4.1 jsonschema-3.2.0 mistune-0.8.4 msal-1.6.0 msal-extensions-0.2.2 msrest-0.6.19 msrestazure-0.6.4 nbconvert-5.6.1 nbformat-5.0.8 ndg-httpsclient-0.5.1 notebook-6.1.4 oauthlib-3.1.0 packaging-20.4 pandocfilters-1.4.3 papermill-1.2.1 pathspec-0.8.0 portalocker-1.7.1 prometheus-client-0.8.0 pyasn1-0.4.8 pyrsistent-0.17.3 pyyaml-5.3.1 requests-oauthlib-1.3.0 ruamel.yaml-0.16.12 ruamel.yaml.clib-0.2.2 tenacity-6.2.0 terminado-0.9.1 testpath-0.4.4 textwrap3-0.9.2 tqdm-4.51.0 webencodings-0.5.1 websocket-client-0.57.0 widgetsnbextension-3.5.1 zipp-3.4.0\nPython interpreter will be restarted.\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Python interpreter will be restarted.\nCollecting azureml-sdk[notebooks]\n  Downloading azureml_sdk-1.17.0-py3-none-any.whl (4.4 kB)\nCollecting azureml-pipeline-core\n  Downloading azureml_pipeline_core-1.17.0-py3-none-any.whl (303 kB)\nCollecting azureml-pipeline-steps\n  Downloading azureml_pipeline_steps-1.17.0-py3-none-any.whl (60 kB)\nRequirement already satisfied: pandas in /databricks/python3/lib/python3.7/site-packages (1.0.1)\nRequirement already satisfied: requests in /databricks/python3/lib/python3.7/site-packages (2.22.0)\nCollecting azureml-train~=1.17.0\n  Downloading azureml_train-1.17.0-py3-none-any.whl (3.3 kB)\nCollecting azureml-pipeline~=1.17.0\n  Downloading azureml_pipeline-1.17.0-py3-none-any.whl (3.7 kB)\nCollecting azureml-dataset-runtime[fuse]~=1.17.0\n  Downloading azureml_dataset_runtime-1.17.0-py3-none-any.whl (3.4 kB)\nCollecting azureml-train-automl-client~=1.17.0\n  Downloading azureml_train_automl_client-1.17.0-py3-none-any.whl (108 kB)\nCollecting azureml-core~=1.17.0\n  Downloading azureml_core-1.17.0-py3-none-any.whl (2.1 MB)\nCollecting azureml-widgets~=1.17.0; extra == &#34;notebooks&#34;\n  Downloading azureml_widgets-1.17.0-py3-none-any.whl (14.1 MB)\nCollecting azureml-contrib-notebook~=1.17.0; extra == &#34;notebooks&#34;\n  Downloading azureml_contrib_notebook-1.17.0-py3-none-any.whl (29 kB)\nCollecting azureml-train-core~=1.17.0\n  Downloading azureml_train_core-1.17.0-py3-none-any.whl (8.6 MB)\nRequirement already satisfied: python-dateutil&gt;=2.6.1 in /databricks/python3/lib/python3.7/site-packages (from pandas) (2.8.1)\nRequirement already satisfied: numpy&gt;=1.13.3 in /databricks/python3/lib/python3.7/site-packages (from pandas) (1.18.1)\nRequirement already satisfied: pytz&gt;=2017.2 in /databricks/python3/lib/python3.7/site-packages (from pandas) (2019.3)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /databricks/python3/lib/python3.7/site-packages (from requests) (2020.6.20)\nRequirement already satisfied: idna&lt;2.9,&gt;=2.5 in /databricks/python3/lib/python3.7/site-packages (from requests) (2.8)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,&lt;1.26,&gt;=1.21.1 in /databricks/python3/lib/python3.7/site-packages (from requests) (1.25.8)\nRequirement already satisfied: chardet&lt;3.1.0,&gt;=3.0.2 in /usr/lib/python3/dist-packages (from requests) (3.0.4)\nRequirement already satisfied: pyarrow&lt;2.0.0,&gt;=0.17.0 in /databricks/python3/lib/python3.7/site-packages (from azureml-dataset-runtime[fuse]~=1.17.0-&gt;azureml-sdk[notebooks]) (1.0.1)\nCollecting azureml-dataprep&lt;2.5.0a,&gt;=2.4.0a\n  Downloading azureml_dataprep-2.4.2-py3-none-any.whl (28.2 MB)\nCollecting fusepy&lt;4.0.0,&gt;=3.0.1; extra == &#34;fuse&#34;\n  Downloading fusepy-3.0.1.tar.gz (11 kB)\nCollecting azureml-telemetry~=1.17.0\n  Downloading azureml_telemetry-1.17.0-py3-none-any.whl (30 kB)\nCollecting azureml-automl-core~=1.17.0\n  Downloading azureml_automl_core-1.17.0-py3-none-any.whl (181 kB)\nCollecting azure-mgmt-resource&lt;15.0.0,&gt;=1.2.1\n  Downloading azure_mgmt_resource-10.3.0-py2.py3-none-any.whl (1.0 MB)\nCollecting jsonpickle\n  Downloading jsonpickle-1.4.1-py2.py3-none-any.whl (36 kB)\nCollecting azure-mgmt-authorization&lt;1.0.0,&gt;=0.40.0\n  Downloading azure_mgmt_authorization-0.61.0-py2.py3-none-any.whl (94 kB)\nCollecting backports.tempfile\n  Downloading backports.tempfile-1.0-py2.py3-none-any.whl (4.4 kB)\nCollecting contextlib2\n  Downloading contextlib2-0.6.0.post1-py2.py3-none-any.whl (9.8 kB)\nCollecting azure-mgmt-containerregistry&gt;=2.0.0\n  Downloading azure_mgmt_containerregistry-2.8.0-py2.py3-none-any.whl (718 kB)\nCollecting azure-graphrbac&lt;1.0.0,&gt;=0.40.0\n  Downloading azure_graphrbac-0.61.1-py2.py3-none-any.whl (141 kB)\nCollecting PyJWT\n  Downloading PyJWT-1.7.1-py2.py3-none-any.whl (18 kB)\nCollecting ndg-httpsclient\n  Downloading ndg_httpsclient-0.5.1-py3-none-any.whl (34 kB)\nCollecting azure-mgmt-storage&lt;16.0.0,&gt;=1.5.0\n  Downloading azure_mgmt_storage-11.2.0-py2.py3-none-any.whl (547 kB)\nCollecting ruamel.yaml&gt;=0.15.35\n  Downloading ruamel.yaml-0.16.12-py2.py3-none-any.whl (111 kB)\nCollecting azure-mgmt-keyvault&lt;7.0.0,&gt;=0.40.0\n  Downloading azure_mgmt_keyvault-2.2.0-py2.py3-none-any.whl (89 kB)\nCollecting docker\n  Downloading docker-4.3.1-py2.py3-none-any.whl (145 kB)\nRequirement already satisfied: jmespath in /databricks/python3/lib/python3.7/site-packages (from azureml-core~=1.17.0-&gt;azureml-sdk[notebooks]) (0.10.0)\nRequirement already satisfied: pyopenssl&lt;20.0.0 in /databricks/python3/lib/python3.7/site-packages (from azureml-core~=1.17.0-&gt;azureml-sdk[notebooks]) (19.1.0)\nCollecting SecretStorage\n  Downloading SecretStorage-3.1.2-py3-none-any.whl (14 kB)\nCollecting pathspec\n  Downloading pathspec-0.8.0-py2.py3-none-any.whl (28 kB)\nCollecting adal&gt;=1.2.0\n  Downloading adal-1.2.5-py2.py3-none-any.whl (55 kB)\nCollecting msrestazure&gt;=0.4.33\n  Downloading msrestazure-0.6.4-py2.py3-none-any.whl (40 kB)\nCollecting msrest&gt;=0.5.1\n  Downloading msrest-0.6.19-py2.py3-none-any.whl (84 kB)\nRequirement already satisfied: cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.* in /databricks/python3/lib/python3.7/site-packages (from azureml-core~=1.17.0-&gt;azureml-sdk[notebooks]) (2.8)\nCollecting azure-common&gt;=1.1.12\n  Downloading azure_common-1.1.25-py2.py3-none-any.whl (12 kB)\nCollecting ipywidgets&gt;=7.0.0\n  Downloading ipywidgets-7.5.1-py2.py3-none-any.whl (121 kB)\nRequirement already satisfied: ipykernel in /databricks/python3/lib/python3.7/site-packages (from azureml-contrib-notebook~=1.17.0; extra == &#34;notebooks&#34;-&gt;azureml-sdk[notebooks]) (5.1.4)\nCollecting nbconvert&lt;6\n  Downloading nbconvert-5.6.1-py2.py3-none-any.whl (455 kB)\nCollecting papermill&lt;2\n  Downloading papermill-1.2.1-py2.py3-none-any.whl (31 kB)\nRequirement already satisfied: ipython in /databricks/python3/lib/python3.7/site-packages (from azureml-contrib-notebook~=1.17.0; extra == &#34;notebooks&#34;-&gt;azureml-sdk[notebooks]) (7.12.0)\nCollecting azureml-train-restclients-hyperdrive~=1.17.0\n  Downloading azureml_train_restclients_hyperdrive-1.17.0-py3-none-any.whl (18 kB)\nRequirement already satisfied: six&gt;=1.5 in /databricks/python3/lib/python3.7/site-packages (from python-dateutil&gt;=2.6.1-&gt;pandas) (1.14.0)\nCollecting azure-identity&lt;2.0.0,&gt;=1.2.0\n  Downloading azure_identity-1.4.1-py2.py3-none-any.whl (86 kB)\nCollecting azureml-dataprep-native&lt;25.0.0,&gt;=24.0.0\n  Downloading azureml_dataprep_native-24.0.0-cp37-cp37m-manylinux1_x86_64.whl (1.3 MB)\nCollecting azureml-dataprep-rslex&lt;1.3.0a,&gt;=1.2.0dev0\n  Downloading azureml_dataprep_rslex-1.2.2-cp37-cp37m-manylinux2010_x86_64.whl (7.9 MB)\nCollecting cloudpickle&lt;2.0.0,&gt;=1.1.0\n  Downloading cloudpickle-1.6.0-py3-none-any.whl (23 kB)\nCollecting dotnetcore2&lt;3.0.0,&gt;=2.1.14\n  Downloading dotnetcore2-2.1.17-py3-none-manylinux1_x86_64.whl (28.7 MB)\nCollecting applicationinsights\n  Downloading applicationinsights-0.11.9-py2.py3-none-any.whl (58 kB)\nCollecting importlib-metadata\n  Downloading importlib_metadata-2.0.0-py2.py3-none-any.whl (31 kB)\nCollecting backports.weakref\n  Downloading backports.weakref-1.0.post1-py2.py3-none-any.whl (5.2 kB)\nCollecting pyasn1&gt;=0.1.1\n  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\nCollecting ruamel.yaml.clib&gt;=0.1.2; platform_python_implementation == &#34;CPython&#34; and python_version &lt; &#34;3.9&#34;\n  Downloading ruamel.yaml.clib-0.2.2-cp37-cp37m-manylinux1_x86_64.whl (547 kB)\nCollecting websocket-client&gt;=0.32.0\n  Downloading websocket_client-0.57.0-py2.py3-none-any.whl (200 kB)\nCollecting jeepney&gt;=0.4.2\n  Downloading jeepney-0.4.3-py3-none-any.whl (21 kB)\nCollecting isodate&gt;=0.6.0\n  Downloading isodate-0.6.0-py2.py3-none-any.whl (45 kB)\nCollecting requests-oauthlib&gt;=0.5.0\n  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\nRequirement already satisfied: cffi!=1.11.3,&gt;=1.8 in /databricks/python3/lib/python3.7/site-packages (from cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*-&gt;azureml-core~=1.17.0-&gt;azureml-sdk[notebooks]) (1.14.0)\nCollecting nbformat&gt;=4.2.0\n  Downloading nbformat-5.0.8-py3-none-any.whl (172 kB)\nRequirement already satisfied: traitlets&gt;=4.3.1 in /databricks/python3/lib/python3.7/site-packages (from ipywidgets&gt;=7.0.0-&gt;azureml-widgets~=1.17.0; extra == &#34;notebooks&#34;-&gt;azureml-sdk[notebooks]) (4.3.3)\nCollecting widgetsnbextension~=3.5.0\n  Downloading widgetsnbextension-3.5.1-py2.py3-none-any.whl (2.2 MB)\nRequirement already satisfied: tornado&gt;=4.2 in /databricks/python3/lib/python3.7/site-packages (from ipykernel-&gt;azureml-contrib-notebook~=1.17.0; extra == &#34;notebooks&#34;-&gt;azureml-sdk[notebooks]) (6.0.3)\nRequirement already satisfied: jupyter-client in /databricks/python3/lib/python3.7/site-packages (from ipykernel-&gt;azureml-contrib-notebook~=1.17.0; extra == &#34;notebooks&#34;-&gt;azureml-sdk[notebooks]) (5.3.4)\nCollecting pandocfilters&gt;=1.4.1\n  Downloading pandocfilters-1.4.3.tar.gz (16 kB)\nCollecting testpath\n  Downloading testpath-0.4.4-py2.py3-none-any.whl (163 kB)\nRequirement already satisfied: entrypoints&gt;=0.2.2 in /databricks/python3/lib/python3.7/site-packages (from nbconvert&lt;6-&gt;azureml-contrib-notebook~=1.17.0; extra == &#34;notebooks&#34;-&gt;azureml-sdk[notebooks]) (0.3)\nCollecting mistune&lt;2,&gt;=0.8.1\n  Downloading mistune-0.8.4-py2.py3-none-any.whl (16 kB)\nRequirement already satisfied: jupyter-core in /databricks/python3/lib/python3.7/site-packages (from nbconvert&lt;6-&gt;azureml-contrib-notebook~=1.17.0; extra == &#34;notebooks&#34;-&gt;azureml-sdk[notebooks]) (4.6.1)\nRequirement already satisfied: pygments in /databricks/python3/lib/python3.7/site-packages (from nbconvert&lt;6-&gt;azureml-contrib-notebook~=1.17.0; extra == &#34;notebooks&#34;-&gt;azureml-sdk[notebooks]) (2.5.2)\nCollecting bleach\n  Downloading bleach-3.2.1-py2.py3-none-any.whl (145 kB)\nCollecting defusedxml\n  Downloading defusedxml-0.6.0-py2.py3-none-any.whl (23 kB)\nCollecting jinja2&gt;=2.4\n  Downloading Jinja2-2.11.2-py2.py3-none-any.whl (125 kB)\nCollecting tenacity\n  Downloading tenacity-6.2.0-py2.py3-none-any.whl (24 kB)\nCollecting click\n  Downloading click-7.1.2-py2.py3-none-any.whl (82 kB)\nCollecting tqdm&gt;=4.32.2\n  Downloading tqdm-4.51.0-py2.py3-none-any.whl (70 kB)\nCollecting pyyaml\n  Downloading PyYAML-5.3.1.tar.gz (269 kB)\nCollecting future\n  Downloading future-0.18.2.tar.gz (829 kB)\nCollecting ansiwrap\n  Downloading ansiwrap-0.8.4-py2.py3-none-any.whl (8.5 kB)\nRequirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,&lt;3.1.0,&gt;=2.0.0 in /databricks/python3/lib/python3.7/site-packages (from ipython-&gt;azureml-contrib-notebook~=1.17.0; extra == &#34;notebooks&#34;-&gt;azureml-sdk[notebooks]) (3.0.3)\nRequirement already satisfied: pexpect; sys_platform != &#34;win32&#34; in /databricks/python3/lib/python3.7/site-packages (from ipython-&gt;azureml-contrib-notebook~=1.17.0; extra == &#34;notebooks&#34;-&gt;azureml-sdk[notebooks]) (4.8.0)\nRequirement already satisfied: decorator in /databricks/python3/lib/python3.7/site-packages (from ipython-&gt;azureml-contrib-notebook~=1.17.0; extra == &#34;notebooks&#34;-&gt;azureml-sdk[notebooks]) (4.4.1)\nRequirement already satisfied: jedi&gt;=0.10 in /databricks/python3/lib/python3.7/site-packages (from ipython-&gt;azureml-contrib-notebook~=1.17.0; extra == &#34;notebooks&#34;-&gt;azureml-sdk[notebooks]) (0.14.1)\nRequirement already satisfied: setuptools&gt;=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython-&gt;azureml-contrib-notebook~=1.17.0; extra == &#34;notebooks&#34;-&gt;azureml-sdk[notebooks]) (45.2.0)\nRequirement already satisfied: pickleshare in /databricks/python3/lib/python3.7/site-packages (from ipython-&gt;azureml-contrib-notebook~=1.17.0; extra == &#34;notebooks&#34;-&gt;azureml-sdk[notebooks]) (0.7.5)\nRequirement already satisfied: backcall in /databricks/python3/lib/python3.7/site-packages (from ipython-&gt;azureml-contrib-notebook~=1.17.0; extra == &#34;notebooks&#34;-&gt;azureml-sdk[notebooks]) (0.1.0)\nCollecting msal&lt;2.0.0,&gt;=1.3.0\n  Downloading msal-1.6.0-py2.py3-none-any.whl (50 kB)\nCollecting msal-extensions~=0.2.2\n  Downloading msal_extensions-0.2.2-py2.py3-none-any.whl (15 kB)\nCollecting azure-core&lt;2.0.0,&gt;=1.0.0\n  Downloading azure_core-1.8.2-py2.py3-none-any.whl (122 kB)\nCollecting distro&gt;=1.2.0\n  Downloading distro-1.5.0-py2.py3-none-any.whl (18 kB)\nCollecting zipp&gt;=0.5\n  Downloading zipp-3.4.0-py3-none-any.whl (5.2 kB)\nCollecting oauthlib&gt;=3.0.0\n  Downloading oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\nRequirement already satisfied: pycparser in /databricks/python3/lib/python3.7/site-packages (from cffi!=1.11.3,&gt;=1.8-&gt;cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*-&gt;azureml-core~=1.17.0-&gt;azureml-sdk[notebooks]) (2.19)\nCollecting jsonschema!=2.5.0,&gt;=2.4\n  Downloading jsonschema-3.2.0-py2.py3-none-any.whl (56 kB)\nRequirement already satisfied: ipython-genutils in /databricks/python3/lib/python3.7/site-packages (from nbformat&gt;=4.2.0-&gt;ipywidgets&gt;=7.0.0-&gt;azureml-widgets~=1.17.0; extra == &#34;notebooks&#34;-&gt;azureml-sdk[notebooks]) (0.2.0)\nCollecting notebook&gt;=4.4.1\n  Downloading notebook-6.1.4-py3-none-any.whl (9.5 MB)\nRequirement already satisfied: pyzmq&gt;=13 in /databricks/python3/lib/python3.7/site-packages (from jupyter-client-&gt;ipykernel-&gt;azureml-contrib-notebook~=1.17.0; extra == &#34;notebooks&#34;-&gt;azureml-sdk[notebooks]) (18.1.1)\nCollecting webencodings\n  Downloading webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\nCollecting packaging\n  Downloading packaging-20.4-py2.py3-none-any.whl (37 kB)\nCollecting MarkupSafe&gt;=0.23\n  Downloading MarkupSafe-1.1.1-cp37-cp37m-manylinux1_x86_64.whl (27 kB)\nCollecting textwrap3&gt;=0.9.2\n  Downloading textwrap3-0.9.2-py2.py3-none-any.whl (12 kB)\nRequirement already satisfied: wcwidth in /databricks/python3/lib/python3.7/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,&lt;3.1.0,&gt;=2.0.0-&gt;ipython-&gt;azureml-contrib-notebook~=1.17.0; extra == &#34;notebooks&#34;-&gt;azureml-sdk[notebooks]) (0.1.8)\nRequirement already satisfied: ptyprocess&gt;=0.5 in /databricks/python3/lib/python3.7/site-packages (from pexpect; sys_platform != &#34;win32&#34;-&gt;ipython-&gt;azureml-contrib-notebook~=1.17.0; extra == &#34;notebooks&#34;-&gt;azureml-sdk[notebooks]) (0.6.0)\nRequirement already satisfied: parso&gt;=0.5.0 in /databricks/python3/lib/python3.7/site-packages (from jedi&gt;=0.10-&gt;ipython-&gt;azureml-contrib-notebook~=1.17.0; extra == &#34;notebooks&#34;-&gt;azureml-sdk[notebooks]) (0.5.2)\nCollecting portalocker~=1.0; platform_system != &#34;Windows&#34;\n  Downloading portalocker-1.7.1-py2.py3-none-any.whl (10 kB)\nCollecting pyrsistent&gt;=0.14.0\n  Downloading pyrsistent-0.17.3.tar.gz (106 kB)\nCollecting attrs&gt;=17.4.0\n  Downloading attrs-20.2.0-py2.py3-none-any.whl (48 kB)\nCollecting prometheus-client\n  Downloading prometheus_client-0.8.0-py2.py3-none-any.whl (53 kB)\nCollecting argon2-cffi\n  Downloading argon2_cffi-20.1.0-cp35-abi3-manylinux1_x86_64.whl (97 kB)\nCollecting Send2Trash\n  Downloading Send2Trash-1.5.0-py3-none-any.whl (12 kB)\nCollecting terminado&gt;=0.8.3\n  Downloading terminado-0.9.1-py3-none-any.whl (13 kB)\nRequirement already satisfied: pyparsing&gt;=2.0.2 in /databricks/python3/lib/python3.7/site-packages (from packaging-&gt;bleach-&gt;nbconvert&lt;6-&gt;azureml-contrib-notebook~=1.17.0; extra == &#34;notebooks&#34;-&gt;azureml-sdk[notebooks]) (2.4.6)\nBuilding wheels for collected packages: fusepy, pandocfilters, pyyaml, future, pyrsistent\n  Building wheel for fusepy (setup.py): started\n  Building wheel for fusepy (setup.py): finished with status &#39;done&#39;\n  Created wheel for fusepy: filename=fusepy-3.0.1-py3-none-any.whl size=10503 sha256=87da0f8442ddb6179583cb5d5f94bea942a46cc985ac79c8fe1572a866bae706\n  Stored in directory: /root/.cache/pip/wheels/89/07/84/a5ebfafeefbbc56ceda9d6935a54a8be7a4eccf4ea7e9bf980\n  Building wheel for pandocfilters (setup.py): started\n  Building wheel for pandocfilters (setup.py): finished with status &#39;done&#39;\n  Created wheel for pandocfilters: filename=pandocfilters-1.4.3-py3-none-any.whl size=7991 sha256=0805ad10776ebdcf6dc639d068a4f383ea75b03e6b1e00946c3f265579fb7259\n  Stored in directory: /root/.cache/pip/wheels/42/81/34/545dc2fbf0e9137811e901108d37fc04650e81d48f97078000\n  Building wheel for pyyaml (setup.py): started\n  Building wheel for pyyaml (setup.py): finished with status &#39;done&#39;\n  Created wheel for pyyaml: filename=PyYAML-5.3.1-cp37-cp37m-linux_x86_64.whl size=44619 sha256=60ea44b3876b59a0a28e65f920969be1ef0940c1fe86b6c7b8ac482e3d999811\n  Stored in directory: /root/.cache/pip/wheels/5e/03/1e/e1e954795d6f35dfc7b637fe2277bff021303bd9570ecea653\n  Building wheel for future (setup.py): started\n  Building wheel for future (setup.py): finished with status &#39;done&#39;\n  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491058 sha256=a8e081c521177e61346dc6068c8f57cd9c6b91b4b0b7418de38e67c8a5ff9799\n  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n  Building wheel for pyrsistent (setup.py): started\n  Building wheel for pyrsistent (setup.py): finished with status &#39;done&#39;\n  Created wheel for pyrsistent: filename=pyrsistent-0.17.3-cp37-cp37m-linux_x86_64.whl size=98033 sha256=1efcf8b51cad95c4eed9ca0e9877d588137dc6cd869408ad49b4837f4cec84da\n  Stored in directory: /root/.cache/pip/wheels/a5/52/bf/71258a1d7b3c8cbe1ee53f9314c6f65f20385481eaee573cc5\nSuccessfully built fusepy pandocfilters pyyaml future pyrsistent\nInstalling collected packages: applicationinsights, azure-common, isodate, oauthlib, requests-oauthlib, msrest, PyJWT, adal, msrestazure, azure-mgmt-resource, zipp, importlib-metadata, jsonpickle, azure-mgmt-authorization, backports.weakref, backports.tempfile, contextlib2, azure-mgmt-containerregistry, azure-graphrbac, pyasn1, ndg-httpsclient, azure-mgmt-storage, ruamel.yaml.clib, ruamel.yaml, azure-mgmt-keyvault, websocket-client, docker, jeepney, SecretStorage, pathspec, azureml-core, azureml-telemetry, azureml-train-restclients-hyperdrive, azureml-train-core, azureml-train, azureml-pipeline-core, msal, portalocker, msal-extensions, azure-core, azure-identity, azureml-dataprep-native, azureml-dataprep-rslex, cloudpickle, distro, dotnetcore2, azureml-dataprep, fusepy, azureml-dataset-runtime, azureml-automl-core, azureml-train-automl-client, azureml-pipeline-steps, azureml-pipeline, pyrsistent, attrs, jsonschema, nbformat, MarkupSafe, jinja2, prometheus-client, pandocfilters, testpath, mistune, webencodings, packaging, bleach, defusedxml, nbconvert, argon2-cffi, Send2Trash, terminado, notebook, widgetsnbextension, ipywidgets, azureml-widgets, tenacity, click, tqdm, pyyaml, future, textwrap3, ansiwrap, papermill, azureml-contrib-notebook, azureml-sdk\nSuccessfully installed MarkupSafe-1.1.1 PyJWT-1.7.1 SecretStorage-3.1.2 Send2Trash-1.5.0 adal-1.2.5 ansiwrap-0.8.4 applicationinsights-0.11.9 argon2-cffi-20.1.0 attrs-20.2.0 azure-common-1.1.25 azure-core-1.8.2 azure-graphrbac-0.61.1 azure-identity-1.4.1 azure-mgmt-authorization-0.61.0 azure-mgmt-containerregistry-2.8.0 azure-mgmt-keyvault-2.2.0 azure-mgmt-resource-10.3.0 azure-mgmt-storage-11.2.0 azureml-automl-core-1.17.0 azureml-contrib-notebook-1.17.0 azureml-core-1.17.0 azureml-dataprep-2.4.2 azureml-dataprep-native-24.0.0 azureml-dataprep-rslex-1.2.2 azureml-dataset-runtime-1.17.0 azureml-pipeline-1.17.0 azureml-pipeline-core-1.17.0 azureml-pipeline-steps-1.17.0 azureml-sdk-1.17.0 azureml-telemetry-1.17.0 azureml-train-1.17.0 azureml-train-automl-client-1.17.0 azureml-train-core-1.17.0 azureml-train-restclients-hyperdrive-1.17.0 azureml-widgets-1.17.0 backports.tempfile-1.0 backports.weakref-1.0.post1 bleach-3.2.1 click-7.1.2 cloudpickle-1.6.0 contextlib2-0.6.0.post1 defusedxml-0.6.0 distro-1.5.0 docker-4.3.1 dotnetcore2-2.1.17 fusepy-3.0.1 future-0.18.2 importlib-metadata-2.0.0 ipywidgets-7.5.1 isodate-0.6.0 jeepney-0.4.3 jinja2-2.11.2 jsonpickle-1.4.1 jsonschema-3.2.0 mistune-0.8.4 msal-1.6.0 msal-extensions-0.2.2 msrest-0.6.19 msrestazure-0.6.4 nbconvert-5.6.1 nbformat-5.0.8 ndg-httpsclient-0.5.1 notebook-6.1.4 oauthlib-3.1.0 packaging-20.4 pandocfilters-1.4.3 papermill-1.2.1 pathspec-0.8.0 portalocker-1.7.1 prometheus-client-0.8.0 pyasn1-0.4.8 pyrsistent-0.17.3 pyyaml-5.3.1 requests-oauthlib-1.3.0 ruamel.yaml-0.16.12 ruamel.yaml.clib-0.2.2 tenacity-6.2.0 terminado-0.9.1 testpath-0.4.4 textwrap3-0.9.2 tqdm-4.51.0 webencodings-0.5.1 websocket-client-0.57.0 widgetsnbextension-3.5.1 zipp-3.4.0\nPython interpreter will be restarted.\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Configure workspace and create datastore"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4bf8dd5e-8b4f-487a-8569-739a87c9f09d"}}},{"cell_type":"markdown","source":["Create a workspace object from the existing workspace. A [Workspace](https://docs.microsoft.com/python/api/azureml-core/azureml.core.workspace.workspace?view=azure-ml-py) is a class that accepts your Azure subscription and resource information. It also creates a cloud resource to monitor and track your model runs. `Workspace.from_config()` reads the file **config.json** and loads the authentication details into an object named `ws`. `ws` is used throughout the rest of the code in this tutorial."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"92c5d9ff-6d0a-45d8-b3f7-6199c6919cef"}}},{"cell_type":"code","source":["#Provide the Subscription ID of your existing Azure subscription\nsubscription_id = \"d30d76c0-804c-4f4e-ab7b-509d06a49550\" # <- needs to be the subscription with the MCW-MLOps resource group\n\n#Provide values for the existing Resource Group \nresource_group = \"vlk-workshop\" # <- replace XXXXX with your unique identifier\n\n#Provide the Workspace Name and Azure Region of the Azure Machine Learning Workspace\nworkspace_name = \"vlk-workspace\" # <- replace XXXXX with your unique identifier\nworkspace_region = \"westeurope\" # <- region of your Quick-Starts resource group"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1be557d7-50e9-49ba-b324-244021d7c7ac"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["import azureml.core\nfrom azureml.core.experiment import Experiment\nfrom azureml.core.workspace import Workspace\nfrom azureml.core.model import Model\nfrom azureml.core.dataset import Dataset\nfrom azureml.core.compute import ComputeTarget, AmlCompute, DatabricksCompute\nfrom azureml.core.compute_target import ComputeTargetException\nfrom azureml.widgets import RunDetails\n\n\n# Check core SDK version number\nprint(\"SDK version:\", azureml.core.VERSION)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0dfcaa94-cc1b-4c2b-a4df-2676576380e0"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">SDK version: 1.17.0\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">SDK version: 1.17.0\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# By using the exist_ok param, if the worskpace already exists you get a reference to the existing workspace\n# allowing you to re-run this cell multiple times as desired (which is fairly common in notebooks).\nws = Workspace.create(\n    name = workspace_name,\n    subscription_id = subscription_id,\n    resource_group = resource_group, \n    location = workspace_region,\n    exist_ok = True)\n\nws.write_config()\nprint('Workspace configuration succeeded')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"45d31d25-7f93-4e94-9f78-8be5cd937bc4"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Performing interactive authentication. Please follow the instructions on the terminal.\nTo sign in, use a web browser to open the page https://microsoft.com/devicelogin and enter the code DXGTFEBRT to authenticate.\nYou have logged in. Now let us find all the subscriptions to which you have access...\nInteractive authentication successfully completed.\nWorkspace configuration succeeded\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Performing interactive authentication. Please follow the instructions on the terminal.\nTo sign in, use a web browser to open the page https://microsoft.com/devicelogin and enter the code DXGTFEBRT to authenticate.\nYou have logged in. Now let us find all the subscriptions to which you have access...\nInteractive authentication successfully completed.\nWorkspace configuration succeeded\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Create AML Compute Cluster\nNow you are ready to create the CPU compute cluster. Run the following cell to create a new compute cluster (or retrieve the existing cluster if it already exists). The code below will create a *CPU based* cluster where each node in the cluster is of the size `Standard_D2_V2`, and the cluster is restricted to use 1 node. This will take couple of minutes to create."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f7893aae-1125-420a-87c8-3129e71f6efb"}}},{"cell_type":"code","source":["### Create AML CPU based Compute Cluster\n\ncluster_name = \"vlk-compute\"\n\ntry:\n    compute_target = ComputeTarget(workspace=ws, name=cluster_name)\n    print('Found existing compute target.')\nexcept ComputeTargetException:\n    print('Creating a new compute target...')\n    compute_config = AmlCompute.provisioning_configuration(vm_size='Standard_D2_V2',\n                                                           min_nodes=1, max_nodes=1)\n\n    # create the cluster\n    compute_target = ComputeTarget.create(ws, cluster_name, compute_config)\n\n    compute_target.wait_for_completion(show_output=True)\n\n# Use the 'status' property to get a detailed status for the current AmlCompute. \nprint(compute_target.status.serialize())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f49d66da-6ea7-4e7e-bd16-f02d7c11be05"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Found existing compute target.\n{&#39;currentNodeCount&#39;: 1, &#39;targetNodeCount&#39;: 1, &#39;nodeStateCounts&#39;: {&#39;preparingNodeCount&#39;: 0, &#39;runningNodeCount&#39;: 0, &#39;idleNodeCount&#39;: 1, &#39;unusableNodeCount&#39;: 0, &#39;leavingNodeCount&#39;: 0, &#39;preemptedNodeCount&#39;: 0}, &#39;allocationState&#39;: &#39;Steady&#39;, &#39;allocationStateTransitionTime&#39;: &#39;2020-11-02T10:06:09.094000+00:00&#39;, &#39;errors&#39;: None, &#39;creationTime&#39;: &#39;2020-11-02T10:03:48.827921+00:00&#39;, &#39;modifiedTime&#39;: &#39;2020-11-02T10:04:04.446973+00:00&#39;, &#39;provisioningState&#39;: &#39;Succeeded&#39;, &#39;provisioningStateTransitionTime&#39;: None, &#39;scaleSettings&#39;: {&#39;minNodeCount&#39;: 1, &#39;maxNodeCount&#39;: 1, &#39;nodeIdleTimeBeforeScaleDown&#39;: &#39;&#39;}, &#39;vmPriority&#39;: &#39;Dedicated&#39;, &#39;vmSize&#39;: &#39;STANDARD_D2_V2&#39;}\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Found existing compute target.\n{&#39;currentNodeCount&#39;: 1, &#39;targetNodeCount&#39;: 1, &#39;nodeStateCounts&#39;: {&#39;preparingNodeCount&#39;: 0, &#39;runningNodeCount&#39;: 0, &#39;idleNodeCount&#39;: 1, &#39;unusableNodeCount&#39;: 0, &#39;leavingNodeCount&#39;: 0, &#39;preemptedNodeCount&#39;: 0}, &#39;allocationState&#39;: &#39;Steady&#39;, &#39;allocationStateTransitionTime&#39;: &#39;2020-11-02T10:06:09.094000+00:00&#39;, &#39;errors&#39;: None, &#39;creationTime&#39;: &#39;2020-11-02T10:03:48.827921+00:00&#39;, &#39;modifiedTime&#39;: &#39;2020-11-02T10:04:04.446973+00:00&#39;, &#39;provisioningState&#39;: &#39;Succeeded&#39;, &#39;provisioningStateTransitionTime&#39;: None, &#39;scaleSettings&#39;: {&#39;minNodeCount&#39;: 1, &#39;maxNodeCount&#39;: 1, &#39;nodeIdleTimeBeforeScaleDown&#39;: &#39;&#39;}, &#39;vmPriority&#39;: &#39;Dedicated&#39;, &#39;vmSize&#39;: &#39;STANDARD_D2_V2&#39;}\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Create a datastore for sample images\n\nGet the ImageNet evaluation public data sample from the public blob container `sampledata` on the account `pipelinedata`. Calling `register_azure_blob_container()` makes the data available to the workspace under the name `images_datastore`. Then specify the workspace default datastore as the output datastore, which you use for scoring output in the pipeline."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"03eb22b7-86e7-4ded-8f59-9dd429ba1b4e"}}},{"cell_type":"code","source":["from azureml.core.datastore import Datastore\n\nbatchscore_blob = Datastore.register_azure_blob_container(ws, \n                      datastore_name=\"images_datastore\", \n                      container_name=\"sampledata\", \n                      account_name=\"pipelinedata\", \n                      overwrite=True)\n\ndef_data_store = ws.get_default_datastore()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9213651d-8ab7-4259-9546-39bdd6b88882"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Create data objects\n\nWhen building pipelines, `Dataset` objects are used for reading data from workspace datastores, and `PipelineData` objects are used for transferring intermediate data between pipeline steps.\n\nThis batch scoring example only uses one pipeline step, but in use-cases with multiple steps, the typical flow will include:\n\n1. Using `Dataset` objects as **inputs** to fetch raw data, performing some transformations, then **outputting** a `PipelineData` object.\n1. Use the previous step's `PipelineData` **output object** as an *input object*, repeated for subsequent steps.\n\nFor this scenario you create `Dataset` objects corresponding to the datastore directories for both the input images and the classification labels (y-test values). You also create a `PipelineData` object for the batch scoring output data."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d421e917-5f2e-4e19-8bb3-433694dc06b2"}}},{"cell_type":"code","source":["from azureml.core.dataset import Dataset\nfrom azureml.pipeline.core import PipelineData\n\ninput_images = Dataset.File.from_files((batchscore_blob, \"batchscoring/images/\"))\nlabel_ds = Dataset.File.from_files((batchscore_blob, \"batchscoring/labels/\"))\noutput_dir = PipelineData(name=\"scores\", datastore=def_data_store)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fada48c1-32b4-44fd-b75e-261b38872d8c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Next, we need to register the datasets with the workspace."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8dd5128f-4947-40cd-b7b0-7a877f713e1a"}}},{"cell_type":"code","source":["input_images = input_images.register(workspace=ws, name=\"input_images\")\nlabel_ds = label_ds.register(workspace=ws, name=\"label_ds\", create_new_version=True)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"284db037-e1c7-42d0-ae59-f90ceed5962e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Download and register the model"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1f40daf6-aad6-4fd8-9a7c-691617e0fe46"}}},{"cell_type":"markdown","source":["Download the pre-trained Tensorflow model to use it for batch scoring in the pipeline. First create a local directory where you store the model, then download and extract it."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"02b22451-4b64-4a16-9adc-ca156536fe6c"}}},{"cell_type":"code","source":["import os\nimport tarfile\nimport urllib.request\n\nif not os.path.isdir(\"models\"):\n    os.mkdir(\"models\")\n    \nresponse = urllib.request.urlretrieve(\"http://download.tensorflow.org/models/inception_v3_2016_08_28.tar.gz\", \"model.tar.gz\")\ntar = tarfile.open(\"model.tar.gz\", \"r:gz\")\ntar.extractall(\"models\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9b5aa87e-d600-410c-ad73-30838221f15d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Now you register the model to your workspace, which allows you to easily retrieve it in the pipeline process. In the `register()` static function, the `model_name` parameter is the key you use to locate your model throughout the SDK."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a5c5dee5-8384-4e4c-9df1-d2139e02ffe1"}}},{"cell_type":"code","source":["import shutil\nfrom azureml.core.model import Model\n\n# register downloaded model \nmodel = Model.register(model_path=\"models/inception_v3.ckpt\",\n                       model_name=\"inception\",\n                       tags={\"pretrained\": \"inception\"},\n                       description=\"Imagenet trained tensorflow inception\",\n                       workspace=ws)\n# remove the downloaded dir after registration if you wish\nshutil.rmtree(\"models\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"de2fa1ff-f0d0-4a00-a8bc-f129977ddc02"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Registering model inception\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Registering model inception\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Create and attach remote compute target\n\nAzure Machine Learning service pipelines cannot be run locally, and only run on cloud resources. Remote compute targets are reusable virtual compute environments where you run experiments and work-flows. Run the following code to create a GPU-enabled [`AmlCompute`](https://docs.microsoft.com/python/api/azureml-core/azureml.core.compute.amlcompute.amlcompute?view=azure-ml-py) target, and attach it to your workspace. See the [conceptual article](https://docs.microsoft.com/azure/machine-learning/service/concept-compute-target) for more information on compute targets."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"33616f9e-f566-464f-9da6-39fae8ab44f5"}}},{"cell_type":"code","source":["from azureml.core.compute import AmlCompute, ComputeTarget\nfrom azureml.exceptions import ComputeTargetException\ncompute_name = \"gpu-cluster\"\n\n# checks to see if compute target already exists in workspace, else create it\ntry:\n    compute_target = ComputeTarget(workspace=ws, name=compute_name)\nexcept ComputeTargetException:\n    config = AmlCompute.provisioning_configuration(vm_size=\"STANDARD_NC6\",\n                                                   vm_priority=\"lowpriority\", \n                                                   min_nodes=0, \n                                                   max_nodes=1)\n\n    compute_target = ComputeTarget.create(workspace=ws, name=compute_name, provisioning_configuration=config)\n    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b75052cd-8ead-4bf1-9530-30a3674cd872"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Creating\nSucceeded\nAmlCompute wait for completion finished\n\nMinimum number of nodes requested have been provisioned\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Creating\nSucceeded\nAmlCompute wait for completion finished\n\nMinimum number of nodes requested have been provisioned\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Write a scoring script"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f50e5cb4-78ce-45c1-b52b-b5f5b82efee8"}}},{"cell_type":"markdown","source":["To do the scoring, you create a batch scoring script `batch_scoring.py`, and write it to the current directory. The script takes a minibatch of input images, applies the classification model, and outputs the predictions to a results file.\n\nThe script `batch_scoring.py` takes the following parameters, which get passed from the `ParallelRunStep` that you create later:\n\n- `--model_name`: the name of the model being used\n- `--labels_dir` : the directory path having the `labels.txt` file \n\nThe pipelines infrastructure uses the `ArgumentParser` class to pass parameters into pipeline steps. For example, in the code below the first argument `--model_name` is given the property identifier `model_name`. In the `main()` function, this property is accessed using `Model.get_model_path(args.model_name)`."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b9161742-fb34-4b9e-890e-ffd8c56f9276"}}},{"cell_type":"markdown","source":["The pipeline in this tutorial only has one step and writes the output to a file, but for multi-step pipelines, you also use `ArgumentParser` to define a directory to write output data for input to subsequent steps. See the [notebook](https://github.com/Azure/MachineLearningNotebooks/blob/master/how-to-use-azureml/machine-learning-pipelines/nyc-taxi-data-regression-model-building/nyc-taxi-data-regression-model-building.ipynb) for an example of passing data between multiple pipeline steps using the `ArgumentParser` design pattern."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"374c3aef-d4ae-4883-aa8b-aaf387d00115"}}},{"cell_type":"code","source":["%%writefile /dbfs/scripts/batch_scoring.py\n\n# Copyright (c) Microsoft. All rights reserved.\n# Licensed under the MIT license.\n\nimport os\nimport argparse\nimport datetime\nimport time\nimport tensorflow as tf\nfrom math import ceil\nimport numpy as np\nimport shutil\nfrom tensorflow.contrib.slim.python.slim.nets import inception_v3\n\nfrom azureml.core import Run\nfrom azureml.core.model import Model\nfrom azureml.core.dataset import Dataset\n\nslim = tf.contrib.slim\n\nimage_size = 299\nnum_channel = 3\n\n\ndef get_class_label_dict(labels_dir):\n    label = []\n    labels_path = os.path.join(labels_dir, 'labels.txt')\n    proto_as_ascii_lines = tf.gfile.GFile(labels_path).readlines()\n    for l in proto_as_ascii_lines:\n        label.append(l.rstrip())\n    return label\n\n\ndef init():\n    global g_tf_sess, probabilities, label_dict, input_images\n\n    parser = argparse.ArgumentParser(description=\"Start a tensorflow model serving\")\n    parser.add_argument('--model_name', dest=\"model_name\", required=True)\n    parser.add_argument('--labels_dir', dest=\"labels_dir\", required=True)\n    args, _ = parser.parse_known_args()\n\n    label_dict = get_class_label_dict(args.labels_dir)\n    classes_num = len(label_dict)\n\n    with slim.arg_scope(inception_v3.inception_v3_arg_scope()):\n        input_images = tf.placeholder(tf.float32, [1, image_size, image_size, num_channel])\n        logits, _ = inception_v3.inception_v3(input_images,\n                                              num_classes=classes_num,\n                                              is_training=False)\n        probabilities = tf.argmax(logits, 1)\n\n    config = tf.ConfigProto()\n    config.gpu_options.allow_growth = True\n    g_tf_sess = tf.Session(config=config)\n    g_tf_sess.run(tf.global_variables_initializer())\n    g_tf_sess.run(tf.local_variables_initializer())\n\n    model_path = Model.get_model_path(args.model_name)\n    saver = tf.train.Saver()\n    saver.restore(g_tf_sess, model_path)\n\n\ndef file_to_tensor(file_path):\n    image_string = tf.read_file(file_path)\n    image = tf.image.decode_image(image_string, channels=3)\n\n    image.set_shape([None, None, None])\n    image = tf.image.resize_images(image, [image_size, image_size])\n    image = tf.divide(tf.subtract(image, [0]), [255])\n    image.set_shape([image_size, image_size, num_channel])\n    return image\n\n\ndef run(mini_batch):\n    result_list = []\n    for file_path in mini_batch:\n        test_image = file_to_tensor(file_path)\n        out = g_tf_sess.run(test_image)\n        result = g_tf_sess.run(probabilities, feed_dict={input_images: [out]})\n        result_list.append(os.path.basename(file_path) + \": \" + label_dict[result[0]])\n    return result_list"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e279527c-eb90-4564-b20c-af359644c57d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Overwriting /dbfs/scripts/batch_scoring.py\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Overwriting /dbfs/scripts/batch_scoring.py\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Build and run the pipeline"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"738b6d13-1662-452f-9682-41a115d4adee"}}},{"cell_type":"markdown","source":["Before running the pipeline, you create an object that defines the python environment and dependencies needed by your script `batch_scoring.py`. The main dependency required is Tensorflow, but you also install `azureml-core` and `azureml-dataset-runtime[fuse]` for background processes from the SDK. Create a `RunConfiguration` object using the dependencies, and also specify Docker and Docker-GPU support."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"febdfd07-5ac0-4d8a-af34-28823623d8ff"}}},{"cell_type":"code","source":["from azureml.core import Environment\nfrom azureml.core.conda_dependencies import CondaDependencies\nfrom azureml.core.runconfig import DEFAULT_GPU_IMAGE\n\ncd = CondaDependencies.create(pip_packages=[\"tensorflow-gpu==1.15.2\",\n                                            \"azureml-core\", \"azureml-dataset-runtime[fuse]\"])\n\nenv = Environment(name=\"parallelenv\")\nenv.python.conda_dependencies=cd\nenv.docker.base_image = DEFAULT_GPU_IMAGE"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d951427d-7781-4ff4-8cf9-efd613425c2a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Create the configuration to wrap the inference script\nCreate the pipeline step using the script, environment configuration, and parameters. Specify the compute target you already attached to your workspace as the target of execution of the script. We will use PythonScriptStep to create the pipeline step."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"aae6de96-88c7-42f3-b0e6-7606fe404109"}}},{"cell_type":"code","source":["from azureml.pipeline.steps import ParallelRunConfig\n\nparallel_run_config = ParallelRunConfig(\n    environment=env,\n    entry_script=\"batch_scoring.py\",\n    source_directory=\"/dbfs/scripts\",\n    output_action=\"append_row\",\n    append_row_file_name=\"parallel_run_step.txt\",\n    mini_batch_size=\"20\",\n    error_threshold=1,\n    compute_target=compute_target,\n    process_count_per_node=2,\n    node_count=1\n)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6b44ce6d-8bee-4b32-a0a3-de4cb321bdc1"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Create the pipeline step\n\nA pipeline step is an object that encapsulates everything you need for running a pipeline including:\n\n* environment and dependency settings\n* the compute resource to run the pipeline on\n* input and output data, and any custom parameters\n* reference to a script or SDK-logic to run during the step\n\nThere are multiple classes that inherit from the parent class [`PipelineStep`](https://docs.microsoft.com/python/api/azureml-pipeline-steps/azureml.pipeline.steps.parallelrunstep?view=azure-ml-py) to assist with building a step using certain frameworks and stacks. In this example, you use the [`ParallelRunStep`](https://docs.microsoft.com/en-us/python/api/azureml-contrib-pipeline-steps/azureml.contrib.pipeline.steps.parallelrunstep?view=azure-ml-py) class to define your step logic using a scoring script. \n\nAn object reference in the `outputs` array becomes available as an **input** for a subsequent pipeline step, for scenarios where there is more than one step."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"81466766-57fa-4490-b6be-1145c00dec36"}}},{"cell_type":"code","source":["from azureml.pipeline.steps import ParallelRunStep\nfrom datetime import datetime\n\nparallel_step_name = \"batchscoring-\" + datetime.now().strftime(\"%Y%m%d%H%M\")\n\nlabel_config = label_ds.as_named_input(\"labels_input\")\n\nbatch_score_step = ParallelRunStep(\n    name=parallel_step_name,\n    inputs=[input_images.as_named_input(\"input_images\")],\n    output=output_dir,\n    arguments=[\"--model_name\", \"inception\",\n               \"--labels_dir\", label_config],\n    side_inputs=[label_config],\n    parallel_run_config=parallel_run_config,\n    allow_reuse=False\n)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9911527c-fb94-4625-aff4-e389daa1197d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["For a list of all classes for different step types, see the [steps package](https://docs.microsoft.com/python/api/azureml-pipeline-steps/azureml.pipeline.steps?view=azure-ml-py)."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"16e6243e-4cf6-4552-bb8d-5edf0975cf08"}}},{"cell_type":"markdown","source":["### Run the pipeline\n\nNow you run the pipeline. First create a `Pipeline` object with your workspace reference and the pipeline step you created. The `steps` parameter is an array of steps, and in this case there is only one step for batch scoring. To build pipelines with multiple steps, you place the steps in order in this array.\n\nNext use the `Experiment.submit()` function to submit the pipeline for execution. You also specify the custom parameter `param_batch_size`. The `wait_for_completion` function will output logs during the pipeline build process, which allows you to see current progress.\n\nNote: The first pipeline run takes roughly **15 minutes**, as all dependencies must be downloaded, a Docker image is created, and the Python environment is provisioned/created. Running it again takes significantly less time as those resources are reused. However, total run time depends on the workload of your scripts and processes running in each pipeline step."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f922170e-8cb5-4a36-8166-9f612bacc574"}}},{"cell_type":"code","source":["from azureml.core import Experiment\nfrom azureml.pipeline.core import Pipeline\n\npipeline = Pipeline(workspace=ws, steps=[batch_score_step])\npipeline_run = Experiment(ws, \"batch_scoring\").submit(pipeline)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a1414077-fd27-40b2-96cf-75b4eccad7c2"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"type":"ipynbError","data":"<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">ValueError</span>                                Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-3981079154799686&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      2</span> <span class=\"ansi-green-fg\">from</span> azureml<span class=\"ansi-blue-fg\">.</span>pipeline<span class=\"ansi-blue-fg\">.</span>core <span class=\"ansi-green-fg\">import</span> Pipeline\n<span class=\"ansi-green-intense-fg ansi-bold\">      3</span> \n<span class=\"ansi-green-fg\">----&gt; 4</span><span class=\"ansi-red-fg\"> </span>pipeline <span class=\"ansi-blue-fg\">=</span> Pipeline<span class=\"ansi-blue-fg\">(</span>workspace<span class=\"ansi-blue-fg\">=</span>ws<span class=\"ansi-blue-fg\">,</span> steps<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-blue-fg\">[</span>batch_score_step<span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      5</span> pipeline_run <span class=\"ansi-blue-fg\">=</span> Experiment<span class=\"ansi-blue-fg\">(</span>ws<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">&#34;batch_scoring&#34;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>submit<span class=\"ansi-blue-fg\">(</span>pipeline<span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/local_disk0/.ephemeral_nfs/envs/pythonEnv-1291aec0-13fd-49c0-a374-30251492cbed/lib/python3.7/site-packages/azureml/core/_experiment_method.py</span> in <span class=\"ansi-cyan-fg\">wrapper</span><span class=\"ansi-blue-fg\">(self, *args, **kwargs)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     95</span>             &#34;&#34;&#34;\n<span class=\"ansi-green-intense-fg ansi-bold\">     96</span>             ExperimentSubmitRegistrar<span class=\"ansi-blue-fg\">.</span>register_submit_function<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">.</span>__class__<span class=\"ansi-blue-fg\">,</span> submit_function<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">---&gt; 97</span><span class=\"ansi-red-fg\">             </span><span class=\"ansi-green-fg\">return</span> init_func<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">*</span>args<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>kwargs<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     98</span>         <span class=\"ansi-green-fg\">return</span> wrapper\n<span class=\"ansi-green-intense-fg ansi-bold\">     99</span>     <span class=\"ansi-green-fg\">return</span> real_decorator\n\n<span class=\"ansi-green-fg\">/local_disk0/.ephemeral_nfs/envs/pythonEnv-1291aec0-13fd-49c0-a374-30251492cbed/lib/python3.7/site-packages/azureml/pipeline/core/pipeline.py</span> in <span class=\"ansi-cyan-fg\">__init__</span><span class=\"ansi-blue-fg\">(self, workspace, steps, description, default_datastore, default_source_directory, resolve_closure, _workflow_provider, _service_endpoint, **kwargs)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    175</span>                 <span class=\"ansi-green-fg\">raise</span> ValueError<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#39;parameter %s is not recognized for Pipeline &#39;</span> <span class=\"ansi-blue-fg\">%</span> key<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    176</span>         self<span class=\"ansi-blue-fg\">.</span>_enable_email_notification <span class=\"ansi-blue-fg\">=</span> enable_email_notification\n<span class=\"ansi-green-fg\">--&gt; 177</span><span class=\"ansi-red-fg\">         </span>self<span class=\"ansi-blue-fg\">.</span>_graph <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_graph_builder<span class=\"ansi-blue-fg\">.</span>build<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">.</span>_name<span class=\"ansi-blue-fg\">,</span> steps<span class=\"ansi-blue-fg\">,</span> finalize<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-green-fg\">False</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    178</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    179</span>     <span class=\"ansi-green-fg\">def</span> _set_experiment_name<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">,</span> name<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/local_disk0/.ephemeral_nfs/envs/pythonEnv-1291aec0-13fd-49c0-a374-30251492cbed/lib/python3.7/site-packages/azureml/pipeline/core/builder.py</span> in <span class=\"ansi-cyan-fg\">build</span><span class=\"ansi-blue-fg\">(self, name, steps, finalize, regenerate_outputs)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1479</span>                 <span class=\"ansi-green-fg\">pass</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1480</span> \n<span class=\"ansi-green-fg\">-&gt; 1481</span><span class=\"ansi-red-fg\">         </span>graph <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>construct<span class=\"ansi-blue-fg\">(</span>name<span class=\"ansi-blue-fg\">,</span> steps<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1482</span>         <span class=\"ansi-green-fg\">if</span> finalize<span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1483</span>             graph<span class=\"ansi-blue-fg\">.</span>finalize<span class=\"ansi-blue-fg\">(</span>regenerate_outputs<span class=\"ansi-blue-fg\">=</span>regenerate_outputs<span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/local_disk0/.ephemeral_nfs/envs/pythonEnv-1291aec0-13fd-49c0-a374-30251492cbed/lib/python3.7/site-packages/azureml/pipeline/core/builder.py</span> in <span class=\"ansi-cyan-fg\">construct</span><span class=\"ansi-blue-fg\">(self, name, steps)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1501</span>         self<span class=\"ansi-blue-fg\">.</span>_graph <span class=\"ansi-blue-fg\">=</span> Graph<span class=\"ansi-blue-fg\">(</span>name<span class=\"ansi-blue-fg\">,</span> self<span class=\"ansi-blue-fg\">.</span>_context<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1502</span>         self<span class=\"ansi-blue-fg\">.</span>_nodeStack<span class=\"ansi-blue-fg\">.</span>append<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">[</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">-&gt; 1503</span><span class=\"ansi-red-fg\">         </span>self<span class=\"ansi-blue-fg\">.</span>process_collection<span class=\"ansi-blue-fg\">(</span>steps<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1504</span>         <span class=\"ansi-green-fg\">for</span> builder <span class=\"ansi-green-fg\">in</span> self<span class=\"ansi-blue-fg\">.</span>_builderStack<span class=\"ansi-blue-fg\">[</span><span class=\"ansi-blue-fg\">:</span><span class=\"ansi-blue-fg\">:</span><span class=\"ansi-blue-fg\">-</span><span class=\"ansi-cyan-fg\">1</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1505</span>             builder<span class=\"ansi-blue-fg\">.</span>apply_rules<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/local_disk0/.ephemeral_nfs/envs/pythonEnv-1291aec0-13fd-49c0-a374-30251492cbed/lib/python3.7/site-packages/azureml/pipeline/core/builder.py</span> in <span class=\"ansi-cyan-fg\">process_collection</span><span class=\"ansi-blue-fg\">(self, collection)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1537</span>         self<span class=\"ansi-blue-fg\">.</span>_nodeStack<span class=\"ansi-blue-fg\">.</span>append<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">[</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1538</span>         self<span class=\"ansi-blue-fg\">.</span>_builderStack<span class=\"ansi-blue-fg\">.</span>append<span class=\"ansi-blue-fg\">(</span>builder<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">-&gt; 1539</span><span class=\"ansi-red-fg\">         </span>builder<span class=\"ansi-blue-fg\">.</span>process_collection<span class=\"ansi-blue-fg\">(</span>collection<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1540</span>         added_nodes <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_nodeStack<span class=\"ansi-blue-fg\">.</span>pop<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1541</span>         self<span class=\"ansi-blue-fg\">.</span>_nodeStack<span class=\"ansi-blue-fg\">[</span><span class=\"ansi-blue-fg\">-</span><span class=\"ansi-cyan-fg\">1</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">.</span>extend<span class=\"ansi-blue-fg\">(</span>added_nodes<span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/local_disk0/.ephemeral_nfs/envs/pythonEnv-1291aec0-13fd-49c0-a374-30251492cbed/lib/python3.7/site-packages/azureml/pipeline/core/builder.py</span> in <span class=\"ansi-cyan-fg\">process_collection</span><span class=\"ansi-blue-fg\">(self, collection)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1828</span>         &#34;&#34;&#34;\n<span class=\"ansi-green-intense-fg ansi-bold\">   1829</span>         <span class=\"ansi-green-fg\">for</span> item <span class=\"ansi-green-fg\">in</span> collection<span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">-&gt; 1830</span><span class=\"ansi-red-fg\">             </span>self<span class=\"ansi-blue-fg\">.</span>_base_builder<span class=\"ansi-blue-fg\">.</span>process_collection<span class=\"ansi-blue-fg\">(</span>item<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1831</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   1832</span>     <span class=\"ansi-green-fg\">def</span> apply_rules<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/local_disk0/.ephemeral_nfs/envs/pythonEnv-1291aec0-13fd-49c0-a374-30251492cbed/lib/python3.7/site-packages/azureml/pipeline/core/builder.py</span> in <span class=\"ansi-cyan-fg\">process_collection</span><span class=\"ansi-blue-fg\">(self, collection)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1531</span>         <span class=\"ansi-red-fg\"># just a step?</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1532</span>         <span class=\"ansi-green-fg\">if</span> isinstance<span class=\"ansi-blue-fg\">(</span>collection<span class=\"ansi-blue-fg\">,</span> PipelineStep<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">-&gt; 1533</span><span class=\"ansi-red-fg\">             </span><span class=\"ansi-green-fg\">return</span> self<span class=\"ansi-blue-fg\">.</span>process_step<span class=\"ansi-blue-fg\">(</span>collection<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1534</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   1535</span>         <span class=\"ansi-red-fg\"># delegate to correct builder</span>\n\n<span class=\"ansi-green-fg\">/local_disk0/.ephemeral_nfs/envs/pythonEnv-1291aec0-13fd-49c0-a374-30251492cbed/lib/python3.7/site-packages/azureml/pipeline/core/builder.py</span> in <span class=\"ansi-cyan-fg\">process_step</span><span class=\"ansi-blue-fg\">(self, step)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1575</span>             <span class=\"ansi-green-fg\">return</span> self<span class=\"ansi-blue-fg\">.</span>_step2node<span class=\"ansi-blue-fg\">[</span>step<span class=\"ansi-blue-fg\">]</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1576</span> \n<span class=\"ansi-green-fg\">-&gt; 1577</span><span class=\"ansi-red-fg\">         </span>node <span class=\"ansi-blue-fg\">=</span> step<span class=\"ansi-blue-fg\">.</span>create_node<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">.</span>_graph<span class=\"ansi-blue-fg\">,</span> self<span class=\"ansi-blue-fg\">.</span>_default_datastore<span class=\"ansi-blue-fg\">,</span> self<span class=\"ansi-blue-fg\">.</span>_context<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1578</span>         self<span class=\"ansi-blue-fg\">.</span>assert_node_valid<span class=\"ansi-blue-fg\">(</span>step<span class=\"ansi-blue-fg\">,</span> self<span class=\"ansi-blue-fg\">.</span>_graph<span class=\"ansi-blue-fg\">,</span> node<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1579</span> \n\n<span class=\"ansi-green-fg\">/local_disk0/.ephemeral_nfs/envs/pythonEnv-1291aec0-13fd-49c0-a374-30251492cbed/lib/python3.7/site-packages/azureml/pipeline/steps/parallel_run_step.py</span> in <span class=\"ansi-cyan-fg\">create_node</span><span class=\"ansi-blue-fg\">(self, graph, default_datastore, context)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    170</span>         <span class=\"ansi-blue-fg\">:</span>rtype<span class=\"ansi-blue-fg\">:</span> azureml<span class=\"ansi-blue-fg\">.</span>pipeline<span class=\"ansi-blue-fg\">.</span>core<span class=\"ansi-blue-fg\">.</span>graph<span class=\"ansi-blue-fg\">.</span>Node\n<span class=\"ansi-green-intense-fg ansi-bold\">    171</span>         &#34;&#34;&#34;\n<span class=\"ansi-green-fg\">--&gt; 172</span><span class=\"ansi-red-fg\">         </span><span class=\"ansi-green-fg\">return</span> super<span class=\"ansi-blue-fg\">(</span>ParallelRunStep<span class=\"ansi-blue-fg\">,</span> self<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>create_node<span class=\"ansi-blue-fg\">(</span>graph<span class=\"ansi-blue-fg\">,</span> default_datastore<span class=\"ansi-blue-fg\">,</span> context<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    173</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    174</span>     def create_module_def(\n\n<span class=\"ansi-green-fg\">/local_disk0/.ephemeral_nfs/envs/pythonEnv-1291aec0-13fd-49c0-a374-30251492cbed/lib/python3.7/site-packages/azureml/pipeline/core/_parallel_run_step_base.py</span> in <span class=\"ansi-cyan-fg\">create_node</span><span class=\"ansi-blue-fg\">(self, graph, default_datastore, context)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    649</span>         <span class=\"ansi-blue-fg\">:</span>rtype<span class=\"ansi-blue-fg\">:</span> azureml<span class=\"ansi-blue-fg\">.</span>pipeline<span class=\"ansi-blue-fg\">.</span>core<span class=\"ansi-blue-fg\">.</span>graph<span class=\"ansi-blue-fg\">.</span>Node\n<span class=\"ansi-green-intense-fg ansi-bold\">    650</span>         &#34;&#34;&#34;\n<span class=\"ansi-green-fg\">--&gt; 651</span><span class=\"ansi-red-fg\">         </span>node <span class=\"ansi-blue-fg\">=</span> super<span class=\"ansi-blue-fg\">(</span>_ParallelRunStepBase<span class=\"ansi-blue-fg\">,</span> self<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>create_node<span class=\"ansi-blue-fg\">(</span>graph<span class=\"ansi-blue-fg\">,</span> default_datastore<span class=\"ansi-blue-fg\">,</span> context<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    652</span>         node<span class=\"ansi-blue-fg\">.</span>get_param<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;BatchInferencingMetaData&#34;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>set_value<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">.</span>_generate_batch_inference_metadata<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    653</span>         node<span class=\"ansi-blue-fg\">.</span>get_param<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;Script&#34;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>set_value<span class=\"ansi-blue-fg\">(</span>DEFAULT_BATCH_SCORE_MAIN_FILE_NAME<span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/local_disk0/.ephemeral_nfs/envs/pythonEnv-1291aec0-13fd-49c0-a374-30251492cbed/lib/python3.7/site-packages/azureml/pipeline/core/_python_script_step_base.py</span> in <span class=\"ansi-cyan-fg\">create_node</span><span class=\"ansi-blue-fg\">(self, graph, default_datastore, context)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    135</span>                                          compute_target_name<span class=\"ansi-blue-fg\">,</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    136</span>                                          compute_target_type<span class=\"ansi-blue-fg\">,</span>\n<span class=\"ansi-green-fg\">--&gt; 137</span><span class=\"ansi-red-fg\">                                          compute_target_object)\n</span><span class=\"ansi-green-intense-fg ansi-bold\">    138</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    139</span>         <span class=\"ansi-red-fg\"># set pipeline parameters on node and on graph</span>\n\n<span class=\"ansi-green-fg\">/local_disk0/.ephemeral_nfs/envs/pythonEnv-1291aec0-13fd-49c0-a374-30251492cbed/lib/python3.7/site-packages/azureml/pipeline/core/_python_script_step_base.py</span> in <span class=\"ansi-cyan-fg\">_set_compute_params_to_node</span><span class=\"ansi-blue-fg\">(self, node, compute_target_name, compute_target_type, compute_target_object)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    224</span>             node<span class=\"ansi-blue-fg\">=</span>node<span class=\"ansi-blue-fg\">,</span> target_name<span class=\"ansi-blue-fg\">=</span>compute_target_name<span class=\"ansi-blue-fg\">,</span> target_type<span class=\"ansi-blue-fg\">=</span>compute_target_type<span class=\"ansi-blue-fg\">,</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    225</span>             target_object<span class=\"ansi-blue-fg\">=</span>compute_target_object<span class=\"ansi-blue-fg\">,</span> script_name<span class=\"ansi-blue-fg\">=</span>self<span class=\"ansi-blue-fg\">.</span>_script_name<span class=\"ansi-blue-fg\">,</span> arguments<span class=\"ansi-blue-fg\">=</span>self<span class=\"ansi-blue-fg\">.</span>_resolved_arguments<span class=\"ansi-blue-fg\">,</span>\n<span class=\"ansi-green-fg\">--&gt; 226</span><span class=\"ansi-red-fg\">             runconfig_params={}, batchai_params=self._amlcompute_params)\n</span><span class=\"ansi-green-intense-fg ansi-bold\">    227</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    228</span>     <span class=\"ansi-green-fg\">def</span> _set_amlcompute_params<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">,</span> native_shared_directory<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-green-fg\">None</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/local_disk0/.ephemeral_nfs/envs/pythonEnv-1291aec0-13fd-49c0-a374-30251492cbed/lib/python3.7/site-packages/azureml/pipeline/core/_module_parameter_provider.py</span> in <span class=\"ansi-cyan-fg\">set_params_to_node</span><span class=\"ansi-blue-fg\">(self, node, target_name, target_type, target_object, script_name, arguments, runconfig_params, batchai_params)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    154</span>                     runconfig_params=None, compute_params=None)\n<span class=\"ansi-green-intense-fg ansi-bold\">    155</span>             <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 156</span><span class=\"ansi-red-fg\">                 </span><span class=\"ansi-green-fg\">raise</span> ValueError<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;Invalid compute target type: {0}&#34;</span><span class=\"ansi-blue-fg\">.</span>format<span class=\"ansi-blue-fg\">(</span>target_type<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    157</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    158</span>     <span class=\"ansi-green-fg\">def</span> _get_common_params_list<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-red-fg\">ValueError</span>: Invalid compute target type: Databricks</div>","errorSummary":"<span class=\"ansi-red-fg\">ValueError</span>: Invalid compute target type: Databricks","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">ValueError</span>                                Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-3981079154799686&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      2</span> <span class=\"ansi-green-fg\">from</span> azureml<span class=\"ansi-blue-fg\">.</span>pipeline<span class=\"ansi-blue-fg\">.</span>core <span class=\"ansi-green-fg\">import</span> Pipeline\n<span class=\"ansi-green-intense-fg ansi-bold\">      3</span> \n<span class=\"ansi-green-fg\">----&gt; 4</span><span class=\"ansi-red-fg\"> </span>pipeline <span class=\"ansi-blue-fg\">=</span> Pipeline<span class=\"ansi-blue-fg\">(</span>workspace<span class=\"ansi-blue-fg\">=</span>ws<span class=\"ansi-blue-fg\">,</span> steps<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-blue-fg\">[</span>batch_score_step<span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      5</span> pipeline_run <span class=\"ansi-blue-fg\">=</span> Experiment<span class=\"ansi-blue-fg\">(</span>ws<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">&#34;batch_scoring&#34;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>submit<span class=\"ansi-blue-fg\">(</span>pipeline<span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/local_disk0/.ephemeral_nfs/envs/pythonEnv-1291aec0-13fd-49c0-a374-30251492cbed/lib/python3.7/site-packages/azureml/core/_experiment_method.py</span> in <span class=\"ansi-cyan-fg\">wrapper</span><span class=\"ansi-blue-fg\">(self, *args, **kwargs)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     95</span>             &#34;&#34;&#34;\n<span class=\"ansi-green-intense-fg ansi-bold\">     96</span>             ExperimentSubmitRegistrar<span class=\"ansi-blue-fg\">.</span>register_submit_function<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">.</span>__class__<span class=\"ansi-blue-fg\">,</span> submit_function<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">---&gt; 97</span><span class=\"ansi-red-fg\">             </span><span class=\"ansi-green-fg\">return</span> init_func<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">*</span>args<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>kwargs<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     98</span>         <span class=\"ansi-green-fg\">return</span> wrapper\n<span class=\"ansi-green-intense-fg ansi-bold\">     99</span>     <span class=\"ansi-green-fg\">return</span> real_decorator\n\n<span class=\"ansi-green-fg\">/local_disk0/.ephemeral_nfs/envs/pythonEnv-1291aec0-13fd-49c0-a374-30251492cbed/lib/python3.7/site-packages/azureml/pipeline/core/pipeline.py</span> in <span class=\"ansi-cyan-fg\">__init__</span><span class=\"ansi-blue-fg\">(self, workspace, steps, description, default_datastore, default_source_directory, resolve_closure, _workflow_provider, _service_endpoint, **kwargs)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    175</span>                 <span class=\"ansi-green-fg\">raise</span> ValueError<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#39;parameter %s is not recognized for Pipeline &#39;</span> <span class=\"ansi-blue-fg\">%</span> key<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    176</span>         self<span class=\"ansi-blue-fg\">.</span>_enable_email_notification <span class=\"ansi-blue-fg\">=</span> enable_email_notification\n<span class=\"ansi-green-fg\">--&gt; 177</span><span class=\"ansi-red-fg\">         </span>self<span class=\"ansi-blue-fg\">.</span>_graph <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_graph_builder<span class=\"ansi-blue-fg\">.</span>build<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">.</span>_name<span class=\"ansi-blue-fg\">,</span> steps<span class=\"ansi-blue-fg\">,</span> finalize<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-green-fg\">False</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    178</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    179</span>     <span class=\"ansi-green-fg\">def</span> _set_experiment_name<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">,</span> name<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/local_disk0/.ephemeral_nfs/envs/pythonEnv-1291aec0-13fd-49c0-a374-30251492cbed/lib/python3.7/site-packages/azureml/pipeline/core/builder.py</span> in <span class=\"ansi-cyan-fg\">build</span><span class=\"ansi-blue-fg\">(self, name, steps, finalize, regenerate_outputs)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1479</span>                 <span class=\"ansi-green-fg\">pass</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1480</span> \n<span class=\"ansi-green-fg\">-&gt; 1481</span><span class=\"ansi-red-fg\">         </span>graph <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>construct<span class=\"ansi-blue-fg\">(</span>name<span class=\"ansi-blue-fg\">,</span> steps<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1482</span>         <span class=\"ansi-green-fg\">if</span> finalize<span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1483</span>             graph<span class=\"ansi-blue-fg\">.</span>finalize<span class=\"ansi-blue-fg\">(</span>regenerate_outputs<span class=\"ansi-blue-fg\">=</span>regenerate_outputs<span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/local_disk0/.ephemeral_nfs/envs/pythonEnv-1291aec0-13fd-49c0-a374-30251492cbed/lib/python3.7/site-packages/azureml/pipeline/core/builder.py</span> in <span class=\"ansi-cyan-fg\">construct</span><span class=\"ansi-blue-fg\">(self, name, steps)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1501</span>         self<span class=\"ansi-blue-fg\">.</span>_graph <span class=\"ansi-blue-fg\">=</span> Graph<span class=\"ansi-blue-fg\">(</span>name<span class=\"ansi-blue-fg\">,</span> self<span class=\"ansi-blue-fg\">.</span>_context<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1502</span>         self<span class=\"ansi-blue-fg\">.</span>_nodeStack<span class=\"ansi-blue-fg\">.</span>append<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">[</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">-&gt; 1503</span><span class=\"ansi-red-fg\">         </span>self<span class=\"ansi-blue-fg\">.</span>process_collection<span class=\"ansi-blue-fg\">(</span>steps<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1504</span>         <span class=\"ansi-green-fg\">for</span> builder <span class=\"ansi-green-fg\">in</span> self<span class=\"ansi-blue-fg\">.</span>_builderStack<span class=\"ansi-blue-fg\">[</span><span class=\"ansi-blue-fg\">:</span><span class=\"ansi-blue-fg\">:</span><span class=\"ansi-blue-fg\">-</span><span class=\"ansi-cyan-fg\">1</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1505</span>             builder<span class=\"ansi-blue-fg\">.</span>apply_rules<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/local_disk0/.ephemeral_nfs/envs/pythonEnv-1291aec0-13fd-49c0-a374-30251492cbed/lib/python3.7/site-packages/azureml/pipeline/core/builder.py</span> in <span class=\"ansi-cyan-fg\">process_collection</span><span class=\"ansi-blue-fg\">(self, collection)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1537</span>         self<span class=\"ansi-blue-fg\">.</span>_nodeStack<span class=\"ansi-blue-fg\">.</span>append<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">[</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1538</span>         self<span class=\"ansi-blue-fg\">.</span>_builderStack<span class=\"ansi-blue-fg\">.</span>append<span class=\"ansi-blue-fg\">(</span>builder<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">-&gt; 1539</span><span class=\"ansi-red-fg\">         </span>builder<span class=\"ansi-blue-fg\">.</span>process_collection<span class=\"ansi-blue-fg\">(</span>collection<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1540</span>         added_nodes <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_nodeStack<span class=\"ansi-blue-fg\">.</span>pop<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1541</span>         self<span class=\"ansi-blue-fg\">.</span>_nodeStack<span class=\"ansi-blue-fg\">[</span><span class=\"ansi-blue-fg\">-</span><span class=\"ansi-cyan-fg\">1</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">.</span>extend<span class=\"ansi-blue-fg\">(</span>added_nodes<span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/local_disk0/.ephemeral_nfs/envs/pythonEnv-1291aec0-13fd-49c0-a374-30251492cbed/lib/python3.7/site-packages/azureml/pipeline/core/builder.py</span> in <span class=\"ansi-cyan-fg\">process_collection</span><span class=\"ansi-blue-fg\">(self, collection)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1828</span>         &#34;&#34;&#34;\n<span class=\"ansi-green-intense-fg ansi-bold\">   1829</span>         <span class=\"ansi-green-fg\">for</span> item <span class=\"ansi-green-fg\">in</span> collection<span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">-&gt; 1830</span><span class=\"ansi-red-fg\">             </span>self<span class=\"ansi-blue-fg\">.</span>_base_builder<span class=\"ansi-blue-fg\">.</span>process_collection<span class=\"ansi-blue-fg\">(</span>item<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1831</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   1832</span>     <span class=\"ansi-green-fg\">def</span> apply_rules<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/local_disk0/.ephemeral_nfs/envs/pythonEnv-1291aec0-13fd-49c0-a374-30251492cbed/lib/python3.7/site-packages/azureml/pipeline/core/builder.py</span> in <span class=\"ansi-cyan-fg\">process_collection</span><span class=\"ansi-blue-fg\">(self, collection)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1531</span>         <span class=\"ansi-red-fg\"># just a step?</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1532</span>         <span class=\"ansi-green-fg\">if</span> isinstance<span class=\"ansi-blue-fg\">(</span>collection<span class=\"ansi-blue-fg\">,</span> PipelineStep<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">-&gt; 1533</span><span class=\"ansi-red-fg\">             </span><span class=\"ansi-green-fg\">return</span> self<span class=\"ansi-blue-fg\">.</span>process_step<span class=\"ansi-blue-fg\">(</span>collection<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1534</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   1535</span>         <span class=\"ansi-red-fg\"># delegate to correct builder</span>\n\n<span class=\"ansi-green-fg\">/local_disk0/.ephemeral_nfs/envs/pythonEnv-1291aec0-13fd-49c0-a374-30251492cbed/lib/python3.7/site-packages/azureml/pipeline/core/builder.py</span> in <span class=\"ansi-cyan-fg\">process_step</span><span class=\"ansi-blue-fg\">(self, step)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1575</span>             <span class=\"ansi-green-fg\">return</span> self<span class=\"ansi-blue-fg\">.</span>_step2node<span class=\"ansi-blue-fg\">[</span>step<span class=\"ansi-blue-fg\">]</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1576</span> \n<span class=\"ansi-green-fg\">-&gt; 1577</span><span class=\"ansi-red-fg\">         </span>node <span class=\"ansi-blue-fg\">=</span> step<span class=\"ansi-blue-fg\">.</span>create_node<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">.</span>_graph<span class=\"ansi-blue-fg\">,</span> self<span class=\"ansi-blue-fg\">.</span>_default_datastore<span class=\"ansi-blue-fg\">,</span> self<span class=\"ansi-blue-fg\">.</span>_context<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1578</span>         self<span class=\"ansi-blue-fg\">.</span>assert_node_valid<span class=\"ansi-blue-fg\">(</span>step<span class=\"ansi-blue-fg\">,</span> self<span class=\"ansi-blue-fg\">.</span>_graph<span class=\"ansi-blue-fg\">,</span> node<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1579</span> \n\n<span class=\"ansi-green-fg\">/local_disk0/.ephemeral_nfs/envs/pythonEnv-1291aec0-13fd-49c0-a374-30251492cbed/lib/python3.7/site-packages/azureml/pipeline/steps/parallel_run_step.py</span> in <span class=\"ansi-cyan-fg\">create_node</span><span class=\"ansi-blue-fg\">(self, graph, default_datastore, context)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    170</span>         <span class=\"ansi-blue-fg\">:</span>rtype<span class=\"ansi-blue-fg\">:</span> azureml<span class=\"ansi-blue-fg\">.</span>pipeline<span class=\"ansi-blue-fg\">.</span>core<span class=\"ansi-blue-fg\">.</span>graph<span class=\"ansi-blue-fg\">.</span>Node\n<span class=\"ansi-green-intense-fg ansi-bold\">    171</span>         &#34;&#34;&#34;\n<span class=\"ansi-green-fg\">--&gt; 172</span><span class=\"ansi-red-fg\">         </span><span class=\"ansi-green-fg\">return</span> super<span class=\"ansi-blue-fg\">(</span>ParallelRunStep<span class=\"ansi-blue-fg\">,</span> self<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>create_node<span class=\"ansi-blue-fg\">(</span>graph<span class=\"ansi-blue-fg\">,</span> default_datastore<span class=\"ansi-blue-fg\">,</span> context<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    173</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    174</span>     def create_module_def(\n\n<span class=\"ansi-green-fg\">/local_disk0/.ephemeral_nfs/envs/pythonEnv-1291aec0-13fd-49c0-a374-30251492cbed/lib/python3.7/site-packages/azureml/pipeline/core/_parallel_run_step_base.py</span> in <span class=\"ansi-cyan-fg\">create_node</span><span class=\"ansi-blue-fg\">(self, graph, default_datastore, context)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    649</span>         <span class=\"ansi-blue-fg\">:</span>rtype<span class=\"ansi-blue-fg\">:</span> azureml<span class=\"ansi-blue-fg\">.</span>pipeline<span class=\"ansi-blue-fg\">.</span>core<span class=\"ansi-blue-fg\">.</span>graph<span class=\"ansi-blue-fg\">.</span>Node\n<span class=\"ansi-green-intense-fg ansi-bold\">    650</span>         &#34;&#34;&#34;\n<span class=\"ansi-green-fg\">--&gt; 651</span><span class=\"ansi-red-fg\">         </span>node <span class=\"ansi-blue-fg\">=</span> super<span class=\"ansi-blue-fg\">(</span>_ParallelRunStepBase<span class=\"ansi-blue-fg\">,</span> self<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>create_node<span class=\"ansi-blue-fg\">(</span>graph<span class=\"ansi-blue-fg\">,</span> default_datastore<span class=\"ansi-blue-fg\">,</span> context<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    652</span>         node<span class=\"ansi-blue-fg\">.</span>get_param<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;BatchInferencingMetaData&#34;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>set_value<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">.</span>_generate_batch_inference_metadata<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    653</span>         node<span class=\"ansi-blue-fg\">.</span>get_param<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;Script&#34;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>set_value<span class=\"ansi-blue-fg\">(</span>DEFAULT_BATCH_SCORE_MAIN_FILE_NAME<span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/local_disk0/.ephemeral_nfs/envs/pythonEnv-1291aec0-13fd-49c0-a374-30251492cbed/lib/python3.7/site-packages/azureml/pipeline/core/_python_script_step_base.py</span> in <span class=\"ansi-cyan-fg\">create_node</span><span class=\"ansi-blue-fg\">(self, graph, default_datastore, context)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    135</span>                                          compute_target_name<span class=\"ansi-blue-fg\">,</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    136</span>                                          compute_target_type<span class=\"ansi-blue-fg\">,</span>\n<span class=\"ansi-green-fg\">--&gt; 137</span><span class=\"ansi-red-fg\">                                          compute_target_object)\n</span><span class=\"ansi-green-intense-fg ansi-bold\">    138</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    139</span>         <span class=\"ansi-red-fg\"># set pipeline parameters on node and on graph</span>\n\n<span class=\"ansi-green-fg\">/local_disk0/.ephemeral_nfs/envs/pythonEnv-1291aec0-13fd-49c0-a374-30251492cbed/lib/python3.7/site-packages/azureml/pipeline/core/_python_script_step_base.py</span> in <span class=\"ansi-cyan-fg\">_set_compute_params_to_node</span><span class=\"ansi-blue-fg\">(self, node, compute_target_name, compute_target_type, compute_target_object)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    224</span>             node<span class=\"ansi-blue-fg\">=</span>node<span class=\"ansi-blue-fg\">,</span> target_name<span class=\"ansi-blue-fg\">=</span>compute_target_name<span class=\"ansi-blue-fg\">,</span> target_type<span class=\"ansi-blue-fg\">=</span>compute_target_type<span class=\"ansi-blue-fg\">,</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    225</span>             target_object<span class=\"ansi-blue-fg\">=</span>compute_target_object<span class=\"ansi-blue-fg\">,</span> script_name<span class=\"ansi-blue-fg\">=</span>self<span class=\"ansi-blue-fg\">.</span>_script_name<span class=\"ansi-blue-fg\">,</span> arguments<span class=\"ansi-blue-fg\">=</span>self<span class=\"ansi-blue-fg\">.</span>_resolved_arguments<span class=\"ansi-blue-fg\">,</span>\n<span class=\"ansi-green-fg\">--&gt; 226</span><span class=\"ansi-red-fg\">             runconfig_params={}, batchai_params=self._amlcompute_params)\n</span><span class=\"ansi-green-intense-fg ansi-bold\">    227</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    228</span>     <span class=\"ansi-green-fg\">def</span> _set_amlcompute_params<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">,</span> native_shared_directory<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-green-fg\">None</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/local_disk0/.ephemeral_nfs/envs/pythonEnv-1291aec0-13fd-49c0-a374-30251492cbed/lib/python3.7/site-packages/azureml/pipeline/core/_module_parameter_provider.py</span> in <span class=\"ansi-cyan-fg\">set_params_to_node</span><span class=\"ansi-blue-fg\">(self, node, target_name, target_type, target_object, script_name, arguments, runconfig_params, batchai_params)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    154</span>                     runconfig_params=None, compute_params=None)\n<span class=\"ansi-green-intense-fg ansi-bold\">    155</span>             <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 156</span><span class=\"ansi-red-fg\">                 </span><span class=\"ansi-green-fg\">raise</span> ValueError<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;Invalid compute target type: {0}&#34;</span><span class=\"ansi-blue-fg\">.</span>format<span class=\"ansi-blue-fg\">(</span>target_type<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    157</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    158</span>     <span class=\"ansi-green-fg\">def</span> _get_common_params_list<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-red-fg\">ValueError</span>: Invalid compute target type: Databricks</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# This will output information of the pipeline run, including the link to the details page of portal.\npipeline_run"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"111ded23-3fbd-4d32-af23-29d71eb44d8d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>batch_scoring</td><td>3df13f5a-5048-484e-8a45-a40881189ca3</td><td>azureml.PipelineRun</td><td>NotStarted</td><td><a href=\"https://ml.azure.com/experiments/batch_scoring/runs/3df13f5a-5048-484e-8a45-a40881189ca3?wsid=/subscriptions/d30d76c0-804c-4f4e-ab7b-509d06a49550/resourcegroups/vlk-workshop/workspaces/vlk-workspace\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>","textData":"<div class=\"ansiout\">Out[56]: </div>","removedWidgets":[],"addedWidgets":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>batch_scoring</td><td>3df13f5a-5048-484e-8a45-a40881189ca3</td><td>azureml.PipelineRun</td><td>NotStarted</td><td><a href=\"https://ml.azure.com/experiments/batch_scoring/runs/3df13f5a-5048-484e-8a45-a40881189ca3?wsid=/subscriptions/d30d76c0-804c-4f4e-ab7b-509d06a49550/resourcegroups/vlk-workshop/workspaces/vlk-workspace\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"]}}],"execution_count":0},{"cell_type":"code","source":["# Wait the run for completion and show output log to console\npipeline_run.wait_for_completion(show_output=True)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"95e0fa7c-8678-4816-8a3a-4f389ca9271a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">PipelineRunId: 3df13f5a-5048-484e-8a45-a40881189ca3\nLink to Azure Machine Learning Portal: https://ml.azure.com/experiments/batch_scoring/runs/3df13f5a-5048-484e-8a45-a40881189ca3?wsid=/subscriptions/d30d76c0-804c-4f4e-ab7b-509d06a49550/resourcegroups/vlk-workshop/workspaces/vlk-workspace\nPipelineRun Status: Running\n\n\nStepRunId: 70f76633-260a-4c25-967f-ea40e74b5983\nLink to Azure Machine Learning Portal: https://ml.azure.com/experiments/batch_scoring/runs/70f76633-260a-4c25-967f-ea40e74b5983?wsid=/subscriptions/d30d76c0-804c-4f4e-ab7b-509d06a49550/resourcegroups/vlk-workshop/workspaces/vlk-workspace\nStepRun( batchscoring-202011021034 ) Status: Queued\n\nStreaming azureml-logs/20_image_build_log.txt\n=============================================\n2020/11/02 10:37:01 Downloading source code...\n2020/11/02 10:37:02 Finished downloading source code\n2020/11/02 10:37:03 Creating Docker network: acb_default_network, driver: &#39;bridge&#39;\n2020/11/02 10:37:03 Successfully set up Docker network: acb_default_network\n2020/11/02 10:37:03 Setting up Docker configuration...\n2020/11/02 10:37:04 Successfully set up Docker configuration\n2020/11/02 10:37:04 Logging in to registry: f89c90464c5e495db4f6977a78dd3507.azurecr.io\n2020/11/02 10:37:05 Successfully logged into f89c90464c5e495db4f6977a78dd3507.azurecr.io\n2020/11/02 10:37:05 Executing step ID: acb_step_0. Timeout(sec): 5400, Working directory: &#39;&#39;, Network: &#39;acb_default_network&#39;\n2020/11/02 10:37:05 Scanning for dependencies...\n2020/11/02 10:37:06 Successfully scanned dependencies\n2020/11/02 10:37:06 Launching container with name: acb_step_0\nSending build context to Docker daemon  60.93kB\n\nStep 1/15 : FROM mcr.microsoft.com/azureml/intelmpi2018.3-cuda10.0-cudnn7-ubuntu16.04:20200821.v1@sha256:652cba03ef8fd4937111da0bc9f204a4310105e87b08eea322c1b55850169a49\nsha256:652cba03ef8fd4937111da0bc9f204a4310105e87b08eea322c1b55850169a49: Pulling from azureml/intelmpi2018.3-cuda10.0-cudnn7-ubuntu16.04\nf7277927d38a: Pulling fs layer\n8d3eac894db4: Pulling fs layer\nedf72af6d627: Pulling fs layer\n3e4f86211d23: Pulling fs layer\nd6e9603ff777: Pulling fs layer\n5cad422780e2: Pulling fs layer\n8130687c8acb: Pulling fs layer\nc11e9246d621: Pulling fs layer\n0dfae24cbbd9: Pulling fs layer\n0bb049a6d391: Pulling fs layer\n1aef3da5021b: Pulling fs layer\ne5f03d63d02d: Pulling fs layer\n22533bcd68c8: Pulling fs layer\na8c7deb5dc88: Pulling fs layer\nef34b1adad4d: Pulling fs layer\n87e1451a8ae7: Pulling fs layer\n6a5d94939972: Pulling fs layer\nf4b1ab4ce7b5: Pulling fs layer\n3e4f86211d23: Waiting\nd6e9603ff777: Waiting\n5cad422780e2: Waiting\n8130687c8acb: Waiting\nc11e9246d621: Waiting\n0dfae24cbbd9: Waiting\n0bb049a6d391: Waiting\n1aef3da5021b: Waiting\ne5f03d63d02d: Waiting\n22533bcd68c8: Waiting\na8c7deb5dc88: Waiting\nef34b1adad4d: Waiting\n87e1451a8ae7: Waiting\n6a5d94939972: Waiting\nf4b1ab4ce7b5: Waiting\nedf72af6d627: Verifying Checksum\nedf72af6d627: Download complete\n8d3eac894db4: Verifying Checksum\n8d3eac894db4: Download complete\n3e4f86211d23: Verifying Checksum\n3e4f86211d23: Download complete\nf7277927d38a: Verifying Checksum\nf7277927d38a: Download complete\nStepRun( batchscoring-202011021034 ) Status: Running\n8130687c8acb: Verifying Checksum\n8130687c8acb: Download complete\nd6e9603ff777: Verifying Checksum\nd6e9603ff777: Download complete\n5cad422780e2: Verifying Checksum\n5cad422780e2: Download complete\nf7277927d38a: Pull complete\n8d3eac894db4: Pull complete\nedf72af6d627: Pull complete\n3e4f86211d23: Pull complete\nd6e9603ff777: Pull complete\n5cad422780e2: Pull complete\n0dfae24cbbd9: Verifying Checksum\n0dfae24cbbd9: Download complete\nc11e9246d621: Verifying Checksum\nc11e9246d621: Download complete\n8130687c8acb: Pull complete\n1aef3da5021b: Verifying Checksum\n1aef3da5021b: Download complete\ne5f03d63d02d: Verifying Checksum\ne5f03d63d02d: Download complete\n22533bcd68c8: Verifying Checksum\n22533bcd68c8: Download complete\na8c7deb5dc88: Verifying Checksum\na8c7deb5dc88: Download complete\nef34b1adad4d: Verifying Checksum\nef34b1adad4d: Download complete\n6a5d94939972: Verifying Checksum\n6a5d94939972: Download complete\nf4b1ab4ce7b5: Verifying Checksum\nf4b1ab4ce7b5: Download complete\n87e1451a8ae7: Verifying Checksum\n87e1451a8ae7: Download complete\nc11e9246d621: Pull complete\n0bb049a6d391: Verifying Checksum\n0bb049a6d391: Download complete\n0dfae24cbbd9: Pull complete\n0bb049a6d391: Pull complete\n1aef3da5021b: Pull complete\ne5f03d63d02d: Pull complete\n22533bcd68c8: Pull complete\na8c7deb5dc88: Pull complete\nef34b1adad4d: Pull complete\n87e1451a8ae7: Pull complete\n6a5d94939972: Pull complete\nf4b1ab4ce7b5: Pull complete\nDigest: sha256:652cba03ef8fd4937111da0bc9f204a4310105e87b08eea322c1b55850169a49\nStatus: Downloaded newer image for mcr.microsoft.com/azureml/intelmpi2018.3-cuda10.0-cudnn7-ubuntu16.04:20200821.v1@sha256:652cba03ef8fd4937111da0bc9f204a4310105e87b08eea322c1b55850169a49\n ---&gt; 29d6cebaed25\nStep 2/15 : USER root\n ---&gt; Running in 78747f81016f\nRemoving intermediate container 78747f81016f\n ---&gt; 665c7b3bf6de\nStep 3/15 : RUN mkdir -p $HOME/.cache\n ---&gt; Running in 748432fdd497\nRemoving intermediate container 748432fdd497\n ---&gt; 7f57bdb4f3e9\nStep 4/15 : WORKDIR /\n ---&gt; Running in 684bedece0d4\nRemoving intermediate container 684bedece0d4\n ---&gt; a983f36cb6db\nStep 5/15 : COPY azureml-environment-setup/99brokenproxy /etc/apt/apt.conf.d/\n ---&gt; 08b03e5ec9a6\nStep 6/15 : RUN if dpkg --compare-versions `conda --version | grep -oE &#39;[^ ]+$&#39;` lt 4.4.11; then conda install conda==4.4.11; fi\n ---&gt; Running in 481ab1be7299\nRemoving intermediate container 481ab1be7299\n ---&gt; 397570faff82\nStep 7/15 : COPY azureml-environment-setup/mutated_conda_dependencies.yml azureml-environment-setup/mutated_conda_dependencies.yml\n ---&gt; a7a2554410d2\nStep 8/15 : RUN ldconfig /usr/local/cuda/lib64/stubs &amp;&amp; conda env create -p /azureml-envs/azureml_2fedf4d8b9700d1bbb353b132ff1f6aa -f azureml-environment-setup/mutated_conda_dependencies.yml &amp;&amp; rm -rf &#34;$HOME/.cache/pip&#34; &amp;&amp; conda clean -aqy &amp;&amp; CONDA_ROOT_DIR=$(conda info --root) &amp;&amp; rm -rf &#34;$CONDA_ROOT_DIR/pkgs&#34; &amp;&amp; find &#34;$CONDA_ROOT_DIR&#34; -type d -name __pycache__ -exec rm -rf {} + &amp;&amp; ldconfig\n ---&gt; Running in 5a08d5ad92d1\nWarning: you have pip-installed dependencies in your environment file, but you do not list pip itself as one of your conda dependencies.  Conda may not use the correct pip to install your packages, and they may end up in the wrong place.  Please add an explicit pip dependency.  I&#39;m adding one for you, but still nagging you.\nCollecting package metadata (repodata.json): ...working... \ndone\nSolving environment: ...working... done\n\nDownloading and Extracting Packages\n\nopenssl-1.0.2u       | 3.1 MB    |            |   0% \nopenssl-1.0.2u       | 3.1 MB    | ####1      |  41% \nopenssl-1.0.2u       | 3.1 MB    | ########## | 100% \n\nlibffi-3.2.1         | 52 KB     |            |   0% \nlibffi-3.2.1         | 52 KB     | ########## | 100% \n\nzlib-1.2.11          | 120 KB    |            |   0% \nzlib-1.2.11          | 120 KB    | ########## | 100% \n\npython-3.6.2         | 27.0 MB   |            |   0% \npython-3.6.2         | 27.0 MB   | ##5        |  26% \npython-3.6.2         | 27.0 MB   | #####7     |  58% \npython-3.6.2         | 27.0 MB   | #########5 |  96% \npython-3.6.2         | 27.0 MB   | ########## | 100% \n\nsetuptools-50.3.0    | 891 KB    |            |   0% \nsetuptools-50.3.0    | 891 KB    | ########## | 100% \n\npip-20.2.4           | 2.0 MB    |            |   0% \npip-20.2.4           | 2.0 MB    | ########## | 100% \n\ncertifi-2020.6.20    | 160 KB    |            |   0% \ncertifi-2020.6.20    | 160 KB    | ########## | 100% \n\ntk-8.6.10            | 3.2 MB    |            |   0% \ntk-8.6.10            | 3.2 MB    | ########## | 100% \n\nsqlite-3.23.1        | 1.5 MB    |            |   0% \nsqlite-3.23.1        | 1.5 MB    | ########## | 100% \n\nlibstdcxx-ng-9.1.0   | 4.0 MB    |            |   0% \nlibstdcxx-ng-9.1.0   | 4.0 MB    | #4         |  14% \nlibstdcxx-ng-9.1.0   | 4.0 MB    | ########## | 100% \n\nlibgcc-ng-9.1.0      | 8.1 MB    |            |   0% \nlibgcc-ng-9.1.0      | 8.1 MB    | ######6    |  66% \nlibgcc-ng-9.1.0      | 8.1 MB    | ########## | 100% \n\nlibedit-3.1          | 171 KB    |            |   0% \nlibedit-3.1          | 171 KB    | ########## | 100% \n\nxz-5.2.5             | 438 KB    |            |   0% \nxz-5.2.5             | 438 KB    | ########## | 100% \n\nreadline-7.0         | 387 KB    |            |   0% \nreadline-7.0         | 387 KB    | ########## | 100% \n\nwheel-0.35.1         | 36 KB     |            |   0% \nwheel-0.35.1         | 36 KB     | ########## | 100% \n\nncurses-6.0          | 907 KB    |            |   0% \nncurses-6.0          | 907 KB    | ########## | 100% \n\nca-certificates-2020 | 128 KB    |            |   0% \nca-certificates-2020 | 128 KB    | ########## | 100% \nPreparing transaction: ...working... done\nVerifying transaction: ...working... done\nExecuting transaction: ...working... done\nRan pip subprocess with arguments:\n[&#39;/azureml-envs/azureml_2fedf4d8b9700d1bbb353b132ff1f6aa/bin/python&#39;, &#39;-m&#39;, &#39;pip&#39;, &#39;install&#39;, &#39;-U&#39;, &#39;-r&#39;, &#39;/azureml-environment-setup/condaenv.7zmp26kf.requirements.txt&#39;]\nPip subprocess output:\nCollecting tensorflow-gpu==1.15.2\n  Downloading tensorflow_gpu-1.15.2-cp36-cp36m-manylinux2010_x86_64.whl (411.0 MB)\nCollecting azureml-core~=1.17.0\n  Downloading azureml_core-1.17.0-py3-none-any.whl (2.1 MB)\nCollecting azureml-dataset-runtime[fuse]~=1.17.0\n  Downloading azureml_dataset_runtime-1.17.0-py3-none-any.whl (3.4 kB)\nCollecting six&gt;=1.10.0\n  Downloading six-1.15.0-py2.py3-none-any.whl (10 kB)\nCollecting termcolor&gt;=1.1.0\n  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\nRequirement already satisfied, skipping upgrade: wheel&gt;=0.26; python_version &gt;= &#34;3&#34; in /azureml-envs/azureml_2fedf4d8b9700d1bbb353b132ff1f6aa/lib/python3.6/site-packages (from tensorflow-gpu==1.15.2-&gt;-r /azureml-environment-setup/condaenv.7zmp26kf.requirements.txt (line 1)) (0.35.1)\nCollecting keras-applications&gt;=1.0.8\n  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\nCollecting tensorflow-estimator==1.15.1\n  Downloading tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\nCollecting numpy&lt;2.0,&gt;=1.16.0\n  Downloading numpy-1.19.3-cp36-cp36m-manylinux2010_x86_64.whl (14.9 MB)\nCollecting protobuf&gt;=3.6.1\n  Downloading protobuf-3.13.0-cp36-cp36m-manylinux1_x86_64.whl (1.3 MB)\nCollecting tensorboard&lt;1.16.0,&gt;=1.15.0\n  Downloading tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\nCollecting gast==0.2.2\n  Downloading gast-0.2.2.tar.gz (10 kB)\nCollecting google-pasta&gt;=0.1.6\n  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\nCollecting wrapt&gt;=1.11.1\n  Downloading wrapt-1.12.1.tar.gz (27 kB)\nCollecting astor&gt;=0.6.0\n  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\nCollecting keras-preprocessing&gt;=1.0.5\n  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\nCollecting opt-einsum&gt;=2.3.2\n  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\nCollecting grpcio&gt;=1.8.6\n  Downloading grpcio-1.33.2-cp36-cp36m-manylinux2014_x86_64.whl (3.8 MB)\nCollecting absl-py&gt;=0.7.0\n  Downloading absl_py-0.11.0-py3-none-any.whl (127 kB)\nCollecting azure-mgmt-authorization&lt;1.0.0,&gt;=0.40.0\n  Downloading azure_mgmt_authorization-0.61.0-py2.py3-none-any.whl (94 kB)\nCollecting ndg-httpsclient\n  Downloading ndg_httpsclient-0.5.1-py3-none-any.whl (34 kB)\nCollecting pathspec\n  Downloading pathspec-0.8.0-py2.py3-none-any.whl (28 kB)\nCollecting python-dateutil&gt;=2.7.3\n  Downloading python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB)\nCollecting azure-common&gt;=1.1.12\n  Downloading azure_common-1.1.25-py2.py3-none-any.whl (12 kB)\nCollecting docker\n  Downloading docker-4.3.1-py2.py3-none-any.whl (145 kB)\nCollecting pyopenssl&lt;20.0.0\n  Downloading pyOpenSSL-19.1.0-py2.py3-none-any.whl (53 kB)\nCollecting azure-mgmt-containerregistry&gt;=2.0.0\n  Downloading azure_mgmt_containerregistry-2.8.0-py2.py3-none-any.whl (718 kB)\nCollecting azure-mgmt-storage&lt;16.0.0,&gt;=1.5.0\n  Downloading azure_mgmt_storage-11.2.0-py2.py3-none-any.whl (547 kB)\nCollecting PyJWT\n  Downloading PyJWT-1.7.1-py2.py3-none-any.whl (18 kB)\nCollecting backports.tempfile\n  Downloading backports.tempfile-1.0-py2.py3-none-any.whl (4.4 kB)\nCollecting requests&gt;=2.19.1\n  Downloading requests-2.24.0-py2.py3-none-any.whl (61 kB)\nCollecting jmespath\n  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\nCollecting azure-graphrbac&lt;1.0.0,&gt;=0.40.0\n  Downloading azure_graphrbac-0.61.1-py2.py3-none-any.whl (141 kB)\nCollecting jsonpickle\n  Downloading jsonpickle-1.4.1-py2.py3-none-any.whl (36 kB)\nCollecting adal&gt;=1.2.0\n  Downloading adal-1.2.5-py2.py3-none-any.whl (55 kB)\nCollecting SecretStorage\n  Downloading SecretStorage-3.1.2-py3-none-any.whl (14 kB)\nCollecting pytz\n  Downloading pytz-2020.4-py2.py3-none-any.whl (509 kB)\nCollecting azure-mgmt-keyvault&lt;7.0.0,&gt;=0.40.0\n  Downloading azure_mgmt_keyvault-2.2.0-py2.py3-none-any.whl (89 kB)\nCollecting azure-mgmt-resource&lt;15.0.0,&gt;=1.2.1\n  Downloading azure_mgmt_resource-10.3.0-py2.py3-none-any.whl (1.0 MB)\nCollecting urllib3&gt;=1.23\n  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\nCollecting cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*\n  Downloading cryptography-3.2.1-cp35-abi3-manylinux2010_x86_64.whl (2.6 MB)\nCollecting msrest&gt;=0.5.1\n  Downloading msrest-0.6.19-py2.py3-none-any.whl (84 kB)\nCollecting msrestazure&gt;=0.4.33\n  Downloading msrestazure-0.6.4-py2.py3-none-any.whl (40 kB)\nCollecting contextlib2\n  Downloading contextlib2-0.6.0.post1-py2.py3-none-any.whl (9.8 kB)\nCollecting ruamel.yaml&gt;=0.15.35\n  Downloading ruamel.yaml-0.16.12-py2.py3-none-any.whl (111 kB)\nCollecting azureml-dataprep&lt;2.5.0a,&gt;=2.4.0a\n  Downloading azureml_dataprep-2.4.2-py3-none-any.whl (28.2 MB)\nCollecting pyarrow&lt;2.0.0,&gt;=0.17.0\n  Downloading pyarrow-1.0.1-cp36-cp36m-manylinux2014_x86_64.whl (17.3 MB)\nCollecting fusepy&lt;4.0.0,&gt;=3.0.1; extra == &#34;fuse&#34;\n  Downloading fusepy-3.0.1.tar.gz (11 kB)\nCollecting h5py\n  Downloading h5py-3.0.0-cp36-cp36m-manylinux1_x86_64.whl (4.0 MB)\nRequirement already satisfied, skipping upgrade: setuptools in /azureml-envs/azureml_2fedf4d8b9700d1bbb353b132ff1f6aa/lib/python3.6/site-packages (from protobuf&gt;=3.6.1-&gt;tensorflow-gpu==1.15.2-&gt;-r /azureml-environment-setup/condaenv.7zmp26kf.requirements.txt (line 1)) (50.3.0.post20201006)\nCollecting markdown&gt;=2.6.8\n  Downloading Markdown-3.3.3-py3-none-any.whl (96 kB)\nCollecting werkzeug&gt;=0.11.15\n  Downloading Werkzeug-1.0.1-py2.py3-none-any.whl (298 kB)\nCollecting pyasn1&gt;=0.1.1\n  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\nCollecting websocket-client&gt;=0.32.0\n  Downloading websocket_client-0.57.0-py2.py3-none-any.whl (200 kB)\nCollecting backports.weakref\n  Downloading backports.weakref-1.0.post1-py2.py3-none-any.whl (5.2 kB)\nRequirement already satisfied, skipping upgrade: certifi&gt;=2017.4.17 in /azureml-envs/azureml_2fedf4d8b9700d1bbb353b132ff1f6aa/lib/python3.6/site-packages (from requests&gt;=2.19.1-&gt;azureml-core~=1.17.0-&gt;-r /azureml-environment-setup/condaenv.7zmp26kf.requirements.txt (line 2)) (2020.6.20)\nCollecting chardet&lt;4,&gt;=3.0.2\n  Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\nCollecting idna&lt;3,&gt;=2.5\n  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\nCollecting importlib-metadata\n  Downloading importlib_metadata-2.0.0-py2.py3-none-any.whl (31 kB)\nCollecting jeepney&gt;=0.4.2\n  Downloading jeepney-0.4.3-py3-none-any.whl (21 kB)\nCollecting cffi!=1.11.3,&gt;=1.8\n  Downloading cffi-1.14.3-cp36-cp36m-manylinux1_x86_64.whl (400 kB)\nCollecting requests-oauthlib&gt;=0.5.0\n  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\nCollecting isodate&gt;=0.6.0\n  Downloading isodate-0.6.0-py2.py3-none-any.whl (45 kB)\nCollecting ruamel.yaml.clib&gt;=0.1.2; platform_python_implementation == &#34;CPython&#34; and python_version &lt; &#34;3.9&#34;\n  Downloading ruamel.yaml.clib-0.2.2-cp36-cp36m-manylinux1_x86_64.whl (549 kB)\nCollecting dotnetcore2&lt;3.0.0,&gt;=2.1.14\n  Downloading dotnetcore2-2.1.17-py3-none-manylinux1_x86_64.whl (28.7 MB)\nCollecting cloudpickle&lt;2.0.0,&gt;=1.1.0\n  Downloading cloudpickle-1.6.0-py3-none-any.whl (23 kB)\nCollecting azure-identity&lt;2.0.0,&gt;=1.2.0\n  Downloading azure_identity-1.4.1-py2.py3-none-any.whl (86 kB)\nCollecting azureml-dataprep-rslex&lt;1.3.0a,&gt;=1.2.0dev0\n  Downloading azureml_dataprep_rslex-1.2.2-cp36-cp36m-manylinux2010_x86_64.whl (7.9 MB)\nCollecting azureml-dataprep-native&lt;25.0.0,&gt;=24.0.0\n  Downloading azureml_dataprep_native-24.0.0-cp36-cp36m-manylinux1_x86_64.whl (1.3 MB)\nCollecting cached-property\n  Downloading cached_property-1.5.2-py2.py3-none-any.whl (7.6 kB)\nCollecting zipp&gt;=0.5\n  Downloading zipp-3.4.0-py3-none-any.whl (5.2 kB)\nCollecting pycparser\n  Downloading pycparser-2.20-py2.py3-none-any.whl (112 kB)\nCollecting oauthlib&gt;=3.0.0\n  Downloading oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\nCollecting distro&gt;=1.2.0\n  Downloading distro-1.5.0-py2.py3-none-any.whl (18 kB)\nCollecting msal-extensions~=0.2.2\n  Downloading msal_extensions-0.2.2-py2.py3-none-any.whl (15 kB)\nCollecting azure-core&lt;2.0.0,&gt;=1.0.0\n  Downloading azure_core-1.8.2-py2.py3-none-any.whl (122 kB)\nCollecting msal&lt;2.0.0,&gt;=1.3.0\n  Downloading msal-1.6.0-py2.py3-none-any.whl (50 kB)\nCollecting portalocker~=1.0; platform_system != &#34;Windows&#34;\n  Downloading portalocker-1.7.1-py2.py3-none-any.whl (10 kB)\nBuilding wheels for collected packages: termcolor, gast, wrapt, fusepy\n  Building wheel for termcolor (setup.py): started\n  Building wheel for termcolor (setup.py): finished with status &#39;done&#39;\n  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4830 sha256=022d8a0b15fc3622a9852a09ef0407b34a011c08b6dbb24bfc52b6c0e4f2e61d\n  Stored in directory: /root/.cache/pip/wheels/93/2a/eb/e58dbcbc963549ee4f065ff80a59f274cc7210b6eab962acdc\n  Building wheel for gast (setup.py): started\n  Building wheel for gast (setup.py): finished with status &#39;done&#39;\n  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7540 sha256=cd0cedf226cb199609d0903ffcd0eccbb4e27b0bcf76b64618a87d404bb66eba\n  Stored in directory: /root/.cache/pip/wheels/19/a7/b9/0740c7a3a7d1d348f04823339274b90de25fbcd217b2ee1fbe\n  Building wheel for wrapt (setup.py): started\n  Building wheel for wrapt (setup.py): finished with status &#39;done&#39;\n  Created wheel for wrapt: filename=wrapt-1.12.1-cp36-cp36m-linux_x86_64.whl size=66285 sha256=932d29c4b04875ab9b0d3cd25e3eb63f05973503c42288042e10808aa99dd5ed\n  Stored in directory: /root/.cache/pip/wheels/32/42/7f/23cae9ff6ef66798d00dc5d659088e57dbba01566f6c60db63\n  Building wheel for fusepy (setup.py): started\n  Building wheel for fusepy (setup.py): finished with status &#39;done&#39;\n  Created wheel for fusepy: filename=fusepy-3.0.1-py3-none-any.whl size=10504 sha256=0f37d1c1dd3c3dc088aa1fa8cf981063d964e402bf81a997f3b0b6808d5858f1\n  Stored in directory: /root/.cache/pip/wheels/21/5c/83/1dd7e8a232d12227e5410120f4374b33adeb4037473105b079\nSuccessfully built termcolor gast wrapt fusepy\nInstalling collected packages: six, termcolor, numpy, cached-property, h5py, keras-applications, tensorflow-estimator, protobuf, absl-py, zipp, importlib-metadata, markdown, grpcio, werkzeug, tensorboard, gast, google-pasta, wrapt, astor, keras-preprocessing, opt-einsum, tensorflow-gpu, chardet, idna, urllib3, requests, oauthlib, requests-oauthlib, isodate, msrest, python-dateutil, PyJWT, pycparser, cffi, cryptography, adal, msrestazure, azure-common, azure-mgmt-authorization, pyopenssl, pyasn1, ndg-httpsclient, pathspec, websocket-client, docker, azure-mgmt-containerregistry, azure-mgmt-storage, backports.weakref, backports.tempfile, jmespath, azure-graphrbac, jsonpickle, jeepney, SecretStorage, pytz, azure-mgmt-keyvault, azure-mgmt-resource, contextlib2, ruamel.yaml.clib, ruamel.yaml, azureml-core, distro, dotnetcore2, cloudpickle, portalocker, msal, msal-extensions, azure-core, azure-identity, azureml-dataprep-rslex, azureml-dataprep-native, azureml-dataprep, pyarrow, fusepy, azureml-dataset-runtime\nSuccessfully installed PyJWT-1.7.1 SecretStorage-3.1.2 absl-py-0.11.0 adal-1.2.5 astor-0.8.1 azure-common-1.1.25 azure-core-1.8.2 azure-graphrbac-0.61.1 azure-identity-1.4.1 azure-mgmt-authorization-0.61.0 azure-mgmt-containerregistry-2.8.0 azure-mgmt-keyvault-2.2.0 azure-mgmt-resource-10.3.0 azure-mgmt-storage-11.2.0 azureml-core-1.17.0 azureml-dataprep-2.4.2 azureml-dataprep-native-24.0.0 azureml-dataprep-rslex-1.2.2 azureml-dataset-runtime-1.17.0 backports.tempfile-1.0 backports.weakref-1.0.post1 cached-property-1.5.2 cffi-1.14.3 chardet-3.0.4 cloudpickle-1.6.0 contextlib2-0.6.0.post1 cryptography-3.2.1 distro-1.5.0 docker-4.3.1 dotnetcore2-2.1.17 fusepy-3.0.1 gast-0.2.2 google-pasta-0.2.0 grpcio-1.33.2 h5py-3.0.0 idna-2.10 importlib-metadata-2.0.0 isodate-0.6.0 jeepney-0.4.3 jmespath-0.10.0 jsonpickle-1.4.1 keras-applications-1.0.8 keras-preprocessing-1.1.2 markdown-3.3.3 msal-1.6.0 msal-extensions-0.2.2 msrest-0.6.19 msrestazure-0.6.4 ndg-httpsclient-0.5.1 numpy-1.19.3 oauthlib-3.1.0 opt-einsum-3.3.0 pathspec-0.8.0 portalocker-1.7.1 protobuf-3.13.0 pyarrow-1.0.1 pyasn1-0.4.8 pycparser-2.20 pyopenssl-19.1.0 python-dateutil-2.8.1 pytz-2020.4 requests-2.24.0 requests-oauthlib-1.3.0 ruamel.yaml-0.16.12 ruamel.yaml.clib-0.2.2 six-1.15.0 tensorboard-1.15.0 tensorflow-estimator-1.15.1 tensorflow-gpu-1.15.2 termcolor-1.1.0 urllib3-1.25.11 websocket-client-0.57.0 werkzeug-1.0.1 wrapt-1.12.1 zipp-3.4.0\n\n#\n# To activate this environment, use\n#\n#     $ conda activate /azureml-envs/azureml_2fedf4d8b9700d1bbb353b132ff1f6aa\n#\n# To deactivate an active environment, use\n#\n#     $ conda deactivate\n\n<span class=\"ansi-red-intense-fg\">\n\n==&gt; WARNING: A newer version of conda exists. &lt;==\n  current version: 4.7.12\n  latest version: 4.9.1\n\nPlease update conda by running\n\n    $ conda update -n base -c defaults conda\n\n\n</span>WARNING: /root/.conda/pkgs does not exist\nRemoving intermediate container 5a08d5ad92d1\n ---&gt; 138c6bd3f1fb\nStep 9/15 : ENV PATH /azureml-envs/azureml_2fedf4d8b9700d1bbb353b132ff1f6aa/bin:$PATH\n ---&gt; Running in 33817c39b9bc\nRemoving intermediate container 33817c39b9bc\n ---&gt; 770a4379dec3\nStep 10/15 : ENV AZUREML_CONDA_ENVIRONMENT_PATH /azureml-envs/azureml_2fedf4d8b9700d1bbb353b132ff1f6aa\n ---&gt; Running in be865e788ecc\nRemoving intermediate container be865e788ecc\n ---&gt; d7b056ee2442\nStep 11/15 : ENV LD_LIBRARY_PATH /azureml-envs/azureml_2fedf4d8b9700d1bbb353b132ff1f6aa/lib:$LD_LIBRARY_PATH\n ---&gt; Running in 236a9a2995aa\nRemoving intermediate container 236a9a2995aa\n ---&gt; a762b124dfcd\nStep 12/15 : COPY azureml-environment-setup/spark_cache.py azureml-environment-setup/log4j.properties /azureml-environment-setup/\n ---&gt; fd0ebe6f9b49\nStep 13/15 : RUN if [ $SPARK_HOME ]; then /bin/bash -c &#39;$SPARK_HOME/bin/spark-submit  /azureml-environment-setup/spark_cache.py&#39;; fi\n ---&gt; Running in f45e1c367978\nRemoving intermediate container f45e1c367978\n ---&gt; a24f18d7db04\nStep 14/15 : ENV AZUREML_ENVIRONMENT_IMAGE True\n ---&gt; Running in 078f3261fac6\nRemoving intermediate container 078f3261fac6\n ---&gt; a51ffcb1acb1\nStep 15/15 : CMD [&#34;bash&#34;]\n ---&gt; Running in 7244718b5877\nRemoving intermediate container 7244718b5877\n ---&gt; 05c914e56f6c\nSuccessfully built 05c914e56f6c\nSuccessfully tagged f89c90464c5e495db4f6977a78dd3507.azurecr.io/azureml/azureml_2c0e7677eec783da9d8011e7f71bebe0:latest\n2020/11/02 10:41:30 Successfully executed container: acb_step_0\n2020/11/02 10:41:30 Executing step ID: acb_step_1. Timeout(sec): 5400, Working directory: &#39;&#39;, Network: &#39;acb_default_network&#39;\n2020/11/02 10:41:30 Pushing image: f89c90464c5e495db4f6977a78dd3507.azurecr.io/azureml/azureml_2c0e7677eec783da9d8011e7f71bebe0:latest, attempt 1\nThe push refers to repository [f89c90464c5e495db4f6977a78dd3507.azurecr.io/azureml/azureml_2c0e7677eec783da9d8011e7f71bebe0]\n5df860bd05f6: Preparing\na6657ca722c4: Preparing\nce9c01a1f34d: Preparing\nbbe4b2423595: Preparing\n696ca92ec92b: Preparing\n505490c18935: Preparing\n80e085142144: Preparing\n3d69c415d1f0: Preparing\ncf59bc701d30: Preparing\n3cf57cc1b3bc: Preparing\n019f14bc11c8: Preparing\n1f16665d954b: Preparing\na0c9064424e4: Preparing\n12d67fac46a2: Preparing\nc36fc92de581: Preparing\n524881d0563d: Preparing\nd05c249e6b9f: Preparing\nfc8a172f94e8: Preparing\n48001c8a7ddb: Preparing\n6dce9683cb41: Preparing\ne79142719515: Preparing\naeda103e78c9: Preparing\n2558e637fbff: Preparing\nf749b9b0fb21: Preparing\n505490c18935: Waiting\n80e085142144: Waiting\n3d69c415d1f0: Waiting\ncf59bc701d30: Waiting\n3cf57cc1b3bc: Waiting\n019f14bc11c8: Waiting\n1f16665d954b: Waiting\n12d67fac46a2: Waiting\nc36fc92de581: Waiting\n524881d0563d: Waiting\nd05c249e6b9f: Waiting\nfc8a172f94e8: Waiting\n48001c8a7ddb: Waiting\n6dce9683cb41: Waiting\ne79142719515: Waiting\naeda103e78c9: Waiting\n2558e637fbff: Waiting\nf749b9b0fb21: Waiting\nce9c01a1f34d: Pushed\n696ca92ec92b: Pushed\n5df860bd05f6: Pushed\nbbe4b2423595: Pushed\n505490c18935: Pushed\n80e085142144: Pushed\n3d69c415d1f0: Pushed\ncf59bc701d30: Pushed\na0c9064424e4: Pushed\n1f16665d954b: Pushed\n12d67fac46a2: Pushed\n\n3cf57cc1b3bc: Pushed\n019f14bc11c8: Pushed\nfc8a172f94e8: Pushed\n48001c8a7ddb: Pushed\n6dce9683cb41: Pushed\ne79142719515: Pushed\naeda103e78c9: Pushed\n2558e637fbff: Pushed\nc36fc92de581: Pushed\nd05c249e6b9f: Pushed\nf749b9b0fb21: Pushed\n\na6657ca722c4: Pushed\n524881d0563d: Pushed\n\n*** WARNING: skipped 4348 bytes of output ***\n\n0bb981bf8833: Verifying Checksum\n0bb981bf8833: Download complete\necaf719dacef: Download complete\n8996db0c4475: Verifying Checksum\n8996db0c4475: Download complete\n2e8512ab6543: Verifying Checksum\n2e8512ab6543: Download complete\nc11e9246d621: Pull complete\n0dfae24cbbd9: Pull complete\n0bb049a6d391: Pull complete\n1aef3da5021b: Pull complete\ne5f03d63d02d: Pull complete\n22533bcd68c8: Pull complete\na8c7deb5dc88: Pull complete\nef34b1adad4d: Pull complete\n87e1451a8ae7: Pull complete\n6a5d94939972: Pull complete\nf4b1ab4ce7b5: Pull complete\n9064eac28188: Pull complete\nad08533d07ce: Pull complete\necaf719dacef: Pull complete\n0bb981bf8833: Pull complete\n\nStreaming azureml-logs/65_job_prep-tvmps_0092ff0627db1719f1dc92ad318b9b246d39f255767ec5d408b3a9d4f88afe26_p.txt\n===============================================================================================================\n[2020-11-02T10:52:50.507766] Entering job preparation.\n[2020-11-02T10:52:51.805589] Starting job preparation.\n[2020-11-02T10:52:51.805626] Extracting the control code.\n[2020-11-02T10:52:51.854715] fetching and extracting the control code on master node.\n[2020-11-02T10:52:51.854742] Starting extract_project.\n[2020-11-02T10:52:51.854779] Starting to extract zip file.\n[2020-11-02T10:52:53.087080] Finished extracting zip file.\n[2020-11-02T10:52:53.381240] Using urllib.request Python 3.0 or later\n[2020-11-02T10:52:53.381285] Start fetching snapshots.\n[2020-11-02T10:52:53.381324] Start fetching snapshot.\n[2020-11-02T10:52:53.381340] Retrieving project from snapshot: bc4707f2-8238-4b2b-8245-721624425091\nStarting the daemon thread to refresh tokens in background for process with pid = 62\n[2020-11-02T10:52:53.821346] Finished fetching snapshot.\n[2020-11-02T10:52:53.821369] Start fetching snapshot.\n[2020-11-02T10:52:53.821382] Retrieving project from snapshot: 0d50123e-1570-4370-b7cf-aa0e648e06a9\n[2020-11-02T10:53:02.588200] Finished fetching snapshot.\n[2020-11-02T10:53:02.588231] Finished fetching snapshots.\n[2020-11-02T10:53:02.588242] Finished extract_project.\n[2020-11-02T10:53:02.619785] Finished fetching and extracting the control code.\n[2020-11-02T10:53:02.622165] downloadDataStore - Download from datastores if requested.\n[2020-11-02T10:53:02.623023] Start run_history_prep.\n[2020-11-02T10:53:02.702578] Entering context manager injector.\nAcquired lockfile /tmp/70f76633-260a-4c25-967f-ea40e74b5983-datastore.lock to downloading input data references\n[2020-11-02T10:53:03.951917] downloadDataStore completed\n[2020-11-02T10:53:03.954753] Job preparation is complete.\n\nStreaming azureml-logs/70_driver_log.txt\n========================================\n2020/11/02 10:53:05 logger.go:297: Attempt 1 of http call to http://10.0.0.5:16384/sendlogstoartifacts/info\n2020/11/02 10:53:05 logger.go:297: Attempt 1 of http call to http://10.0.0.5:16384/sendlogstoartifacts/status\n[2020-11-02T10:53:06.860730] Entering context manager injector.\n[context_manager_injector.py] Command line Options: Namespace(inject=[&#39;ProjectPythonPath:context_managers.ProjectPythonPath&#39;, &#39;Dataset:context_managers.Datasets&#39;, &#39;RunHistory:context_managers.RunHistory&#39;, &#39;TrackUserError:context_managers.TrackUserError&#39;, &#39;UserExceptions:context_managers.UserExceptions&#39;], invocation=[&#39;driver/amlbi_main.py&#39;, &#39;--client_sdk_version&#39;, &#39;1.17.0&#39;, &#39;--scoring_module_name&#39;, &#39;batch_scoring.py&#39;, &#39;--mini_batch_size&#39;, &#39;20&#39;, &#39;--error_threshold&#39;, &#39;1&#39;, &#39;--output_action&#39;, &#39;append_row&#39;, &#39;--logging_level&#39;, &#39;INFO&#39;, &#39;--run_invocation_timeout&#39;, &#39;60&#39;, &#39;--run_max_try&#39;, &#39;3&#39;, &#39;--create_snapshot_at_runtime&#39;, &#39;True&#39;, &#39;--append_row_file_name&#39;, &#39;parallel_run_step.txt&#39;, &#39;--output&#39;, &#39;/mnt/batch/tasks/shared/LS_root/jobs/vlk-workspace/azureml/70f76633-260a-4c25-967f-ea40e74b5983/mounts/workspaceblobstore/azureml/70f76633-260a-4c25-967f-ea40e74b5983/scores&#39;, &#39;--process_count_per_node&#39;, &#39;2&#39;, &#39;--model_name&#39;, &#39;inception&#39;, &#39;--labels_dir&#39;, &#39;DatasetConsumptionConfig:labels_input&#39;, &#39;--input_fds_0&#39;, &#39;input_images&#39;])\nInitialize DatasetContextManager.\nStarting the daemon thread to refresh tokens in background for process with pid = 128\nSet Dataset input_images&#39;s target path to /tmp/tmp0uzkd6at\nSet Dataset labels_input&#39;s target path to /tmp/tmp0z68irne\nEnter __enter__ of DatasetContextManager\nSDK version: azureml-core==1.17.0 azureml-dataprep==2.4.2. Session id: 0b50dba5-af29-45f5-85b5-ff2d852661e5. Run id: 70f76633-260a-4c25-967f-ea40e74b5983.\nProcessing &#39;input_images&#39;.\nProcessing dataset FileDataset\n{\n  &#34;source&#34;: [\n    &#34;(&#39;images_datastore&#39;, &#39;batchscoring/images/&#39;)&#34;\n  ],\n  &#34;definition&#34;: [\n    &#34;GetDatastoreFiles&#34;\n  ],\n  &#34;registration&#34;: {\n    &#34;id&#34;: &#34;6b7aefe9-2af6-494d-9ec6-7455fefdbcde&#34;,\n    &#34;name&#34;: &#34;input_images&#34;,\n    &#34;version&#34;: 1,\n    &#34;workspace&#34;: &#34;Workspace.create(name=&#39;vlk-workspace&#39;, subscription_id=&#39;d30d76c0-804c-4f4e-ab7b-509d06a49550&#39;, resource_group=&#39;vlk-workshop&#39;)&#34;\n  }\n}\nMounting input_images to /tmp/tmp0uzkd6at.\nCannot find cached workspace due to: KeyError(&#39;d30d76c0-804c-4f4e-ab7b-509d06a49550vlk-workshopvlk-workspace&#39;,)\nMounted input_images to /tmp/tmp0uzkd6at as folder.\nProcessing &#39;labels_input&#39;.\nProcessing dataset FileDataset\n{\n  &#34;source&#34;: [\n    &#34;(&#39;images_datastore&#39;, &#39;batchscoring/labels/&#39;)&#34;\n  ],\n  &#34;definition&#34;: [\n    &#34;GetDatastoreFiles&#34;\n  ],\n  &#34;registration&#34;: {\n    &#34;id&#34;: &#34;a091a995-2e8c-4def-806d-e4f1a40478a6&#34;,\n    &#34;name&#34;: &#34;label_ds&#34;,\n    &#34;version&#34;: 1,\n    &#34;workspace&#34;: &#34;Workspace.create(name=&#39;vlk-workspace&#39;, subscription_id=&#39;d30d76c0-804c-4f4e-ab7b-509d06a49550&#39;, resource_group=&#39;vlk-workshop&#39;)&#34;\n  }\n}\nMounting labels_input to /tmp/tmp0z68irne.\nWARNING - Already registered authentication for run id: 70f76633-260a-4c25-967f-ea40e74b5983\nCannot find cached workspace due to: KeyError(&#39;d30d76c0-804c-4f4e-ab7b-509d06a49550vlk-workshopvlk-workspace&#39;,)\nMounted labels_input to /tmp/tmp0z68irne as folder.\nExit __enter__ of DatasetContextManager\nEntering Run History Context Manager.\nCurrent directory:  /mnt/batch/tasks/shared/LS_root/jobs/vlk-workspace/azureml/70f76633-260a-4c25-967f-ea40e74b5983/mounts/workspaceblobstore/azureml/70f76633-260a-4c25-967f-ea40e74b5983\nPreparing to call script [ driver/amlbi_main.py ] with arguments: [&#39;--client_sdk_version&#39;, &#39;1.17.0&#39;, &#39;--scoring_module_name&#39;, &#39;batch_scoring.py&#39;, &#39;--mini_batch_size&#39;, &#39;20&#39;, &#39;--error_threshold&#39;, &#39;1&#39;, &#39;--output_action&#39;, &#39;append_row&#39;, &#39;--logging_level&#39;, &#39;INFO&#39;, &#39;--run_invocation_timeout&#39;, &#39;60&#39;, &#39;--run_max_try&#39;, &#39;3&#39;, &#39;--create_snapshot_at_runtime&#39;, &#39;True&#39;, &#39;--append_row_file_name&#39;, &#39;parallel_run_step.txt&#39;, &#39;--output&#39;, &#39;/mnt/batch/tasks/shared/LS_root/jobs/vlk-workspace/azureml/70f76633-260a-4c25-967f-ea40e74b5983/mounts/workspaceblobstore/azureml/70f76633-260a-4c25-967f-ea40e74b5983/scores&#39;, &#39;--process_count_per_node&#39;, &#39;2&#39;, &#39;--model_name&#39;, &#39;inception&#39;, &#39;--labels_dir&#39;, &#39;$labels_input&#39;, &#39;--input_fds_0&#39;, &#39;input_images&#39;]\nAfter variable expansion, calling script [ driver/amlbi_main.py ] with arguments: [&#39;--client_sdk_version&#39;, &#39;1.17.0&#39;, &#39;--scoring_module_name&#39;, &#39;batch_scoring.py&#39;, &#39;--mini_batch_size&#39;, &#39;20&#39;, &#39;--error_threshold&#39;, &#39;1&#39;, &#39;--output_action&#39;, &#39;append_row&#39;, &#39;--logging_level&#39;, &#39;INFO&#39;, &#39;--run_invocation_timeout&#39;, &#39;60&#39;, &#39;--run_max_try&#39;, &#39;3&#39;, &#39;--create_snapshot_at_runtime&#39;, &#39;True&#39;, &#39;--append_row_file_name&#39;, &#39;parallel_run_step.txt&#39;, &#39;--output&#39;, &#39;/mnt/batch/tasks/shared/LS_root/jobs/vlk-workspace/azureml/70f76633-260a-4c25-967f-ea40e74b5983/mounts/workspaceblobstore/azureml/70f76633-260a-4c25-967f-ea40e74b5983/scores&#39;, &#39;--process_count_per_node&#39;, &#39;2&#39;, &#39;--model_name&#39;, &#39;inception&#39;, &#39;--labels_dir&#39;, &#39;/tmp/tmp0z68irne&#39;, &#39;--input_fds_0&#39;, &#39;input_images&#39;]\n\nScript type = None\nWARNING - \nThe TensorFlow contrib module will not be included in TensorFlow 2.0.\nFor more information, please see:\n  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n  * https://github.com/tensorflow/addons\n  * https://github.com/tensorflow/io (for I/O related ops)\nIf you depend on functionality not listed there, please file an issue.\n\nCannot find cached workspace due to: KeyError(&#39;d30d76c0-804c-4f4e-ab7b-509d06a49550vlk-workshopvlk-workspace&#39;,)\nCannot find cached workspace due to: KeyError(&#39;d30d76c0-804c-4f4e-ab7b-509d06a49550vlk-workshopvlk-workspace&#39;,)\n\nStreaming azureml-logs/75_job_post-tvmps_0092ff0627db1719f1dc92ad318b9b246d39f255767ec5d408b3a9d4f88afe26_p.txt\n===============================================================================================================\nEntering job release. Current time:2020-11-02T10:55:04.260590\nStarting job release. Current time:2020-11-02T10:55:05.144686\nLogging experiment finalizing status in history service.\nStarting the daemon thread to refresh tokens in background for process with pid = 910\n[2020-11-02T10:55:05.145568] job release stage : upload_datastore starting...\n[{}] job release stage : start importing azureml.history._tracking in run_history_release.\n[2020-11-02T10:55:05.147973] job release stage : execute_job_release starting...\n[2020-11-02T10:55:05.154686] job release stage : copy_batchai_cached_logs starting...\n[2020-11-02T10:55:05.154729] job release stage : copy_batchai_cached_logs completed...\n[2020-11-02T10:55:05.155637] Entering context manager injector.\n[2020-11-02T10:55:05.345492] job release stage : upload_datastore completed...\n[2020-11-02T10:55:05.375453] job release stage : send_run_telemetry starting...\n[2020-11-02T10:55:05.495124] job release stage : execute_job_release completed...\n[2020-11-02T10:55:06.294308] job release stage : send_run_telemetry completed...\nJob release is complete. Current time:2020-11-02T10:55:06.294496\n\nStepRun(batchscoring-202011021034) Execution Summary\n=====================================================\nStepRun( batchscoring-202011021034 ) Status: Finished\n{&#39;runId&#39;: &#39;70f76633-260a-4c25-967f-ea40e74b5983&#39;, &#39;target&#39;: &#39;gpu-cluster&#39;, &#39;status&#39;: &#39;Completed&#39;, &#39;startTimeUtc&#39;: &#39;2020-11-02T10:50:44.846109Z&#39;, &#39;endTimeUtc&#39;: &#39;2020-11-02T10:55:13.14022Z&#39;, &#39;properties&#39;: {&#39;azureml.runsource&#39;: &#39;azureml.StepRun&#39;, &#39;ContentSnapshotId&#39;: &#39;bc4707f2-8238-4b2b-8245-721624425091&#39;, &#39;StepType&#39;: &#39;PythonScriptStep&#39;, &#39;ComputeTargetType&#39;: &#39;AmlCompute&#39;, &#39;azureml.moduleid&#39;: &#39;215fd82b-5329-49eb-ab98-f1a369fb4367&#39;, &#39;azureml.nodeid&#39;: &#39;e8e874c6&#39;, &#39;azureml.pipelinerunid&#39;: &#39;3df13f5a-5048-484e-8a45-a40881189ca3&#39;, &#39;_azureml.ComputeTargetType&#39;: &#39;amlcompute&#39;, &#39;ProcessInfoFile&#39;: &#39;azureml-logs/process_info.json&#39;, &#39;ProcessStatusFile&#39;: &#39;azureml-logs/process_status.json&#39;, &#39;azureml.parallelrunstep&#39;: &#39;true&#39;}, &#39;inputDatasets&#39;: [{&#39;dataset&#39;: {&#39;id&#39;: &#39;6b7aefe9-2af6-494d-9ec6-7455fefdbcde&#39;}, &#39;consumptionDetails&#39;: {&#39;type&#39;: &#39;RunInput&#39;, &#39;inputName&#39;: &#39;input_images&#39;, &#39;mechanism&#39;: &#39;Mount&#39;}}, {&#39;dataset&#39;: {&#39;id&#39;: &#39;a091a995-2e8c-4def-806d-e4f1a40478a6&#39;}, &#39;consumptionDetails&#39;: {&#39;type&#39;: &#39;RunInput&#39;, &#39;inputName&#39;: &#39;labels_input&#39;, &#39;mechanism&#39;: &#39;Mount&#39;}}], &#39;outputDatasets&#39;: [], &#39;runDefinition&#39;: {&#39;script&#39;: &#39;driver/amlbi_main.py&#39;, &#39;command&#39;: [], &#39;useAbsolutePath&#39;: False, &#39;arguments&#39;: [&#39;--client_sdk_version&#39;, &#39;1.17.0&#39;, &#39;--scoring_module_name&#39;, &#39;batch_scoring.py&#39;, &#39;--mini_batch_size&#39;, &#39;20&#39;, &#39;--error_threshold&#39;, &#39;1&#39;, &#39;--output_action&#39;, &#39;append_row&#39;, &#39;--logging_level&#39;, &#39;INFO&#39;, &#39;--run_invocation_timeout&#39;, &#39;60&#39;, &#39;--run_max_try&#39;, &#39;3&#39;, &#39;--create_snapshot_at_runtime&#39;, &#39;True&#39;, &#39;--append_row_file_name&#39;, &#39;parallel_run_step.txt&#39;, &#39;--output&#39;, &#39;$AZUREML_DATAREFERENCE_scores&#39;, &#39;--process_count_per_node&#39;, &#39;2&#39;, &#39;--model_name&#39;, &#39;inception&#39;, &#39;--labels_dir&#39;, &#39;DatasetConsumptionConfig:labels_input&#39;, &#39;--input_fds_0&#39;, &#39;input_images&#39;], &#39;sourceDirectoryDataStore&#39;: None, &#39;framework&#39;: &#39;Python&#39;, &#39;communicator&#39;: &#39;None&#39;, &#39;target&#39;: &#39;gpu-cluster&#39;, &#39;dataReferences&#39;: {&#39;scores&#39;: {&#39;dataStoreName&#39;: &#39;workspaceblobstore&#39;, &#39;mode&#39;: &#39;Mount&#39;, &#39;pathOnDataStore&#39;: &#39;azureml/70f76633-260a-4c25-967f-ea40e74b5983/scores&#39;, &#39;pathOnCompute&#39;: None, &#39;overwrite&#39;: False}}, &#39;data&#39;: {&#39;input_images&#39;: {&#39;dataLocation&#39;: {&#39;dataset&#39;: {&#39;id&#39;: &#39;6b7aefe9-2af6-494d-9ec6-7455fefdbcde&#39;, &#39;name&#39;: None, &#39;version&#39;: &#39;1&#39;}, &#39;dataPath&#39;: None}, &#39;mechanism&#39;: &#39;Mount&#39;, &#39;environmentVariableName&#39;: &#39;input_images&#39;, &#39;pathOnCompute&#39;: None, &#39;overwrite&#39;: False}, &#39;labels_input&#39;: {&#39;dataLocation&#39;: {&#39;dataset&#39;: {&#39;id&#39;: &#39;a091a995-2e8c-4def-806d-e4f1a40478a6&#39;, &#39;name&#39;: None, &#39;version&#39;: &#39;1&#39;}, &#39;dataPath&#39;: None}, &#39;mechanism&#39;: &#39;Mount&#39;, &#39;environmentVariableName&#39;: &#39;labels_input&#39;, &#39;pathOnCompute&#39;: None, &#39;overwrite&#39;: False}}, &#39;outputData&#39;: {}, &#39;jobName&#39;: None, &#39;maxRunDurationSeconds&#39;: None, &#39;nodeCount&#39;: 1, &#39;priority&#39;: None, &#39;environment&#39;: {&#39;name&#39;: &#39;parallelenv&#39;, &#39;version&#39;: &#39;Autosave_2020-11-02T10:36:49Z_7b9b48a4&#39;, &#39;python&#39;: {&#39;interpreterPath&#39;: &#39;python&#39;, &#39;userManagedDependencies&#39;: False, &#39;condaDependencies&#39;: {&#39;channels&#39;: [&#39;anaconda&#39;, &#39;conda-forge&#39;], &#39;dependencies&#39;: [&#39;python=3.6.2&#39;, {&#39;pip&#39;: [&#39;tensorflow-gpu==1.15.2&#39;, &#39;azureml-core~=1.17.0&#39;, &#39;azureml-dataset-runtime[fuse]~=1.17.0&#39;]}], &#39;name&#39;: &#39;azureml_2fedf4d8b9700d1bbb353b132ff1f6aa&#39;}, &#39;baseCondaEnvironment&#39;: None}, &#39;environmentVariables&#39;: {&#39;EXAMPLE_ENV_VAR&#39;: &#39;EXAMPLE_VALUE&#39;}, &#39;docker&#39;: {&#39;baseImage&#39;: &#39;mcr.microsoft.com/azureml/intelmpi2018.3-cuda10.0-cudnn7-ubuntu16.04:20200821.v1&#39;, &#39;platform&#39;: {&#39;os&#39;: &#39;Linux&#39;, &#39;architecture&#39;: &#39;amd64&#39;}, &#39;baseDockerfile&#39;: None, &#39;baseImageRegistry&#39;: {&#39;address&#39;: None, &#39;username&#39;: None, &#39;password&#39;: None}, &#39;enabled&#39;: True, &#39;arguments&#39;: []}, &#39;spark&#39;: {&#39;repositories&#39;: [], &#39;packages&#39;: [], &#39;precachePackages&#39;: True}, &#39;inferencingStackVersion&#39;: None}, &#39;history&#39;: {&#39;outputCollection&#39;: True, &#39;directoriesToWatch&#39;: [&#39;logs&#39;], &#39;enableMLflowTracking&#39;: True, &#39;snapshotProject&#39;: True}, &#39;spark&#39;: {&#39;configuration&#39;: {&#39;spark.app.name&#39;: &#39;Azure ML Experiment&#39;, &#39;spark.yarn.maxAppAttempts&#39;: &#39;1&#39;}}, &#39;parallelTask&#39;: {&#39;maxRetriesPerWorker&#39;: 0, &#39;workerCountPerNode&#39;: 1, &#39;terminalExitCodes&#39;: None, &#39;configuration&#39;: {}}, &#39;amlCompute&#39;: {&#39;name&#39;: None, &#39;vmSize&#39;: None, &#39;retainCluster&#39;: False, &#39;clusterMaxNodeCount&#39;: 1}, &#39;aiSuperComputer&#39;: {&#39;instanceType&#39;: None, &#39;frameworkImage&#39;: None, &#39;imageVersion&#39;: None, &#39;location&#39;: None}, &#39;tensorflow&#39;: {&#39;workerCount&#39;: 1, &#39;parameterServerCount&#39;: 1}, &#39;mpi&#39;: {&#39;processCountPerNode&#39;: 1}, &#39;hdi&#39;: {&#39;yarnDeployMode&#39;: &#39;Cluster&#39;}, &#39;containerInstance&#39;: {&#39;region&#39;: None, &#39;cpuCores&#39;: 2.0, &#39;memoryGb&#39;: 3.5}, &#39;exposedPorts&#39;: None, &#39;docker&#39;: {&#39;useDocker&#39;: True, &#39;sharedVolumes&#39;: True, &#39;shmSize&#39;: &#39;2g&#39;, &#39;arguments&#39;: []}, &#39;cmk8sCompute&#39;: {&#39;configuration&#39;: {}}, &#39;globalJobDispatcher&#39;: {&#39;vmSize&#39;: []}}, &#39;logFiles&#39;: {&#39;azureml-logs/20_image_build_log.txt&#39;: &#39;https://vlkworkspace8006493384.blob.core.windows.net/azureml/ExperimentRun/dcid.70f76633-260a-4c25-967f-ea40e74b5983/azureml-logs/20_image_build_log.txt?sv=2019-02-02&amp;sr=b&amp;sig=x2rRDFCUwDil%2FPXFPteZ98ATTjV%2BOArrAEFtlAj7u2Q%3D&amp;st=2020-11-02T10%3A45%3A07Z&amp;se=2020-11-02T18%3A55%3A07Z&amp;sp=r&#39;, &#39;azureml-logs/55_azureml-execution-tvmps_0092ff0627db1719f1dc92ad318b9b246d39f255767ec5d408b3a9d4f88afe26_p.txt&#39;: &#39;https://vlkworkspace8006493384.blob.core.windows.net/azureml/ExperimentRun/dcid.70f76633-260a-4c25-967f-ea40e74b5983/azureml-logs/55_azureml-execution-tvmps_0092ff0627db1719f1dc92ad318b9b246d39f255767ec5d408b3a9d4f88afe26_p.txt?sv=2019-02-02&amp;sr=b&amp;sig=%2FUhMpo5hAOhWAicEA93C55IrbrTKFp6ES1W2kPBYLyQ%3D&amp;st=2020-11-02T10%3A45%3A07Z&amp;se=2020-11-02T18%3A55%3A07Z&amp;sp=r&#39;, &#39;azureml-logs/65_job_prep-tvmps_0092ff0627db1719f1dc92ad318b9b246d39f255767ec5d408b3a9d4f88afe26_p.txt&#39;: &#39;https://vlkworkspace8006493384.blob.core.windows.net/azureml/ExperimentRun/dcid.70f76633-260a-4c25-967f-ea40e74b5983/azureml-logs/65_job_prep-tvmps_0092ff0627db1719f1dc92ad318b9b246d39f255767ec5d408b3a9d4f88afe26_p.txt?sv=2019-02-02&amp;sr=b&amp;sig=J5%2FKs3TGxvzNHT5QKCENPaEwIgCYKqZivxec9IKRvMI%3D&amp;st=2020-11-02T10%3A45%3A07Z&amp;se=2020-11-02T18%3A55%3A07Z&amp;sp=r&#39;, &#39;azureml-logs/70_driver_log.txt&#39;: &#39;https://vlkworkspace8006493384.blob.core.windows.net/azureml/ExperimentRun/dcid.70f76633-260a-4c25-967f-ea40e74b5983/azureml-logs/70_driver_log.txt?sv=2019-02-02&amp;sr=b&amp;sig=f8ffzbzGXzNJd4JRyckHuG9RQTx%2BmErPQmQfTbLXysE%3D&amp;st=2020-11-02T10%3A45%3A07Z&amp;se=2020-11-02T18%3A55%3A07Z&amp;sp=r&#39;, &#39;azureml-logs/75_job_post-tvmps_0092ff0627db1719f1dc92ad318b9b246d39f255767ec5d408b3a9d4f88afe26_p.txt&#39;: &#39;https://vlkworkspace8006493384.blob.core.windows.net/azureml/ExperimentRun/dcid.70f76633-260a-4c25-967f-ea40e74b5983/azureml-logs/75_job_post-tvmps_0092ff0627db1719f1dc92ad318b9b246d39f255767ec5d408b3a9d4f88afe26_p.txt?sv=2019-02-02&amp;sr=b&amp;sig=LmuTBtygKCQnwXBWPG9ewvsDF2j0qzb1HtupGG4C0UY%3D&amp;st=2020-11-02T10%3A45%3A07Z&amp;se=2020-11-02T18%3A55%3A07Z&amp;sp=r&#39;, &#39;azureml-logs/process_info.json&#39;: &#39;https://vlkworkspace8006493384.blob.core.windows.net/azureml/ExperimentRun/dcid.70f76633-260a-4c25-967f-ea40e74b5983/azureml-logs/process_info.json?sv=2019-02-02&amp;sr=b&amp;sig=FAghgdt87DpvHV20gip6S64gsV7uXwII27NYeZqRcSo%3D&amp;st=2020-11-02T10%3A45%3A07Z&amp;se=2020-11-02T18%3A55%3A07Z&amp;sp=r&#39;, &#39;azureml-logs/process_status.json&#39;: &#39;https://vlkworkspace8006493384.blob.core.windows.net/azureml/ExperimentRun/dcid.70f76633-260a-4c25-967f-ea40e74b5983/azureml-logs/process_status.json?sv=2019-02-02&amp;sr=b&amp;sig=zStoUnUh1%2B8dMXYFFBIgz%2Bg4TzNVfEhCxA4Iy5B%2BHl8%3D&amp;st=2020-11-02T10%3A45%3A07Z&amp;se=2020-11-02T18%3A55%3A07Z&amp;sp=r&#39;, &#39;logs/azureml/128_azureml.log&#39;: &#39;https://vlkworkspace8006493384.blob.core.windows.net/azureml/ExperimentRun/dcid.70f76633-260a-4c25-967f-ea40e74b5983/logs/azureml/128_azureml.log?sv=2019-02-02&amp;sr=b&amp;sig=Sl71E6u1erLYR80mtb18wOLsYjwS5%2FuXIXexvkE64%2BQ%3D&amp;st=2020-11-02T10%3A45%3A07Z&amp;se=2020-11-02T18%3A55%3A07Z&amp;sp=r&#39;, &#39;logs/azureml/dataprep/backgroundProcess.log&#39;: &#39;https://vlkworkspace8006493384.blob.core.windows.net/azureml/ExperimentRun/dcid.70f76633-260a-4c25-967f-ea40e74b5983/logs/azureml/dataprep/backgroundProcess.log?sv=2019-02-02&amp;sr=b&amp;sig=tpvFcbQWtryVgkuoA9g3SVYXcF0sQCJRH2e6d0RAThg%3D&amp;st=2020-11-02T10%3A45%3A07Z&amp;se=2020-11-02T18%3A55%3A07Z&amp;sp=r&#39;, &#39;logs/azureml/dataprep/backgroundProcess_Telemetry.log&#39;: &#39;https://vlkworkspace8006493384.blob.core.windows.net/azureml/ExperimentRun/dcid.70f76633-260a-4c25-967f-ea40e74b5983/logs/azureml/dataprep/backgroundProcess_Telemetry.log?sv=2019-02-02&amp;sr=b&amp;sig=lPdv0gLdrzgoU2NlRB0KiUZEA%2BDyOgO0AEg0t1XKOdM%3D&amp;st=2020-11-02T10%3A45%3A07Z&amp;se=2020-11-02T18%3A55%3A07Z&amp;sp=r&#39;, &#39;logs/azureml/dataprep/engine_spans_l_2c7c31cd-013d-4808-912c-eaebdd4b1914.jsonl&#39;: &#39;https://vlkworkspace8006493384.blob.core.windows.net/azureml/ExperimentRun/dcid.70f76633-260a-4c25-967f-ea40e74b5983/logs/azureml/dataprep/engine_spans_l_2c7c31cd-013d-4808-912c-eaebdd4b1914.jsonl?sv=2019-02-02&amp;sr=b&amp;sig=dWZJJWHqTkfUC5rMy3cXj7kARTmvpapwTPl5uyubx2k%3D&amp;st=2020-11-02T10%3A45%3A07Z&amp;se=2020-11-02T18%3A55%3A07Z&amp;sp=r&#39;, &#39;logs/azureml/dataprep/engine_spans_l_47ed807e-26ff-4e83-947e-04481221881f.jsonl&#39;: &#39;https://vlkworkspace8006493384.blob.core.windows.net/azureml/ExperimentRun/dcid.70f76633-260a-4c25-967f-ea40e74b5983/logs/azureml/dataprep/engine_spans_l_47ed807e-26ff-4e83-947e-04481221881f.jsonl?sv=2019-02-02&amp;sr=b&amp;sig=%2B3hfG1ja%2FqZn%2FElaKf1B6DJHp5zlHTj1H27XVCXWID4%3D&amp;st=2020-11-02T10%3A45%3A07Z&amp;se=2020-11-02T18%3A55%3A07Z&amp;sp=r&#39;, &#39;logs/azureml/dataprep/engine_spans_l_cd977402-eab9-410c-8162-1029929988f2.jsonl&#39;: &#39;https://vlkworkspace8006493384.blob.core.windows.net/azureml/ExperimentRun/dcid.70f76633-260a-4c25-967f-ea40e74b5983/logs/azureml/dataprep/engine_spans_l_cd977402-eab9-410c-8162-1029929988f2.jsonl?sv=2019-02-02&amp;sr=b&amp;sig=w17x7WAy1peIGq9eCVWK7hyKYmRfvERddtcQnCgdvFg%3D&amp;st=2020-11-02T10%3A45%3A07Z&amp;se=2020-11-02T18%3A55%3A07Z&amp;sp=r&#39;, &#39;logs/azureml/dataprep/python_span_33403279-dd4b-4ae2-9570-1d3277f68071.jsonl&#39;: &#39;https://vlkworkspace8006493384.blob.core.windows.net/azureml/ExperimentRun/dcid.70f76633-260a-4c25-967f-ea40e74b5983/logs/azureml/dataprep/python_span_33403279-dd4b-4ae2-9570-1d3277f68071.jsonl?sv=2019-02-02&amp;sr=b&amp;sig=B22i7UQ6BNbAScXO9Eyj2YXUKvvjWsriutHEczSUzPc%3D&amp;st=2020-11-02T10%3A45%3A07Z&amp;se=2020-11-02T18%3A55%3A07Z&amp;sp=r&#39;, &#39;logs/azureml/dataprep/python_span_46df6ed2-ecc5-4163-955f-603d5a261da6.jsonl&#39;: &#39;https://vlkworkspace8006493384.blob.core.windows.net/azureml/ExperimentRun/dcid.70f76633-260a-4c25-967f-ea40e74b5983/logs/azureml/dataprep/python_span_46df6ed2-ecc5-4163-955f-603d5a261da6.jsonl?sv=2019-02-02&amp;sr=b&amp;sig=kAS%2FpsIIT22%2B7e8yrW9hRYiMqQgUXpFBNoRId2bvHLg%3D&amp;st=2020-11-02T10%3A45%3A07Z&amp;se=2020-11-02T18%3A55%3A07Z&amp;sp=r&#39;, &#39;logs/azureml/dataprep/python_span_l_0b691dcb-8165-4ce4-888d-ec1b7d9b784d.jsonl&#39;: &#39;https://vlkworkspace8006493384.blob.core.windows.net/azureml/ExperimentRun/dcid.70f76633-260a-4c25-967f-ea40e74b5983/logs/azureml/dataprep/python_span_l_0b691dcb-8165-4ce4-888d-ec1b7d9b784d.jsonl?sv=2019-02-02&amp;sr=b&amp;sig=1nerINsR93B99Luduz201oRr8zdjZDb2cfgfnbxjjKc%3D&amp;st=2020-11-02T10%3A45%3A07Z&amp;se=2020-11-02T18%3A55%3A07Z&amp;sp=r&#39;, &#39;logs/azureml/dataprep/python_span_l_2c7c31cd-013d-4808-912c-eaebdd4b1914.jsonl&#39;: &#39;https://vlkworkspace8006493384.blob.core.windows.net/azureml/ExperimentRun/dcid.70f76633-260a-4c25-967f-ea40e74b5983/logs/azureml/dataprep/python_span_l_2c7c31cd-013d-4808-912c-eaebdd4b1914.jsonl?sv=2019-02-02&amp;sr=b&amp;sig=MLhqBQ70hH96%2FLGmCNrqpeX8xjaf9KkBoUW0z7CdvII%3D&amp;st=2020-11-02T10%3A45%3A07Z&amp;se=2020-11-02T18%3A55%3A07Z&amp;sp=r&#39;, &#39;logs/azureml/dataprep/python_span_l_47ed807e-26ff-4e83-947e-04481221881f.jsonl&#39;: &#39;https://vlkworkspace8006493384.blob.core.windows.net/azureml/ExperimentRun/dcid.70f76633-260a-4c25-967f-ea40e74b5983/logs/azureml/dataprep/python_span_l_47ed807e-26ff-4e83-947e-04481221881f.jsonl?sv=2019-02-02&amp;sr=b&amp;sig=Xffgfdw4AOn5jva3%2FcirS2oLe3DnZVnHo1u3XGwgcns%3D&amp;st=2020-11-02T10%3A45%3A07Z&amp;se=2020-11-02T18%3A55%3A07Z&amp;sp=r&#39;, &#39;logs/azureml/dataprep/python_span_l_cd977402-eab9-410c-8162-1029929988f2.jsonl&#39;: &#39;https://vlkworkspace8006493384.blob.core.windows.net/azureml/ExperimentRun/dcid.70f76633-260a-4c25-967f-ea40e74b5983/logs/azureml/dataprep/python_span_l_cd977402-eab9-410c-8162-1029929988f2.jsonl?sv=2019-02-02&amp;sr=b&amp;sig=yCbG4v5mpjJ0Kfy1cmYBL%2B8JHjEN%2FdiJff0lsaisLU8%3D&amp;st=2020-11-02T10%3A45%3A07Z&amp;se=2020-11-02T18%3A55%3A07Z&amp;sp=r&#39;, &#39;logs/azureml/dataprep/python_span_l_de6ea322-1579-47a9-98e4-0efe5c0cb6a9.jsonl&#39;: &#39;https://vlkworkspace8006493384.blob.core.windows.net/azureml/ExperimentRun/dcid.70f76633-260a-4c25-967f-ea40e74b5983/logs/azureml/dataprep/python_span_l_de6ea322-1579-47a9-98e4-0efe5c0cb6a9.jsonl?sv=2019-02-02&amp;sr=b&amp;sig=iTeQ4LtAzqIm4P8QNWncwUP%2Fm4AT4ce41tivgETfj%2BQ%3D&amp;st=2020-11-02T10%3A45%3A07Z&amp;se=2020-11-02T18%3A55%3A07Z&amp;sp=r&#39;, &#39;logs/azureml/executionlogs.txt&#39;: &#39;https://vlkworkspace8006493384.blob.core.windows.net/azureml/ExperimentRun/dcid.70f76633-260a-4c25-967f-ea40e74b5983/logs/azureml/executionlogs.txt?sv=2019-02-02&amp;sr=b&amp;sig=Q%2BFdXNJZS6dUWOns1zm7vLJnAj3gj93mp7C7a4b3blQ%3D&amp;st=2020-11-02T10%3A45%3A07Z&amp;se=2020-11-02T18%3A55%3A07Z&amp;sp=r&#39;, &#39;logs/azureml/job_prep_azureml.log&#39;: &#39;https://vlkworkspace8006493384.blob.core.windows.net/azureml/ExperimentRun/dcid.70f76633-260a-4c25-967f-ea40e74b5983/logs/azureml/job_prep_azureml.log?sv=2019-02-02&amp;sr=b&amp;sig=6UtzdbSPTqXF%2FJLm%2FE27oqsZZNNUiwqPEr3G69S9jRU%3D&amp;st=2020-11-02T10%3A45%3A07Z&amp;se=2020-11-02T18%3A55%3A07Z&amp;sp=r&#39;, &#39;logs/azureml/job_release_azureml.log&#39;: &#39;https://vlkworkspace8006493384.blob.core.windows.net/azureml/ExperimentRun/dcid.70f76633-260a-4c25-967f-ea40e74b5983/logs/azureml/job_release_azureml.log?sv=2019-02-02&amp;sr=b&amp;sig=2ne8TBptqEpZt8ilyzyAfgySbMl26QQI6CFhUXN%2FQ2Q%3D&amp;st=2020-11-02T10%3A45%3A07Z&amp;se=2020-11-02T18%3A55%3A07Z&amp;sp=r&#39;, &#39;logs/azureml/stderrlogs.txt&#39;: &#39;https://vlkworkspace8006493384.blob.core.windows.net/azureml/ExperimentRun/dcid.70f76633-260a-4c25-967f-ea40e74b5983/logs/azureml/stderrlogs.txt?sv=2019-02-02&amp;sr=b&amp;sig=Ybt1gB%2B%2B4iK4gvrJ5%2BWi0EKtRe%2FfPLIFa9vZlOTtTiA%3D&amp;st=2020-11-02T10%3A45%3A07Z&amp;se=2020-11-02T18%3A55%3A07Z&amp;sp=r&#39;, &#39;logs/azureml/stdoutlogs.txt&#39;: &#39;https://vlkworkspace8006493384.blob.core.windows.net/azureml/ExperimentRun/dcid.70f76633-260a-4c25-967f-ea40e74b5983/logs/azureml/stdoutlogs.txt?sv=2019-02-02&amp;sr=b&amp;sig=TK2xOY9%2BtTFltaORb1x%2B4aqBn0c%2Fc5syFrczdTika4c%3D&amp;st=2020-11-02T10%3A45%3A07Z&amp;se=2020-11-02T18%3A55%3A07Z&amp;sp=r&#39;}}\n\n\n\nPipelineRun Execution Summary\n==============================\nPipelineRun Status: Finished\n{&#39;runId&#39;: &#39;3df13f5a-5048-484e-8a45-a40881189ca3&#39;, &#39;status&#39;: &#39;Completed&#39;, &#39;startTimeUtc&#39;: &#39;2020-11-02T10:35:15.92179Z&#39;, &#39;endTimeUtc&#39;: &#39;2020-11-02T10:55:22.148206Z&#39;, &#39;properties&#39;: {&#39;azureml.runsource&#39;: &#39;azureml.PipelineRun&#39;, &#39;runSource&#39;: &#39;SDK&#39;, &#39;runType&#39;: &#39;SDK&#39;, &#39;azureml.parameters&#39;: &#39;{}&#39;}, &#39;inputDatasets&#39;: [], &#39;logFiles&#39;: {&#39;logs/azureml/executionlogs.txt&#39;: &#39;https://vlkworkspace8006493384.blob.core.windows.net/azureml/ExperimentRun/dcid.3df13f5a-5048-484e-8a45-a40881189ca3/logs/azureml/executionlogs.txt?sv=2019-02-02&amp;sr=b&amp;sig=WzjpgUj4Xj5nbO0NxxcDSSps6jNYc6NOojfkqRvQtho%3D&amp;st=2020-11-02T10%3A45%3A23Z&amp;se=2020-11-02T18%3A55%3A23Z&amp;sp=r&#39;, &#39;logs/azureml/stderrlogs.txt&#39;: &#39;https://vlkworkspace8006493384.blob.core.windows.net/azureml/ExperimentRun/dcid.3df13f5a-5048-484e-8a45-a40881189ca3/logs/azureml/stderrlogs.txt?sv=2019-02-02&amp;sr=b&amp;sig=NqoHDdK%2FdRnR46lRd9iqdQzgLD%2BaiVwtfo%2Bzy6KKwaY%3D&amp;st=2020-11-02T10%3A45%3A23Z&amp;se=2020-11-02T18%3A55%3A23Z&amp;sp=r&#39;, &#39;logs/azureml/stdoutlogs.txt&#39;: &#39;https://vlkworkspace8006493384.blob.core.windows.net/azureml/ExperimentRun/dcid.3df13f5a-5048-484e-8a45-a40881189ca3/logs/azureml/stdoutlogs.txt?sv=2019-02-02&amp;sr=b&amp;sig=%2BbJpenx5MMhc74zH6jMg6YVP468sGVGorgxutlXxH%2FU%3D&amp;st=2020-11-02T10%3A45%3A23Z&amp;se=2020-11-02T18%3A55%3A23Z&amp;sp=r&#39;}}\n\nOut[57]: &#39;Finished&#39;</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">PipelineRunId: 3df13f5a-5048-484e-8a45-a40881189ca3\nLink to Azure Machine Learning Portal: https://ml.azure.com/experiments/batch_scoring/runs/3df13f5a-5048-484e-8a45-a40881189ca3?wsid=/subscriptions/d30d76c0-804c-4f4e-ab7b-509d06a49550/resourcegroups/vlk-workshop/workspaces/vlk-workspace\nPipelineRun Status: Running\n\n\nStepRunId: 70f76633-260a-4c25-967f-ea40e74b5983\nLink to Azure Machine Learning Portal: https://ml.azure.com/experiments/batch_scoring/runs/70f76633-260a-4c25-967f-ea40e74b5983?wsid=/subscriptions/d30d76c0-804c-4f4e-ab7b-509d06a49550/resourcegroups/vlk-workshop/workspaces/vlk-workspace\nStepRun( batchscoring-202011021034 ) Status: Queued\n\nStreaming azureml-logs/20_image_build_log.txt\n=============================================\n2020/11/02 10:37:01 Downloading source code...\n2020/11/02 10:37:02 Finished downloading source code\n2020/11/02 10:37:03 Creating Docker network: acb_default_network, driver: &#39;bridge&#39;\n2020/11/02 10:37:03 Successfully set up Docker network: acb_default_network\n2020/11/02 10:37:03 Setting up Docker configuration...\n2020/11/02 10:37:04 Successfully set up Docker configuration\n2020/11/02 10:37:04 Logging in to registry: f89c90464c5e495db4f6977a78dd3507.azurecr.io\n2020/11/02 10:37:05 Successfully logged into f89c90464c5e495db4f6977a78dd3507.azurecr.io\n2020/11/02 10:37:05 Executing step ID: acb_step_0. Timeout(sec): 5400, Working directory: &#39;&#39;, Network: &#39;acb_default_network&#39;\n2020/11/02 10:37:05 Scanning for dependencies...\n2020/11/02 10:37:06 Successfully scanned dependencies\n2020/11/02 10:37:06 Launching container with name: acb_step_0\nSending build context to Docker daemon  60.93kB\n\nStep 1/15 : FROM mcr.microsoft.com/azureml/intelmpi2018.3-cuda10.0-cudnn7-ubuntu16.04:20200821.v1@sha256:652cba03ef8fd4937111da0bc9f204a4310105e87b08eea322c1b55850169a49\nsha256:652cba03ef8fd4937111da0bc9f204a4310105e87b08eea322c1b55850169a49: Pulling from azureml/intelmpi2018.3-cuda10.0-cudnn7-ubuntu16.04\nf7277927d38a: Pulling fs layer\n8d3eac894db4: Pulling fs layer\nedf72af6d627: Pulling fs layer\n3e4f86211d23: Pulling fs layer\nd6e9603ff777: Pulling fs layer\n5cad422780e2: Pulling fs layer\n8130687c8acb: Pulling fs layer\nc11e9246d621: Pulling fs layer\n0dfae24cbbd9: Pulling fs layer\n0bb049a6d391: Pulling fs layer\n1aef3da5021b: Pulling fs layer\ne5f03d63d02d: Pulling fs layer\n22533bcd68c8: Pulling fs layer\na8c7deb5dc88: Pulling fs layer\nef34b1adad4d: Pulling fs layer\n87e1451a8ae7: Pulling fs layer\n6a5d94939972: Pulling fs layer\nf4b1ab4ce7b5: Pulling fs layer\n3e4f86211d23: Waiting\nd6e9603ff777: Waiting\n5cad422780e2: Waiting\n8130687c8acb: Waiting\nc11e9246d621: Waiting\n0dfae24cbbd9: Waiting\n0bb049a6d391: Waiting\n1aef3da5021b: Waiting\ne5f03d63d02d: Waiting\n22533bcd68c8: Waiting\na8c7deb5dc88: Waiting\nef34b1adad4d: Waiting\n87e1451a8ae7: Waiting\n6a5d94939972: Waiting\nf4b1ab4ce7b5: Waiting\nedf72af6d627: Verifying Checksum\nedf72af6d627: Download complete\n8d3eac894db4: Verifying Checksum\n8d3eac894db4: Download complete\n3e4f86211d23: Verifying Checksum\n3e4f86211d23: Download complete\nf7277927d38a: Verifying Checksum\nf7277927d38a: Download complete\nStepRun( batchscoring-202011021034 ) Status: Running\n8130687c8acb: Verifying Checksum\n8130687c8acb: Download complete\nd6e9603ff777: Verifying Checksum\nd6e9603ff777: Download complete\n5cad422780e2: Verifying Checksum\n5cad422780e2: Download complete\nf7277927d38a: Pull complete\n8d3eac894db4: Pull complete\nedf72af6d627: Pull complete\n3e4f86211d23: Pull complete\nd6e9603ff777: Pull complete\n5cad422780e2: Pull complete\n0dfae24cbbd9: Verifying Checksum\n0dfae24cbbd9: Download complete\nc11e9246d621: Verifying Checksum\nc11e9246d621: Download complete\n8130687c8acb: Pull complete\n1aef3da5021b: Verifying Checksum\n1aef3da5021b: Download complete\ne5f03d63d02d: Verifying Checksum\ne5f03d63d02d: Download complete\n22533bcd68c8: Verifying Checksum\n22533bcd68c8: Download complete\na8c7deb5dc88: Verifying Checksum\na8c7deb5dc88: Download complete\nef34b1adad4d: Verifying Checksum\nef34b1adad4d: Download complete\n6a5d94939972: Verifying Checksum\n6a5d94939972: Download complete\nf4b1ab4ce7b5: Verifying Checksum\nf4b1ab4ce7b5: Download complete\n87e1451a8ae7: Verifying Checksum\n87e1451a8ae7: Download complete\nc11e9246d621: Pull complete\n0bb049a6d391: Verifying Checksum\n0bb049a6d391: Download complete\n0dfae24cbbd9: Pull complete\n0bb049a6d391: Pull complete\n1aef3da5021b: Pull complete\ne5f03d63d02d: Pull complete\n22533bcd68c8: Pull complete\na8c7deb5dc88: Pull complete\nef34b1adad4d: Pull complete\n87e1451a8ae7: Pull complete\n6a5d94939972: Pull complete\nf4b1ab4ce7b5: Pull complete\nDigest: sha256:652cba03ef8fd4937111da0bc9f204a4310105e87b08eea322c1b55850169a49\nStatus: Downloaded newer image for mcr.microsoft.com/azureml/intelmpi2018.3-cuda10.0-cudnn7-ubuntu16.04:20200821.v1@sha256:652cba03ef8fd4937111da0bc9f204a4310105e87b08eea322c1b55850169a49\n ---&gt; 29d6cebaed25\nStep 2/15 : USER root\n ---&gt; Running in 78747f81016f\nRemoving intermediate container 78747f81016f\n ---&gt; 665c7b3bf6de\nStep 3/15 : RUN mkdir -p $HOME/.cache\n ---&gt; Running in 748432fdd497\nRemoving intermediate container 748432fdd497\n ---&gt; 7f57bdb4f3e9\nStep 4/15 : WORKDIR /\n ---&gt; Running in 684bedece0d4\nRemoving intermediate container 684bedece0d4\n ---&gt; a983f36cb6db\nStep 5/15 : COPY azureml-environment-setup/99brokenproxy /etc/apt/apt.conf.d/\n ---&gt; 08b03e5ec9a6\nStep 6/15 : RUN if dpkg --compare-versions `conda --version | grep -oE &#39;[^ ]+$&#39;` lt 4.4.11; then conda install conda==4.4.11; fi\n ---&gt; Running in 481ab1be7299\nRemoving intermediate container 481ab1be7299\n ---&gt; 397570faff82\nStep 7/15 : COPY azureml-environment-setup/mutated_conda_dependencies.yml azureml-environment-setup/mutated_conda_dependencies.yml\n ---&gt; a7a2554410d2\nStep 8/15 : RUN ldconfig /usr/local/cuda/lib64/stubs &amp;&amp; conda env create -p /azureml-envs/azureml_2fedf4d8b9700d1bbb353b132ff1f6aa -f azureml-environment-setup/mutated_conda_dependencies.yml &amp;&amp; rm -rf &#34;$HOME/.cache/pip&#34; &amp;&amp; conda clean -aqy &amp;&amp; CONDA_ROOT_DIR=$(conda info --root) &amp;&amp; rm -rf &#34;$CONDA_ROOT_DIR/pkgs&#34; &amp;&amp; find &#34;$CONDA_ROOT_DIR&#34; -type d -name __pycache__ -exec rm -rf {} + &amp;&amp; ldconfig\n ---&gt; Running in 5a08d5ad92d1\nWarning: you have pip-installed dependencies in your environment file, but you do not list pip itself as one of your conda dependencies.  Conda may not use the correct pip to install your packages, and they may end up in the wrong place.  Please add an explicit pip dependency.  I&#39;m adding one for you, but still nagging you.\nCollecting package metadata (repodata.json): ...working... \ndone\nSolving environment: ...working... done\n\nDownloading and Extracting Packages\n\nopenssl-1.0.2u       | 3.1 MB    |            |   0% \nopenssl-1.0.2u       | 3.1 MB    | ####1      |  41% \nopenssl-1.0.2u       | 3.1 MB    | ########## | 100% \n\nlibffi-3.2.1         | 52 KB     |            |   0% \nlibffi-3.2.1         | 52 KB     | ########## | 100% \n\nzlib-1.2.11          | 120 KB    |            |   0% \nzlib-1.2.11          | 120 KB    | ########## | 100% \n\npython-3.6.2         | 27.0 MB   |            |   0% \npython-3.6.2         | 27.0 MB   | ##5        |  26% \npython-3.6.2         | 27.0 MB   | #####7     |  58% \npython-3.6.2         | 27.0 MB   | #########5 |  96% \npython-3.6.2         | 27.0 MB   | ########## | 100% \n\nsetuptools-50.3.0    | 891 KB    |            |   0% \nsetuptools-50.3.0    | 891 KB    | ########## | 100% \n\npip-20.2.4           | 2.0 MB    |            |   0% \npip-20.2.4           | 2.0 MB    | ########## | 100% \n\ncertifi-2020.6.20    | 160 KB    |            |   0% \ncertifi-2020.6.20    | 160 KB    | ########## | 100% \n\ntk-8.6.10            | 3.2 MB    |            |   0% \ntk-8.6.10            | 3.2 MB    | ########## | 100% \n\nsqlite-3.23.1        | 1.5 MB    |            |   0% \nsqlite-3.23.1        | 1.5 MB    | ########## | 100% \n\nlibstdcxx-ng-9.1.0   | 4.0 MB    |            |   0% \nlibstdcxx-ng-9.1.0   | 4.0 MB    | #4         |  14% \nlibstdcxx-ng-9.1.0   | 4.0 MB    | ########## | 100% \n\nlibgcc-ng-9.1.0      | 8.1 MB    |            |   0% \nlibgcc-ng-9.1.0      | 8.1 MB    | ######6    |  66% \nlibgcc-ng-9.1.0      | 8.1 MB    | ########## | 100% \n\nlibedit-3.1          | 171 KB    |            |   0% \nlibedit-3.1          | 171 KB    | ########## | 100% \n\nxz-5.2.5             | 438 KB    |            |   0% \nxz-5.2.5             | 438 KB    | ########## | 100% \n\nreadline-7.0         | 387 KB    |            |   0% \nreadline-7.0         | 387 KB    | ########## | 100% \n\nwheel-0.35.1         | 36 KB     |            |   0% \nwheel-0.35.1         | 36 KB     | ########## | 100% \n\nncurses-6.0          | 907 KB    |            |   0% \nncurses-6.0          | 907 KB    | ########## | 100% \n\nca-certificates-2020 | 128 KB    |            |   0% \nca-certificates-2020 | 128 KB    | ########## | 100% \nPreparing transaction: ...working... done\nVerifying transaction: ...working... done\nExecuting transaction: ...working... done\nRan pip subprocess with arguments:\n[&#39;/azureml-envs/azureml_2fedf4d8b9700d1bbb353b132ff1f6aa/bin/python&#39;, &#39;-m&#39;, &#39;pip&#39;, &#39;install&#39;, &#39;-U&#39;, &#39;-r&#39;, &#39;/azureml-environment-setup/condaenv.7zmp26kf.requirements.txt&#39;]\nPip subprocess output:\nCollecting tensorflow-gpu==1.15.2\n  Downloading tensorflow_gpu-1.15.2-cp36-cp36m-manylinux2010_x86_64.whl (411.0 MB)\nCollecting azureml-core~=1.17.0\n  Downloading azureml_core-1.17.0-py3-none-any.whl (2.1 MB)\nCollecting azureml-dataset-runtime[fuse]~=1.17.0\n  Downloading azureml_dataset_runtime-1.17.0-py3-none-any.whl (3.4 kB)\nCollecting six&gt;=1.10.0\n  Downloading six-1.15.0-py2.py3-none-any.whl (10 kB)\nCollecting termcolor&gt;=1.1.0\n  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\nRequirement already satisfied, skipping upgrade: wheel&gt;=0.26; python_version &gt;= &#34;3&#34; in /azureml-envs/azureml_2fedf4d8b9700d1bbb353b132ff1f6aa/lib/python3.6/site-packages (from tensorflow-gpu==1.15.2-&gt;-r /azureml-environment-setup/condaenv.7zmp26kf.requirements.txt (line 1)) (0.35.1)\nCollecting keras-applications&gt;=1.0.8\n  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\nCollecting tensorflow-estimator==1.15.1\n  Downloading tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\nCollecting numpy&lt;2.0,&gt;=1.16.0\n  Downloading numpy-1.19.3-cp36-cp36m-manylinux2010_x86_64.whl (14.9 MB)\nCollecting protobuf&gt;=3.6.1\n  Downloading protobuf-3.13.0-cp36-cp36m-manylinux1_x86_64.whl (1.3 MB)\nCollecting tensorboard&lt;1.16.0,&gt;=1.15.0\n  Downloading tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\nCollecting gast==0.2.2\n  Downloading gast-0.2.2.tar.gz (10 kB)\nCollecting google-pasta&gt;=0.1.6\n  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\nCollecting wrapt&gt;=1.11.1\n  Downloading wrapt-1.12.1.tar.gz (27 kB)\nCollecting astor&gt;=0.6.0\n  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\nCollecting keras-preprocessing&gt;=1.0.5\n  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\nCollecting opt-einsum&gt;=2.3.2\n  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\nCollecting grpcio&gt;=1.8.6\n  Downloading grpcio-1.33.2-cp36-cp36m-manylinux2014_x86_64.whl (3.8 MB)\nCollecting absl-py&gt;=0.7.0\n  Downloading absl_py-0.11.0-py3-none-any.whl (127 kB)\nCollecting azure-mgmt-authorization&lt;1.0.0,&gt;=0.40.0\n  Downloading azure_mgmt_authorization-0.61.0-py2.py3-none-any.whl (94 kB)\nCollecting ndg-httpsclient\n  Downloading ndg_httpsclient-0.5.1-py3-none-any.whl (34 kB)\nCollecting pathspec\n  Downloading pathspec-0.8.0-py2.py3-none-any.whl (28 kB)\nCollecting python-dateutil&gt;=2.7.3\n  Downloading python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB)\nCollecting azure-common&gt;=1.1.12\n  Downloading azure_common-1.1.25-py2.py3-none-any.whl (12 kB)\nCollecting docker\n  Downloading docker-4.3.1-py2.py3-none-any.whl (145 kB)\nCollecting pyopenssl&lt;20.0.0\n  Downloading pyOpenSSL-19.1.0-py2.py3-none-any.whl (53 kB)\nCollecting azure-mgmt-containerregistry&gt;=2.0.0\n  Downloading azure_mgmt_containerregistry-2.8.0-py2.py3-none-any.whl (718 kB)\nCollecting azure-mgmt-storage&lt;16.0.0,&gt;=1.5.0\n  Downloading azure_mgmt_storage-11.2.0-py2.py3-none-any.whl (547 kB)\nCollecting PyJWT\n  Downloading PyJWT-1.7.1-py2.py3-none-any.whl (18 kB)\nCollecting backports.tempfile\n  Downloading backports.tempfile-1.0-py2.py3-none-any.whl (4.4 kB)\nCollecting requests&gt;=2.19.1\n  Downloading requests-2.24.0-py2.py3-none-any.whl (61 kB)\nCollecting jmespath\n  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\nCollecting azure-graphrbac&lt;1.0.0,&gt;=0.40.0\n  Downloading azure_graphrbac-0.61.1-py2.py3-none-any.whl (141 kB)\nCollecting jsonpickle\n  Downloading jsonpickle-1.4.1-py2.py3-none-any.whl (36 kB)\nCollecting adal&gt;=1.2.0\n  Downloading adal-1.2.5-py2.py3-none-any.whl (55 kB)\nCollecting SecretStorage\n  Downloading SecretStorage-3.1.2-py3-none-any.whl (14 kB)\nCollecting pytz\n  Downloading pytz-2020.4-py2.py3-none-any.whl (509 kB)\nCollecting azure-mgmt-keyvault&lt;7.0.0,&gt;=0.40.0\n  Downloading azure_mgmt_keyvault-2.2.0-py2.py3-none-any.whl (89 kB)\nCollecting azure-mgmt-resource&lt;15.0.0,&gt;=1.2.1\n  Downloading azure_mgmt_resource-10.3.0-py2.py3-none-any.whl (1.0 MB)\nCollecting urllib3&gt;=1.23\n  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\nCollecting cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*\n  Downloading cryptography-3.2.1-cp35-abi3-manylinux2010_x86_64.whl (2.6 MB)\nCollecting msrest&gt;=0.5.1\n  Downloading msrest-0.6.19-py2.py3-none-any.whl (84 kB)\nCollecting msrestazure&gt;=0.4.33\n  Downloading msrestazure-0.6.4-py2.py3-none-any.whl (40 kB)\nCollecting contextlib2\n  Downloading contextlib2-0.6.0.post1-py2.py3-none-any.whl (9.8 kB)\nCollecting ruamel.yaml&gt;=0.15.35\n  Downloading ruamel.yaml-0.16.12-py2.py3-none-any.whl (111 kB)\nCollecting azureml-dataprep&lt;2.5.0a,&gt;=2.4.0a\n  Downloading azureml_dataprep-2.4.2-py3-none-any.whl (28.2 MB)\nCollecting pyarrow&lt;2.0.0,&gt;=0.17.0\n  Downloading pyarrow-1.0.1-cp36-cp36m-manylinux2014_x86_64.whl (17.3 MB)\nCollecting fusepy&lt;4.0.0,&gt;=3.0.1; extra == &#34;fuse&#34;\n  Downloading fusepy-3.0.1.tar.gz (11 kB)\nCollecting h5py\n  Downloading h5py-3.0.0-cp36-cp36m-manylinux1_x86_64.whl (4.0 MB)\nRequirement already satisfied, skipping upgrade: setuptools in /azureml-envs/azureml_2fedf4d8b9700d1bbb353b132ff1f6aa/lib/python3.6/site-packages (from protobuf&gt;=3.6.1-&gt;tensorflow-gpu==1.15.2-&gt;-r /azureml-environment-setup/condaenv.7zmp26kf.requirements.txt (line 1)) (50.3.0.post20201006)\nCollecting markdown&gt;=2.6.8\n  Downloading Markdown-3.3.3-py3-none-any.whl (96 kB)\nCollecting werkzeug&gt;=0.11.15\n  Downloading Werkzeug-1.0.1-py2.py3-none-any.whl (298 kB)\nCollecting pyasn1&gt;=0.1.1\n  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\nCollecting websocket-client&gt;=0.32.0\n  Downloading websocket_client-0.57.0-py2.py3-none-any.whl (200 kB)\nCollecting backports.weakref\n  Downloading backports.weakref-1.0.post1-py2.py3-none-any.whl (5.2 kB)\nRequirement already satisfied, skipping upgrade: certifi&gt;=2017.4.17 in /azureml-envs/azureml_2fedf4d8b9700d1bbb353b132ff1f6aa/lib/python3.6/site-packages (from requests&gt;=2.19.1-&gt;azureml-core~=1.17.0-&gt;-r /azureml-environment-setup/condaenv.7zmp26kf.requirements.txt (line 2)) (2020.6.20)\nCollecting chardet&lt;4,&gt;=3.0.2\n  Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\nCollecting idna&lt;3,&gt;=2.5\n  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\nCollecting importlib-metadata\n  Downloading importlib_metadata-2.0.0-py2.py3-none-any.whl (31 kB)\nCollecting jeepney&gt;=0.4.2\n  Downloading jeepney-0.4.3-py3-none-any.whl (21 kB)\nCollecting cffi!=1.11.3,&gt;=1.8\n  Downloading cffi-1.14.3-cp36-cp36m-manylinux1_x86_64.whl (400 kB)\nCollecting requests-oauthlib&gt;=0.5.0\n  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\nCollecting isodate&gt;=0.6.0\n  Downloading isodate-0.6.0-py2.py3-none-any.whl (45 kB)\nCollecting ruamel.yaml.clib&gt;=0.1.2; platform_python_implementation == &#34;CPython&#34; and python_version &lt; &#34;3.9&#34;\n  Downloading ruamel.yaml.clib-0.2.2-cp36-cp36m-manylinux1_x86_64.whl (549 kB)\nCollecting dotnetcore2&lt;3.0.0,&gt;=2.1.14\n  Downloading dotnetcore2-2.1.17-py3-none-manylinux1_x86_64.whl (28.7 MB)\nCollecting cloudpickle&lt;2.0.0,&gt;=1.1.0\n  Downloading cloudpickle-1.6.0-py3-none-any.whl (23 kB)\nCollecting azure-identity&lt;2.0.0,&gt;=1.2.0\n  Downloading azure_identity-1.4.1-py2.py3-none-any.whl (86 kB)\nCollecting azureml-dataprep-rslex&lt;1.3.0a,&gt;=1.2.0dev0\n  Downloading azureml_dataprep_rslex-1.2.2-cp36-cp36m-manylinux2010_x86_64.whl (7.9 MB)\nCollecting azureml-dataprep-native&lt;25.0.0,&gt;=24.0.0\n  Downloading azureml_dataprep_native-24.0.0-cp36-cp36m-manylinux1_x86_64.whl (1.3 MB)\nCollecting cached-property\n  Downloading cached_property-1.5.2-py2.py3-none-any.whl (7.6 kB)\nCollecting zipp&gt;=0.5\n  Downloading zipp-3.4.0-py3-none-any.whl (5.2 kB)\nCollecting pycparser\n  Downloading pycparser-2.20-py2.py3-none-any.whl (112 kB)\nCollecting oauthlib&gt;=3.0.0\n  Downloading oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\nCollecting distro&gt;=1.2.0\n  Downloading distro-1.5.0-py2.py3-none-any.whl (18 kB)\nCollecting msal-extensions~=0.2.2\n  Downloading msal_extensions-0.2.2-py2.py3-none-any.whl (15 kB)\nCollecting azure-core&lt;2.0.0,&gt;=1.0.0\n  Downloading azure_core-1.8.2-py2.py3-none-any.whl (122 kB)\nCollecting msal&lt;2.0.0,&gt;=1.3.0\n  Downloading msal-1.6.0-py2.py3-none-any.whl (50 kB)\nCollecting portalocker~=1.0; platform_system != &#34;Windows&#34;\n  Downloading portalocker-1.7.1-py2.py3-none-any.whl (10 kB)\nBuilding wheels for collected packages: termcolor, gast, wrapt, fusepy\n  Building wheel for termcolor (setup.py): started\n  Building wheel for termcolor (setup.py): finished with status &#39;done&#39;\n  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4830 sha256=022d8a0b15fc3622a9852a09ef0407b34a011c08b6dbb24bfc52b6c0e4f2e61d\n  Stored in directory: /root/.cache/pip/wheels/93/2a/eb/e58dbcbc963549ee4f065ff80a59f274cc7210b6eab962acdc\n  Building wheel for gast (setup.py): started\n  Building wheel for gast (setup.py): finished with status &#39;done&#39;\n  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7540 sha256=cd0cedf226cb199609d0903ffcd0eccbb4e27b0bcf76b64618a87d404bb66eba\n  Stored in directory: /root/.cache/pip/wheels/19/a7/b9/0740c7a3a7d1d348f04823339274b90de25fbcd217b2ee1fbe\n  Building wheel for wrapt (setup.py): started\n  Building wheel for wrapt (setup.py): finished with status &#39;done&#39;\n  Created wheel for wrapt: filename=wrapt-1.12.1-cp36-cp36m-linux_x86_64.whl size=66285 sha256=932d29c4b04875ab9b0d3cd25e3eb63f05973503c42288042e10808aa99dd5ed\n  Stored in directory: /root/.cache/pip/wheels/32/42/7f/23cae9ff6ef66798d00dc5d659088e57dbba01566f6c60db63\n  Building wheel for fusepy (setup.py): started\n  Building wheel for fusepy (setup.py): finished with status &#39;done&#39;\n  Created wheel for fusepy: filename=fusepy-3.0.1-py3-none-any.whl size=10504 sha256=0f37d1c1dd3c3dc088aa1fa8cf981063d964e402bf81a997f3b0b6808d5858f1\n  Stored in directory: /root/.cache/pip/wheels/21/5c/83/1dd7e8a232d12227e5410120f4374b33adeb4037473105b079\nSuccessfully built termcolor gast wrapt fusepy\nInstalling collected packages: six, termcolor, numpy, cached-property, h5py, keras-applications, tensorflow-estimator, protobuf, absl-py, zipp, importlib-metadata, markdown, grpcio, werkzeug, tensorboard, gast, google-pasta, wrapt, astor, keras-preprocessing, opt-einsum, tensorflow-gpu, chardet, idna, urllib3, requests, oauthlib, requests-oauthlib, isodate, msrest, python-dateutil, PyJWT, pycparser, cffi, cryptography, adal, msrestazure, azure-common, azure-mgmt-authorization, pyopenssl, pyasn1, ndg-httpsclient, pathspec, websocket-client, docker, azure-mgmt-containerregistry, azure-mgmt-storage, backports.weakref, backports.tempfile, jmespath, azure-graphrbac, jsonpickle, jeepney, SecretStorage, pytz, azure-mgmt-keyvault, azure-mgmt-resource, contextlib2, ruamel.yaml.clib, ruamel.yaml, azureml-core, distro, dotnetcore2, cloudpickle, portalocker, msal, msal-extensions, azure-core, azure-identity, azureml-dataprep-rslex, azureml-dataprep-native, azureml-dataprep, pyarrow, fusepy, azureml-dataset-runtime\nSuccessfully installed PyJWT-1.7.1 SecretStorage-3.1.2 absl-py-0.11.0 adal-1.2.5 astor-0.8.1 azure-common-1.1.25 azure-core-1.8.2 azure-graphrbac-0.61.1 azure-identity-1.4.1 azure-mgmt-authorization-0.61.0 azure-mgmt-containerregistry-2.8.0 azure-mgmt-keyvault-2.2.0 azure-mgmt-resource-10.3.0 azure-mgmt-storage-11.2.0 azureml-core-1.17.0 azureml-dataprep-2.4.2 azureml-dataprep-native-24.0.0 azureml-dataprep-rslex-1.2.2 azureml-dataset-runtime-1.17.0 backports.tempfile-1.0 backports.weakref-1.0.post1 cached-property-1.5.2 cffi-1.14.3 chardet-3.0.4 cloudpickle-1.6.0 contextlib2-0.6.0.post1 cryptography-3.2.1 distro-1.5.0 docker-4.3.1 dotnetcore2-2.1.17 fusepy-3.0.1 gast-0.2.2 google-pasta-0.2.0 grpcio-1.33.2 h5py-3.0.0 idna-2.10 importlib-metadata-2.0.0 isodate-0.6.0 jeepney-0.4.3 jmespath-0.10.0 jsonpickle-1.4.1 keras-applications-1.0.8 keras-preprocessing-1.1.2 markdown-3.3.3 msal-1.6.0 msal-extensions-0.2.2 msrest-0.6.19 msrestazure-0.6.4 ndg-httpsclient-0.5.1 numpy-1.19.3 oauthlib-3.1.0 opt-einsum-3.3.0 pathspec-0.8.0 portalocker-1.7.1 protobuf-3.13.0 pyarrow-1.0.1 pyasn1-0.4.8 pycparser-2.20 pyopenssl-19.1.0 python-dateutil-2.8.1 pytz-2020.4 requests-2.24.0 requests-oauthlib-1.3.0 ruamel.yaml-0.16.12 ruamel.yaml.clib-0.2.2 six-1.15.0 tensorboard-1.15.0 tensorflow-estimator-1.15.1 tensorflow-gpu-1.15.2 termcolor-1.1.0 urllib3-1.25.11 websocket-client-0.57.0 werkzeug-1.0.1 wrapt-1.12.1 zipp-3.4.0\n\n#\n# To activate this environment, use\n#\n#     $ conda activate /azureml-envs/azureml_2fedf4d8b9700d1bbb353b132ff1f6aa\n#\n# To deactivate an active environment, use\n#\n#     $ conda deactivate\n\n<span class=\"ansi-red-intense-fg\">\n\n==&gt; WARNING: A newer version of conda exists. &lt;==\n  current version: 4.7.12\n  latest version: 4.9.1\n\nPlease update conda by running\n\n    $ conda update -n base -c defaults conda\n\n\n</span>WARNING: /root/.conda/pkgs does not exist\nRemoving intermediate container 5a08d5ad92d1\n ---&gt; 138c6bd3f1fb\nStep 9/15 : ENV PATH /azureml-envs/azureml_2fedf4d8b9700d1bbb353b132ff1f6aa/bin:$PATH\n ---&gt; Running in 33817c39b9bc\nRemoving intermediate container 33817c39b9bc\n ---&gt; 770a4379dec3\nStep 10/15 : ENV AZUREML_CONDA_ENVIRONMENT_PATH /azureml-envs/azureml_2fedf4d8b9700d1bbb353b132ff1f6aa\n ---&gt; Running in be865e788ecc\nRemoving intermediate container be865e788ecc\n ---&gt; d7b056ee2442\nStep 11/15 : ENV LD_LIBRARY_PATH /azureml-envs/azureml_2fedf4d8b9700d1bbb353b132ff1f6aa/lib:$LD_LIBRARY_PATH\n ---&gt; Running in 236a9a2995aa\nRemoving intermediate container 236a9a2995aa\n ---&gt; a762b124dfcd\nStep 12/15 : COPY azureml-environment-setup/spark_cache.py azureml-environment-setup/log4j.properties /azureml-environment-setup/\n ---&gt; fd0ebe6f9b49\nStep 13/15 : RUN if [ $SPARK_HOME ]; then /bin/bash -c &#39;$SPARK_HOME/bin/spark-submit  /azureml-environment-setup/spark_cache.py&#39;; fi\n ---&gt; Running in f45e1c367978\nRemoving intermediate container f45e1c367978\n ---&gt; a24f18d7db04\nStep 14/15 : ENV AZUREML_ENVIRONMENT_IMAGE True\n ---&gt; Running in 078f3261fac6\nRemoving intermediate container 078f3261fac6\n ---&gt; a51ffcb1acb1\nStep 15/15 : CMD [&#34;bash&#34;]\n ---&gt; Running in 7244718b5877\nRemoving intermediate container 7244718b5877\n ---&gt; 05c914e56f6c\nSuccessfully built 05c914e56f6c\nSuccessfully tagged f89c90464c5e495db4f6977a78dd3507.azurecr.io/azureml/azureml_2c0e7677eec783da9d8011e7f71bebe0:latest\n2020/11/02 10:41:30 Successfully executed container: acb_step_0\n2020/11/02 10:41:30 Executing step ID: acb_step_1. Timeout(sec): 5400, Working directory: &#39;&#39;, Network: &#39;acb_default_network&#39;\n2020/11/02 10:41:30 Pushing image: f89c90464c5e495db4f6977a78dd3507.azurecr.io/azureml/azureml_2c0e7677eec783da9d8011e7f71bebe0:latest, attempt 1\nThe push refers to repository [f89c90464c5e495db4f6977a78dd3507.azurecr.io/azureml/azureml_2c0e7677eec783da9d8011e7f71bebe0]\n5df860bd05f6: Preparing\na6657ca722c4: Preparing\nce9c01a1f34d: Preparing\nbbe4b2423595: Preparing\n696ca92ec92b: Preparing\n505490c18935: Preparing\n80e085142144: Preparing\n3d69c415d1f0: Preparing\ncf59bc701d30: Preparing\n3cf57cc1b3bc: Preparing\n019f14bc11c8: Preparing\n1f16665d954b: Preparing\na0c9064424e4: Preparing\n12d67fac46a2: Preparing\nc36fc92de581: Preparing\n524881d0563d: Preparing\nd05c249e6b9f: Preparing\nfc8a172f94e8: Preparing\n48001c8a7ddb: Preparing\n6dce9683cb41: Preparing\ne79142719515: Preparing\naeda103e78c9: Preparing\n2558e637fbff: Preparing\nf749b9b0fb21: Preparing\n505490c18935: Waiting\n80e085142144: Waiting\n3d69c415d1f0: Waiting\ncf59bc701d30: Waiting\n3cf57cc1b3bc: Waiting\n019f14bc11c8: Waiting\n1f16665d954b: Waiting\n12d67fac46a2: Waiting\nc36fc92de581: Waiting\n524881d0563d: Waiting\nd05c249e6b9f: Waiting\nfc8a172f94e8: Waiting\n48001c8a7ddb: Waiting\n6dce9683cb41: Waiting\ne79142719515: Waiting\naeda103e78c9: Waiting\n2558e637fbff: Waiting\nf749b9b0fb21: Waiting\nce9c01a1f34d: Pushed\n696ca92ec92b: Pushed\n5df860bd05f6: Pushed\nbbe4b2423595: Pushed\n505490c18935: Pushed\n80e085142144: Pushed\n3d69c415d1f0: Pushed\ncf59bc701d30: Pushed\na0c9064424e4: Pushed\n1f16665d954b: Pushed\n12d67fac46a2: Pushed\n\n3cf57cc1b3bc: Pushed\n019f14bc11c8: Pushed\nfc8a172f94e8: Pushed\n48001c8a7ddb: Pushed\n6dce9683cb41: Pushed\ne79142719515: Pushed\naeda103e78c9: Pushed\n2558e637fbff: Pushed\nc36fc92de581: Pushed\nd05c249e6b9f: Pushed\nf749b9b0fb21: Pushed\n\na6657ca722c4: Pushed\n524881d0563d: Pushed\n\n*** WARNING: skipped 4348 bytes of output ***\n\n0bb981bf8833: Verifying Checksum\n0bb981bf8833: Download complete\necaf719dacef: Download complete\n8996db0c4475: Verifying Checksum\n8996db0c4475: Download complete\n2e8512ab6543: Verifying Checksum\n2e8512ab6543: Download complete\nc11e9246d621: Pull complete\n0dfae24cbbd9: Pull complete\n0bb049a6d391: Pull complete\n1aef3da5021b: Pull complete\ne5f03d63d02d: Pull complete\n22533bcd68c8: Pull complete\na8c7deb5dc88: Pull complete\nef34b1adad4d: Pull complete\n87e1451a8ae7: Pull complete\n6a5d94939972: Pull complete\nf4b1ab4ce7b5: Pull complete\n9064eac28188: Pull complete\nad08533d07ce: Pull complete\necaf719dacef: Pull complete\n0bb981bf8833: Pull complete\n\nStreaming azureml-logs/65_job_prep-tvmps_0092ff0627db1719f1dc92ad318b9b246d39f255767ec5d408b3a9d4f88afe26_p.txt\n===============================================================================================================\n[2020-11-02T10:52:50.507766] Entering job preparation.\n[2020-11-02T10:52:51.805589] Starting job preparation.\n[2020-11-02T10:52:51.805626] Extracting the control code.\n[2020-11-02T10:52:51.854715] fetching and extracting the control code on master node.\n[2020-11-02T10:52:51.854742] Starting extract_project.\n[2020-11-02T10:52:51.854779] Starting to extract zip file.\n[2020-11-02T10:52:53.087080] Finished extracting zip file.\n[2020-11-02T10:52:53.381240] Using urllib.request Python 3.0 or later\n[2020-11-02T10:52:53.381285] Start fetching snapshots.\n[2020-11-02T10:52:53.381324] Start fetching snapshot.\n[2020-11-02T10:52:53.381340] Retrieving project from snapshot: bc4707f2-8238-4b2b-8245-721624425091\nStarting the daemon thread to refresh tokens in background for process with pid = 62\n[2020-11-02T10:52:53.821346] Finished fetching snapshot.\n[2020-11-02T10:52:53.821369] Start fetching snapshot.\n[2020-11-02T10:52:53.821382] Retrieving project from snapshot: 0d50123e-1570-4370-b7cf-aa0e648e06a9\n[2020-11-02T10:53:02.588200] Finished fetching snapshot.\n[2020-11-02T10:53:02.588231] Finished fetching snapshots.\n[2020-11-02T10:53:02.588242] Finished extract_project.\n[2020-11-02T10:53:02.619785] Finished fetching and extracting the control code.\n[2020-11-02T10:53:02.622165] downloadDataStore - Download from datastores if requested.\n[2020-11-02T10:53:02.623023] Start run_history_prep.\n[2020-11-02T10:53:02.702578] Entering context manager injector.\nAcquired lockfile /tmp/70f76633-260a-4c25-967f-ea40e74b5983-datastore.lock to downloading input data references\n[2020-11-02T10:53:03.951917] downloadDataStore completed\n[2020-11-02T10:53:03.954753] Job preparation is complete.\n\nStreaming azureml-logs/70_driver_log.txt\n========================================\n2020/11/02 10:53:05 logger.go:297: Attempt 1 of http call to http://10.0.0.5:16384/sendlogstoartifacts/info\n2020/11/02 10:53:05 logger.go:297: Attempt 1 of http call to http://10.0.0.5:16384/sendlogstoartifacts/status\n[2020-11-02T10:53:06.860730] Entering context manager injector.\n[context_manager_injector.py] Command line Options: Namespace(inject=[&#39;ProjectPythonPath:context_managers.ProjectPythonPath&#39;, &#39;Dataset:context_managers.Datasets&#39;, &#39;RunHistory:context_managers.RunHistory&#39;, &#39;TrackUserError:context_managers.TrackUserError&#39;, &#39;UserExceptions:context_managers.UserExceptions&#39;], invocation=[&#39;driver/amlbi_main.py&#39;, &#39;--client_sdk_version&#39;, &#39;1.17.0&#39;, &#39;--scoring_module_name&#39;, &#39;batch_scoring.py&#39;, &#39;--mini_batch_size&#39;, &#39;20&#39;, &#39;--error_threshold&#39;, &#39;1&#39;, &#39;--output_action&#39;, &#39;append_row&#39;, &#39;--logging_level&#39;, &#39;INFO&#39;, &#39;--run_invocation_timeout&#39;, &#39;60&#39;, &#39;--run_max_try&#39;, &#39;3&#39;, &#39;--create_snapshot_at_runtime&#39;, &#39;True&#39;, &#39;--append_row_file_name&#39;, &#39;parallel_run_step.txt&#39;, &#39;--output&#39;, &#39;/mnt/batch/tasks/shared/LS_root/jobs/vlk-workspace/azureml/70f76633-260a-4c25-967f-ea40e74b5983/mounts/workspaceblobstore/azureml/70f76633-260a-4c25-967f-ea40e74b5983/scores&#39;, &#39;--process_count_per_node&#39;, &#39;2&#39;, &#39;--model_name&#39;, &#39;inception&#39;, &#39;--labels_dir&#39;, &#39;DatasetConsumptionConfig:labels_input&#39;, &#39;--input_fds_0&#39;, &#39;input_images&#39;])\nInitialize DatasetContextManager.\nStarting the daemon thread to refresh tokens in background for process with pid = 128\nSet Dataset input_images&#39;s target path to /tmp/tmp0uzkd6at\nSet Dataset labels_input&#39;s target path to /tmp/tmp0z68irne\nEnter __enter__ of DatasetContextManager\nSDK version: azureml-core==1.17.0 azureml-dataprep==2.4.2. Session id: 0b50dba5-af29-45f5-85b5-ff2d852661e5. Run id: 70f76633-260a-4c25-967f-ea40e74b5983.\nProcessing &#39;input_images&#39;.\nProcessing dataset FileDataset\n{\n  &#34;source&#34;: [\n    &#34;(&#39;images_datastore&#39;, &#39;batchscoring/images/&#39;)&#34;\n  ],\n  &#34;definition&#34;: [\n    &#34;GetDatastoreFiles&#34;\n  ],\n  &#34;registration&#34;: {\n    &#34;id&#34;: &#34;6b7aefe9-2af6-494d-9ec6-7455fefdbcde&#34;,\n    &#34;name&#34;: &#34;input_images&#34;,\n    &#34;version&#34;: 1,\n    &#34;workspace&#34;: &#34;Workspace.create(name=&#39;vlk-workspace&#39;, subscription_id=&#39;d30d76c0-804c-4f4e-ab7b-509d06a49550&#39;, resource_group=&#39;vlk-workshop&#39;)&#34;\n  }\n}\nMounting input_images to /tmp/tmp0uzkd6at.\nCannot find cached workspace due to: KeyError(&#39;d30d76c0-804c-4f4e-ab7b-509d06a49550vlk-workshopvlk-workspace&#39;,)\nMounted input_images to /tmp/tmp0uzkd6at as folder.\nProcessing &#39;labels_input&#39;.\nProcessing dataset FileDataset\n{\n  &#34;source&#34;: [\n    &#34;(&#39;images_datastore&#39;, &#39;batchscoring/labels/&#39;)&#34;\n  ],\n  &#34;definition&#34;: [\n    &#34;GetDatastoreFiles&#34;\n  ],\n  &#34;registration&#34;: {\n    &#34;id&#34;: &#34;a091a995-2e8c-4def-806d-e4f1a40478a6&#34;,\n    &#34;name&#34;: &#34;label_ds&#34;,\n    &#34;version&#34;: 1,\n    &#34;workspace&#34;: &#34;Workspace.create(name=&#39;vlk-workspace&#39;, subscription_id=&#39;d30d76c0-804c-4f4e-ab7b-509d06a49550&#39;, resource_group=&#39;vlk-workshop&#39;)&#34;\n  }\n}\nMounting labels_input to /tmp/tmp0z68irne.\nWARNING - Already registered authentication for run id: 70f76633-260a-4c25-967f-ea40e74b5983\nCannot find cached workspace due to: KeyError(&#39;d30d76c0-804c-4f4e-ab7b-509d06a49550vlk-workshopvlk-workspace&#39;,)\nMounted labels_input to /tmp/tmp0z68irne as folder.\nExit __enter__ of DatasetContextManager\nEntering Run History Context Manager.\nCurrent directory:  /mnt/batch/tasks/shared/LS_root/jobs/vlk-workspace/azureml/70f76633-260a-4c25-967f-ea40e74b5983/mounts/workspaceblobstore/azureml/70f76633-260a-4c25-967f-ea40e74b5983\nPreparing to call script [ driver/amlbi_main.py ] with arguments: [&#39;--client_sdk_version&#39;, &#39;1.17.0&#39;, &#39;--scoring_module_name&#39;, &#39;batch_scoring.py&#39;, &#39;--mini_batch_size&#39;, &#39;20&#39;, &#39;--error_threshold&#39;, &#39;1&#39;, &#39;--output_action&#39;, &#39;append_row&#39;, &#39;--logging_level&#39;, &#39;INFO&#39;, &#39;--run_invocation_timeout&#39;, &#39;60&#39;, &#39;--run_max_try&#39;, &#39;3&#39;, &#39;--create_snapshot_at_runtime&#39;, &#39;True&#39;, &#39;--append_row_file_name&#39;, &#39;parallel_run_step.txt&#39;, &#39;--output&#39;, &#39;/mnt/batch/tasks/shared/LS_root/jobs/vlk-workspace/azureml/70f76633-260a-4c25-967f-ea40e74b5983/mounts/workspaceblobstore/azureml/70f76633-260a-4c25-967f-ea40e74b5983/scores&#39;, &#39;--process_count_per_node&#39;, &#39;2&#39;, &#39;--model_name&#39;, &#39;inception&#39;, &#39;--labels_dir&#39;, &#39;$labels_input&#39;, &#39;--input_fds_0&#39;, &#39;input_images&#39;]\nAfter variable expansion, calling script [ driver/amlbi_main.py ] with arguments: [&#39;--client_sdk_version&#39;, &#39;1.17.0&#39;, &#39;--scoring_module_name&#39;, &#39;batch_scoring.py&#39;, &#39;--mini_batch_size&#39;, &#39;20&#39;, &#39;--error_threshold&#39;, &#39;1&#39;, &#39;--output_action&#39;, &#39;append_row&#39;, &#39;--logging_level&#39;, &#39;INFO&#39;, &#39;--run_invocation_timeout&#39;, &#39;60&#39;, &#39;--run_max_try&#39;, &#39;3&#39;, &#39;--create_snapshot_at_runtime&#39;, &#39;True&#39;, &#39;--append_row_file_name&#39;, &#39;parallel_run_step.txt&#39;, &#39;--output&#39;, &#39;/mnt/batch/tasks/shared/LS_root/jobs/vlk-workspace/azureml/70f76633-260a-4c25-967f-ea40e74b5983/mounts/workspaceblobstore/azureml/70f76633-260a-4c25-967f-ea40e74b5983/scores&#39;, &#39;--process_count_per_node&#39;, &#39;2&#39;, &#39;--model_name&#39;, &#39;inception&#39;, &#39;--labels_dir&#39;, &#39;/tmp/tmp0z68irne&#39;, &#39;--input_fds_0&#39;, &#39;input_images&#39;]\n\nScript type = None\nWARNING - \nThe TensorFlow contrib module will not be included in TensorFlow 2.0.\nFor more information, please see:\n  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n  * https://github.com/tensorflow/addons\n  * https://github.com/tensorflow/io (for I/O related ops)\nIf you depend on functionality not listed there, please file an issue.\n\nCannot find cached workspace due to: KeyError(&#39;d30d76c0-804c-4f4e-ab7b-509d06a49550vlk-workshopvlk-workspace&#39;,)\nCannot find cached workspace due to: KeyError(&#39;d30d76c0-804c-4f4e-ab7b-509d06a49550vlk-workshopvlk-workspace&#39;,)\n\nStreaming azureml-logs/75_job_post-tvmps_0092ff0627db1719f1dc92ad318b9b246d39f255767ec5d408b3a9d4f88afe26_p.txt\n===============================================================================================================\nEntering job release. Current time:2020-11-02T10:55:04.260590\nStarting job release. Current time:2020-11-02T10:55:05.144686\nLogging experiment finalizing status in history service.\nStarting the daemon thread to refresh tokens in background for process with pid = 910\n[2020-11-02T10:55:05.145568] job release stage : upload_datastore starting...\n[{}] job release stage : start importing azureml.history._tracking in run_history_release.\n[2020-11-02T10:55:05.147973] job release stage : execute_job_release starting...\n[2020-11-02T10:55:05.154686] job release stage : copy_batchai_cached_logs starting...\n[2020-11-02T10:55:05.154729] job release stage : copy_batchai_cached_logs completed...\n[2020-11-02T10:55:05.155637] Entering context manager injector.\n[2020-11-02T10:55:05.345492] job release stage : upload_datastore completed...\n[2020-11-02T10:55:05.375453] job release stage : send_run_telemetry starting...\n[2020-11-02T10:55:05.495124] job release stage : execute_job_release completed...\n[2020-11-02T10:55:06.294308] job release stage : send_run_telemetry completed...\nJob release is complete. Current time:2020-11-02T10:55:06.294496\n\nStepRun(batchscoring-202011021034) Execution Summary\n=====================================================\nStepRun( batchscoring-202011021034 ) Status: Finished\n{&#39;runId&#39;: &#39;70f76633-260a-4c25-967f-ea40e74b5983&#39;, &#39;target&#39;: &#39;gpu-cluster&#39;, &#39;status&#39;: &#39;Completed&#39;, &#39;startTimeUtc&#39;: &#39;2020-11-02T10:50:44.846109Z&#39;, &#39;endTimeUtc&#39;: &#39;2020-11-02T10:55:13.14022Z&#39;, &#39;properties&#39;: {&#39;azureml.runsource&#39;: &#39;azureml.StepRun&#39;, &#39;ContentSnapshotId&#39;: &#39;bc4707f2-8238-4b2b-8245-721624425091&#39;, &#39;StepType&#39;: &#39;PythonScriptStep&#39;, &#39;ComputeTargetType&#39;: &#39;AmlCompute&#39;, &#39;azureml.moduleid&#39;: &#39;215fd82b-5329-49eb-ab98-f1a369fb4367&#39;, &#39;azureml.nodeid&#39;: &#39;e8e874c6&#39;, &#39;azureml.pipelinerunid&#39;: &#39;3df13f5a-5048-484e-8a45-a40881189ca3&#39;, &#39;_azureml.ComputeTargetType&#39;: &#39;amlcompute&#39;, &#39;ProcessInfoFile&#39;: &#39;azureml-logs/process_info.json&#39;, &#39;ProcessStatusFile&#39;: &#39;azureml-logs/process_status.json&#39;, &#39;azureml.parallelrunstep&#39;: &#39;true&#39;}, &#39;inputDatasets&#39;: [{&#39;dataset&#39;: {&#39;id&#39;: &#39;6b7aefe9-2af6-494d-9ec6-7455fefdbcde&#39;}, &#39;consumptionDetails&#39;: {&#39;type&#39;: &#39;RunInput&#39;, &#39;inputName&#39;: &#39;input_images&#39;, &#39;mechanism&#39;: &#39;Mount&#39;}}, {&#39;dataset&#39;: {&#39;id&#39;: &#39;a091a995-2e8c-4def-806d-e4f1a40478a6&#39;}, &#39;consumptionDetails&#39;: {&#39;type&#39;: &#39;RunInput&#39;, &#39;inputName&#39;: &#39;labels_input&#39;, &#39;mechanism&#39;: &#39;Mount&#39;}}], &#39;outputDatasets&#39;: [], &#39;runDefinition&#39;: {&#39;script&#39;: &#39;driver/amlbi_main.py&#39;, &#39;command&#39;: [], &#39;useAbsolutePath&#39;: False, &#39;arguments&#39;: [&#39;--client_sdk_version&#39;, &#39;1.17.0&#39;, &#39;--scoring_module_name&#39;, &#39;batch_scoring.py&#39;, &#39;--mini_batch_size&#39;, &#39;20&#39;, &#39;--error_threshold&#39;, &#39;1&#39;, &#39;--output_action&#39;, &#39;append_row&#39;, &#39;--logging_level&#39;, &#39;INFO&#39;, &#39;--run_invocation_timeout&#39;, &#39;60&#39;, &#39;--run_max_try&#39;, &#39;3&#39;, &#39;--create_snapshot_at_runtime&#39;, &#39;True&#39;, &#39;--append_row_file_name&#39;, &#39;parallel_run_step.txt&#39;, &#39;--output&#39;, &#39;$AZUREML_DATAREFERENCE_scores&#39;, &#39;--process_count_per_node&#39;, &#39;2&#39;, &#39;--model_name&#39;, &#39;inception&#39;, &#39;--labels_dir&#39;, &#39;DatasetConsumptionConfig:labels_input&#39;, &#39;--input_fds_0&#39;, &#39;input_images&#39;], &#39;sourceDirectoryDataStore&#39;: None, &#39;framework&#39;: &#39;Python&#39;, &#39;communicator&#39;: &#39;None&#39;, &#39;target&#39;: &#39;gpu-cluster&#39;, &#39;dataReferences&#39;: {&#39;scores&#39;: {&#39;dataStoreName&#39;: &#39;workspaceblobstore&#39;, &#39;mode&#39;: &#39;Mount&#39;, &#39;pathOnDataStore&#39;: &#39;azureml/70f76633-260a-4c25-967f-ea40e74b5983/scores&#39;, &#39;pathOnCompute&#39;: None, &#39;overwrite&#39;: False}}, &#39;data&#39;: {&#39;input_images&#39;: {&#39;dataLocation&#39;: {&#39;dataset&#39;: {&#39;id&#39;: &#39;6b7aefe9-2af6-494d-9ec6-7455fefdbcde&#39;, &#39;name&#39;: None, &#39;version&#39;: &#39;1&#39;}, &#39;dataPath&#39;: None}, &#39;mechanism&#39;: &#39;Mount&#39;, &#39;environmentVariableName&#39;: &#39;input_images&#39;, &#39;pathOnCompute&#39;: None, &#39;overwrite&#39;: False}, &#39;labels_input&#39;: {&#39;dataLocation&#39;: {&#39;dataset&#39;: {&#39;id&#39;: &#39;a091a995-2e8c-4def-806d-e4f1a40478a6&#39;, &#39;name&#39;: None, &#39;version&#39;: &#39;1&#39;}, &#39;dataPath&#39;: None}, &#39;mechanism&#39;: &#39;Mount&#39;, &#39;environmentVariableName&#39;: &#39;labels_input&#39;, &#39;pathOnCompute&#39;: None, &#39;overwrite&#39;: False}}, &#39;outputData&#39;: {}, &#39;jobName&#39;: None, &#39;maxRunDurationSeconds&#39;: None, &#39;nodeCount&#39;: 1, &#39;priority&#39;: None, &#39;environment&#39;: {&#39;name&#39;: &#39;parallelenv&#39;, &#39;version&#39;: &#39;Autosave_2020-11-02T10:36:49Z_7b9b48a4&#39;, &#39;python&#39;: {&#39;interpreterPath&#39;: &#39;python&#39;, &#39;userManagedDependencies&#39;: False, &#39;condaDependencies&#39;: {&#39;channels&#39;: [&#39;anaconda&#39;, &#39;conda-forge&#39;], &#39;dependencies&#39;: [&#39;python=3.6.2&#39;, {&#39;pip&#39;: [&#39;tensorflow-gpu==1.15.2&#39;, &#39;azureml-core~=1.17.0&#39;, &#39;azureml-dataset-runtime[fuse]~=1.17.0&#39;]}], &#39;name&#39;: &#39;azureml_2fedf4d8b9700d1bbb353b132ff1f6aa&#39;}, &#39;baseCondaEnvironment&#39;: None}, &#39;environmentVariables&#39;: {&#39;EXAMPLE_ENV_VAR&#39;: &#39;EXAMPLE_VALUE&#39;}, &#39;docker&#39;: {&#39;baseImage&#39;: &#39;mcr.microsoft.com/azureml/intelmpi2018.3-cuda10.0-cudnn7-ubuntu16.04:20200821.v1&#39;, &#39;platform&#39;: {&#39;os&#39;: &#39;Linux&#39;, &#39;architecture&#39;: &#39;amd64&#39;}, &#39;baseDockerfile&#39;: None, &#39;baseImageRegistry&#39;: {&#39;address&#39;: None, &#39;username&#39;: None, &#39;password&#39;: None}, &#39;enabled&#39;: True, &#39;arguments&#39;: []}, &#39;spark&#39;: {&#39;repositories&#39;: [], &#39;packages&#39;: [], &#39;precachePackages&#39;: True}, &#39;inferencingStackVersion&#39;: None}, &#39;history&#39;: {&#39;outputCollection&#39;: True, &#39;directoriesToWatch&#39;: [&#39;logs&#39;], &#39;enableMLflowTracking&#39;: True, &#39;snapshotProject&#39;: True}, &#39;spark&#39;: {&#39;configuration&#39;: {&#39;spark.app.name&#39;: &#39;Azure ML Experiment&#39;, &#39;spark.yarn.maxAppAttempts&#39;: &#39;1&#39;}}, &#39;parallelTask&#39;: {&#39;maxRetriesPerWorker&#39;: 0, &#39;workerCountPerNode&#39;: 1, &#39;terminalExitCodes&#39;: None, &#39;configuration&#39;: {}}, &#39;amlCompute&#39;: {&#39;name&#39;: None, &#39;vmSize&#39;: None, &#39;retainCluster&#39;: False, &#39;clusterMaxNodeCount&#39;: 1}, &#39;aiSuperComputer&#39;: {&#39;instanceType&#39;: None, &#39;frameworkImage&#39;: None, &#39;imageVersion&#39;: None, &#39;location&#39;: None}, &#39;tensorflow&#39;: {&#39;workerCount&#39;: 1, &#39;parameterServerCount&#39;: 1}, &#39;mpi&#39;: {&#39;processCountPerNode&#39;: 1}, &#39;hdi&#39;: {&#39;yarnDeployMode&#39;: &#39;Cluster&#39;}, &#39;containerInstance&#39;: {&#39;region&#39;: None, &#39;cpuCores&#39;: 2.0, &#39;memoryGb&#39;: 3.5}, &#39;exposedPorts&#39;: None, &#39;docker&#39;: {&#39;useDocker&#39;: True, &#39;sharedVolumes&#39;: True, &#39;shmSize&#39;: &#39;2g&#39;, &#39;arguments&#39;: []}, &#39;cmk8sCompute&#39;: {&#39;configuration&#39;: {}}, &#39;globalJobDispatcher&#39;: {&#39;vmSize&#39;: []}}, &#39;logFiles&#39;: {&#39;azureml-logs/20_image_build_log.txt&#39;: &#39;https://vlkworkspace8006493384.blob.core.windows.net/azureml/ExperimentRun/dcid.70f76633-260a-4c25-967f-ea40e74b5983/azureml-logs/20_image_build_log.txt?sv=2019-02-02&amp;sr=b&amp;sig=x2rRDFCUwDil%2FPXFPteZ98ATTjV%2BOArrAEFtlAj7u2Q%3D&amp;st=2020-11-02T10%3A45%3A07Z&amp;se=2020-11-02T18%3A55%3A07Z&amp;sp=r&#39;, &#39;azureml-logs/55_azureml-execution-tvmps_0092ff0627db1719f1dc92ad318b9b246d39f255767ec5d408b3a9d4f88afe26_p.txt&#39;: &#39;https://vlkworkspace8006493384.blob.core.windows.net/azureml/ExperimentRun/dcid.70f76633-260a-4c25-967f-ea40e74b5983/azureml-logs/55_azureml-execution-tvmps_0092ff0627db1719f1dc92ad318b9b246d39f255767ec5d408b3a9d4f88afe26_p.txt?sv=2019-02-02&amp;sr=b&amp;sig=%2FUhMpo5hAOhWAicEA93C55IrbrTKFp6ES1W2kPBYLyQ%3D&amp;st=2020-11-02T10%3A45%3A07Z&amp;se=2020-11-02T18%3A55%3A07Z&amp;sp=r&#39;, &#39;azureml-logs/65_job_prep-tvmps_0092ff0627db1719f1dc92ad318b9b246d39f255767ec5d408b3a9d4f88afe26_p.txt&#39;: &#39;https://vlkworkspace8006493384.blob.core.windows.net/azureml/ExperimentRun/dcid.70f76633-260a-4c25-967f-ea40e74b5983/azureml-logs/65_job_prep-tvmps_0092ff0627db1719f1dc92ad318b9b246d39f255767ec5d408b3a9d4f88afe26_p.txt?sv=2019-02-02&amp;sr=b&amp;sig=J5%2FKs3TGxvzNHT5QKCENPaEwIgCYKqZivxec9IKRvMI%3D&amp;st=2020-11-02T10%3A45%3A07Z&amp;se=2020-11-02T18%3A55%3A07Z&amp;sp=r&#39;, &#39;azureml-logs/70_driver_log.txt&#39;: &#39;https://vlkworkspace8006493384.blob.core.windows.net/azureml/ExperimentRun/dcid.70f76633-260a-4c25-967f-ea40e74b5983/azureml-logs/70_driver_log.txt?sv=2019-02-02&amp;sr=b&amp;sig=f8ffzbzGXzNJd4JRyckHuG9RQTx%2BmErPQmQfTbLXysE%3D&amp;st=2020-11-02T10%3A45%3A07Z&amp;se=2020-11-02T18%3A55%3A07Z&amp;sp=r&#39;, &#39;azureml-logs/75_job_post-tvmps_0092ff0627db1719f1dc92ad318b9b246d39f255767ec5d408b3a9d4f88afe26_p.txt&#39;: &#39;https://vlkworkspace8006493384.blob.core.windows.net/azureml/ExperimentRun/dcid.70f76633-260a-4c25-967f-ea40e74b5983/azureml-logs/75_job_post-tvmps_0092ff0627db1719f1dc92ad318b9b246d39f255767ec5d408b3a9d4f88afe26_p.txt?sv=2019-02-02&amp;sr=b&amp;sig=LmuTBtygKCQnwXBWPG9ewvsDF2j0qzb1HtupGG4C0UY%3D&amp;st=2020-11-02T10%3A45%3A07Z&amp;se=2020-11-02T18%3A55%3A07Z&amp;sp=r&#39;, &#39;azureml-logs/process_info.json&#39;: &#39;https://vlkworkspace8006493384.blob.core.windows.net/azureml/ExperimentRun/dcid.70f76633-260a-4c25-967f-ea40e74b5983/azureml-logs/process_info.json?sv=2019-02-02&amp;sr=b&amp;sig=FAghgdt87DpvHV20gip6S64gsV7uXwII27NYeZqRcSo%3D&amp;st=2020-11-02T10%3A45%3A07Z&amp;se=2020-11-02T18%3A55%3A07Z&amp;sp=r&#39;, &#39;azureml-logs/process_status.json&#39;: &#39;https://vlkworkspace8006493384.blob.core.windows.net/azureml/ExperimentRun/dcid.70f76633-260a-4c25-967f-ea40e74b5983/azureml-logs/process_status.json?sv=2019-02-02&amp;sr=b&amp;sig=zStoUnUh1%2B8dMXYFFBIgz%2Bg4TzNVfEhCxA4Iy5B%2BHl8%3D&amp;st=2020-11-02T10%3A45%3A07Z&amp;se=2020-11-02T18%3A55%3A07Z&amp;sp=r&#39;, &#39;logs/azureml/128_azureml.log&#39;: &#39;https://vlkworkspace8006493384.blob.core.windows.net/azureml/ExperimentRun/dcid.70f76633-260a-4c25-967f-ea40e74b5983/logs/azureml/128_azureml.log?sv=2019-02-02&amp;sr=b&amp;sig=Sl71E6u1erLYR80mtb18wOLsYjwS5%2FuXIXexvkE64%2BQ%3D&amp;st=2020-11-02T10%3A45%3A07Z&amp;se=2020-11-02T18%3A55%3A07Z&amp;sp=r&#39;, &#39;logs/azureml/dataprep/backgroundProcess.log&#39;: &#39;https://vlkworkspace8006493384.blob.core.windows.net/azureml/ExperimentRun/dcid.70f76633-260a-4c25-967f-ea40e74b5983/logs/azureml/dataprep/backgroundProcess.log?sv=2019-02-02&amp;sr=b&amp;sig=tpvFcbQWtryVgkuoA9g3SVYXcF0sQCJRH2e6d0RAThg%3D&amp;st=2020-11-02T10%3A45%3A07Z&amp;se=2020-11-02T18%3A55%3A07Z&amp;sp=r&#39;, &#39;logs/azureml/dataprep/backgroundProcess_Telemetry.log&#39;: &#39;https://vlkworkspace8006493384.blob.core.windows.net/azureml/ExperimentRun/dcid.70f76633-260a-4c25-967f-ea40e74b5983/logs/azureml/dataprep/backgroundProcess_Telemetry.log?sv=2019-02-02&amp;sr=b&amp;sig=lPdv0gLdrzgoU2NlRB0KiUZEA%2BDyOgO0AEg0t1XKOdM%3D&amp;st=2020-11-02T10%3A45%3A07Z&amp;se=2020-11-02T18%3A55%3A07Z&amp;sp=r&#39;, &#39;logs/azureml/dataprep/engine_spans_l_2c7c31cd-013d-4808-912c-eaebdd4b1914.jsonl&#39;: &#39;https://vlkworkspace8006493384.blob.core.windows.net/azureml/ExperimentRun/dcid.70f76633-260a-4c25-967f-ea40e74b5983/logs/azureml/dataprep/engine_spans_l_2c7c31cd-013d-4808-912c-eaebdd4b1914.jsonl?sv=2019-02-02&amp;sr=b&amp;sig=dWZJJWHqTkfUC5rMy3cXj7kARTmvpapwTPl5uyubx2k%3D&amp;st=2020-11-02T10%3A45%3A07Z&amp;se=2020-11-02T18%3A55%3A07Z&amp;sp=r&#39;, &#39;logs/azureml/dataprep/engine_spans_l_47ed807e-26ff-4e83-947e-04481221881f.jsonl&#39;: &#39;https://vlkworkspace8006493384.blob.core.windows.net/azureml/ExperimentRun/dcid.70f76633-260a-4c25-967f-ea40e74b5983/logs/azureml/dataprep/engine_spans_l_47ed807e-26ff-4e83-947e-04481221881f.jsonl?sv=2019-02-02&amp;sr=b&amp;sig=%2B3hfG1ja%2FqZn%2FElaKf1B6DJHp5zlHTj1H27XVCXWID4%3D&amp;st=2020-11-02T10%3A45%3A07Z&amp;se=2020-11-02T18%3A55%3A07Z&amp;sp=r&#39;, &#39;logs/azureml/dataprep/engine_spans_l_cd977402-eab9-410c-8162-1029929988f2.jsonl&#39;: &#39;https://vlkworkspace8006493384.blob.core.windows.net/azureml/ExperimentRun/dcid.70f76633-260a-4c25-967f-ea40e74b5983/logs/azureml/dataprep/engine_spans_l_cd977402-eab9-410c-8162-1029929988f2.jsonl?sv=2019-02-02&amp;sr=b&amp;sig=w17x7WAy1peIGq9eCVWK7hyKYmRfvERddtcQnCgdvFg%3D&amp;st=2020-11-02T10%3A45%3A07Z&amp;se=2020-11-02T18%3A55%3A07Z&amp;sp=r&#39;, &#39;logs/azureml/dataprep/python_span_33403279-dd4b-4ae2-9570-1d3277f68071.jsonl&#39;: &#39;https://vlkworkspace8006493384.blob.core.windows.net/azureml/ExperimentRun/dcid.70f76633-260a-4c25-967f-ea40e74b5983/logs/azureml/dataprep/python_span_33403279-dd4b-4ae2-9570-1d3277f68071.jsonl?sv=2019-02-02&amp;sr=b&amp;sig=B22i7UQ6BNbAScXO9Eyj2YXUKvvjWsriutHEczSUzPc%3D&amp;st=2020-11-02T10%3A45%3A07Z&amp;se=2020-11-02T18%3A55%3A07Z&amp;sp=r&#39;, &#39;logs/azureml/dataprep/python_span_46df6ed2-ecc5-4163-955f-603d5a261da6.jsonl&#39;: &#39;https://vlkworkspace8006493384.blob.core.windows.net/azureml/ExperimentRun/dcid.70f76633-260a-4c25-967f-ea40e74b5983/logs/azureml/dataprep/python_span_46df6ed2-ecc5-4163-955f-603d5a261da6.jsonl?sv=2019-02-02&amp;sr=b&amp;sig=kAS%2FpsIIT22%2B7e8yrW9hRYiMqQgUXpFBNoRId2bvHLg%3D&amp;st=2020-11-02T10%3A45%3A07Z&amp;se=2020-11-02T18%3A55%3A07Z&amp;sp=r&#39;, &#39;logs/azureml/dataprep/python_span_l_0b691dcb-8165-4ce4-888d-ec1b7d9b784d.jsonl&#39;: &#39;https://vlkworkspace8006493384.blob.core.windows.net/azureml/ExperimentRun/dcid.70f76633-260a-4c25-967f-ea40e74b5983/logs/azureml/dataprep/python_span_l_0b691dcb-8165-4ce4-888d-ec1b7d9b784d.jsonl?sv=2019-02-02&amp;sr=b&amp;sig=1nerINsR93B99Luduz201oRr8zdjZDb2cfgfnbxjjKc%3D&amp;st=2020-11-02T10%3A45%3A07Z&amp;se=2020-11-02T18%3A55%3A07Z&amp;sp=r&#39;, &#39;logs/azureml/dataprep/python_span_l_2c7c31cd-013d-4808-912c-eaebdd4b1914.jsonl&#39;: &#39;https://vlkworkspace8006493384.blob.core.windows.net/azureml/ExperimentRun/dcid.70f76633-260a-4c25-967f-ea40e74b5983/logs/azureml/dataprep/python_span_l_2c7c31cd-013d-4808-912c-eaebdd4b1914.jsonl?sv=2019-02-02&amp;sr=b&amp;sig=MLhqBQ70hH96%2FLGmCNrqpeX8xjaf9KkBoUW0z7CdvII%3D&amp;st=2020-11-02T10%3A45%3A07Z&amp;se=2020-11-02T18%3A55%3A07Z&amp;sp=r&#39;, &#39;logs/azureml/dataprep/python_span_l_47ed807e-26ff-4e83-947e-04481221881f.jsonl&#39;: &#39;https://vlkworkspace8006493384.blob.core.windows.net/azureml/ExperimentRun/dcid.70f76633-260a-4c25-967f-ea40e74b5983/logs/azureml/dataprep/python_span_l_47ed807e-26ff-4e83-947e-04481221881f.jsonl?sv=2019-02-02&amp;sr=b&amp;sig=Xffgfdw4AOn5jva3%2FcirS2oLe3DnZVnHo1u3XGwgcns%3D&amp;st=2020-11-02T10%3A45%3A07Z&amp;se=2020-11-02T18%3A55%3A07Z&amp;sp=r&#39;, &#39;logs/azureml/dataprep/python_span_l_cd977402-eab9-410c-8162-1029929988f2.jsonl&#39;: &#39;https://vlkworkspace8006493384.blob.core.windows.net/azureml/ExperimentRun/dcid.70f76633-260a-4c25-967f-ea40e74b5983/logs/azureml/dataprep/python_span_l_cd977402-eab9-410c-8162-1029929988f2.jsonl?sv=2019-02-02&amp;sr=b&amp;sig=yCbG4v5mpjJ0Kfy1cmYBL%2B8JHjEN%2FdiJff0lsaisLU8%3D&amp;st=2020-11-02T10%3A45%3A07Z&amp;se=2020-11-02T18%3A55%3A07Z&amp;sp=r&#39;, &#39;logs/azureml/dataprep/python_span_l_de6ea322-1579-47a9-98e4-0efe5c0cb6a9.jsonl&#39;: &#39;https://vlkworkspace8006493384.blob.core.windows.net/azureml/ExperimentRun/dcid.70f76633-260a-4c25-967f-ea40e74b5983/logs/azureml/dataprep/python_span_l_de6ea322-1579-47a9-98e4-0efe5c0cb6a9.jsonl?sv=2019-02-02&amp;sr=b&amp;sig=iTeQ4LtAzqIm4P8QNWncwUP%2Fm4AT4ce41tivgETfj%2BQ%3D&amp;st=2020-11-02T10%3A45%3A07Z&amp;se=2020-11-02T18%3A55%3A07Z&amp;sp=r&#39;, &#39;logs/azureml/executionlogs.txt&#39;: &#39;https://vlkworkspace8006493384.blob.core.windows.net/azureml/ExperimentRun/dcid.70f76633-260a-4c25-967f-ea40e74b5983/logs/azureml/executionlogs.txt?sv=2019-02-02&amp;sr=b&amp;sig=Q%2BFdXNJZS6dUWOns1zm7vLJnAj3gj93mp7C7a4b3blQ%3D&amp;st=2020-11-02T10%3A45%3A07Z&amp;se=2020-11-02T18%3A55%3A07Z&amp;sp=r&#39;, &#39;logs/azureml/job_prep_azureml.log&#39;: &#39;https://vlkworkspace8006493384.blob.core.windows.net/azureml/ExperimentRun/dcid.70f76633-260a-4c25-967f-ea40e74b5983/logs/azureml/job_prep_azureml.log?sv=2019-02-02&amp;sr=b&amp;sig=6UtzdbSPTqXF%2FJLm%2FE27oqsZZNNUiwqPEr3G69S9jRU%3D&amp;st=2020-11-02T10%3A45%3A07Z&amp;se=2020-11-02T18%3A55%3A07Z&amp;sp=r&#39;, &#39;logs/azureml/job_release_azureml.log&#39;: &#39;https://vlkworkspace8006493384.blob.core.windows.net/azureml/ExperimentRun/dcid.70f76633-260a-4c25-967f-ea40e74b5983/logs/azureml/job_release_azureml.log?sv=2019-02-02&amp;sr=b&amp;sig=2ne8TBptqEpZt8ilyzyAfgySbMl26QQI6CFhUXN%2FQ2Q%3D&amp;st=2020-11-02T10%3A45%3A07Z&amp;se=2020-11-02T18%3A55%3A07Z&amp;sp=r&#39;, &#39;logs/azureml/stderrlogs.txt&#39;: &#39;https://vlkworkspace8006493384.blob.core.windows.net/azureml/ExperimentRun/dcid.70f76633-260a-4c25-967f-ea40e74b5983/logs/azureml/stderrlogs.txt?sv=2019-02-02&amp;sr=b&amp;sig=Ybt1gB%2B%2B4iK4gvrJ5%2BWi0EKtRe%2FfPLIFa9vZlOTtTiA%3D&amp;st=2020-11-02T10%3A45%3A07Z&amp;se=2020-11-02T18%3A55%3A07Z&amp;sp=r&#39;, &#39;logs/azureml/stdoutlogs.txt&#39;: &#39;https://vlkworkspace8006493384.blob.core.windows.net/azureml/ExperimentRun/dcid.70f76633-260a-4c25-967f-ea40e74b5983/logs/azureml/stdoutlogs.txt?sv=2019-02-02&amp;sr=b&amp;sig=TK2xOY9%2BtTFltaORb1x%2B4aqBn0c%2Fc5syFrczdTika4c%3D&amp;st=2020-11-02T10%3A45%3A07Z&amp;se=2020-11-02T18%3A55%3A07Z&amp;sp=r&#39;}}\n\n\n\nPipelineRun Execution Summary\n==============================\nPipelineRun Status: Finished\n{&#39;runId&#39;: &#39;3df13f5a-5048-484e-8a45-a40881189ca3&#39;, &#39;status&#39;: &#39;Completed&#39;, &#39;startTimeUtc&#39;: &#39;2020-11-02T10:35:15.92179Z&#39;, &#39;endTimeUtc&#39;: &#39;2020-11-02T10:55:22.148206Z&#39;, &#39;properties&#39;: {&#39;azureml.runsource&#39;: &#39;azureml.PipelineRun&#39;, &#39;runSource&#39;: &#39;SDK&#39;, &#39;runType&#39;: &#39;SDK&#39;, &#39;azureml.parameters&#39;: &#39;{}&#39;}, &#39;inputDatasets&#39;: [], &#39;logFiles&#39;: {&#39;logs/azureml/executionlogs.txt&#39;: &#39;https://vlkworkspace8006493384.blob.core.windows.net/azureml/ExperimentRun/dcid.3df13f5a-5048-484e-8a45-a40881189ca3/logs/azureml/executionlogs.txt?sv=2019-02-02&amp;sr=b&amp;sig=WzjpgUj4Xj5nbO0NxxcDSSps6jNYc6NOojfkqRvQtho%3D&amp;st=2020-11-02T10%3A45%3A23Z&amp;se=2020-11-02T18%3A55%3A23Z&amp;sp=r&#39;, &#39;logs/azureml/stderrlogs.txt&#39;: &#39;https://vlkworkspace8006493384.blob.core.windows.net/azureml/ExperimentRun/dcid.3df13f5a-5048-484e-8a45-a40881189ca3/logs/azureml/stderrlogs.txt?sv=2019-02-02&amp;sr=b&amp;sig=NqoHDdK%2FdRnR46lRd9iqdQzgLD%2BaiVwtfo%2Bzy6KKwaY%3D&amp;st=2020-11-02T10%3A45%3A23Z&amp;se=2020-11-02T18%3A55%3A23Z&amp;sp=r&#39;, &#39;logs/azureml/stdoutlogs.txt&#39;: &#39;https://vlkworkspace8006493384.blob.core.windows.net/azureml/ExperimentRun/dcid.3df13f5a-5048-484e-8a45-a40881189ca3/logs/azureml/stdoutlogs.txt?sv=2019-02-02&amp;sr=b&amp;sig=%2BbJpenx5MMhc74zH6jMg6YVP468sGVGorgxutlXxH%2FU%3D&amp;st=2020-11-02T10%3A45%3A23Z&amp;se=2020-11-02T18%3A55%3A23Z&amp;sp=r&#39;}}\n\nOut[57]: &#39;Finished&#39;</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Download and review output"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f674b624-2ab4-48c0-9a1d-901f46738f6d"}}},{"cell_type":"markdown","source":["Run the following code to download the output file created from the `batch_scoring.py` script, then explore the scoring results."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9400c8ba-70f3-4cee-86c0-44fa51419667"}}},{"cell_type":"code","source":["import pandas as pd\nimport tempfile\n\nbatch_run = pipeline_run.find_step_run(batch_score_step.name)[0]\nbatch_output = batch_run.get_output_data(output_dir.name)\n\ntarget_dir = tempfile.mkdtemp()\nbatch_output.download(local_path=target_dir)\nresult_file = os.path.join(target_dir, batch_output.path_on_datastore, parallel_run_config.append_row_file_name)\n\ndf = pd.read_csv(result_file, delimiter=\":\", header=None)\ndf.columns = [\"Filename\", \"Prediction\"]\nprint(\"Prediction has \", df.shape[0], \" rows\")\ndf.head(10) "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"92875a66-9615-4fe7-a233-d3a5568b7ad7"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Filename</th>\n      <th>Prediction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>n02691156_5992_airplane.jpg</td>\n      <td>rapeseed</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>n02764044_41120_axe.jpg</td>\n      <td>\"plane, carpenters plane, woodworking plane\"</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>n02766320_8764_baby_bed.jpg</td>\n      <td>crib, cot</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>n02769748_23541_backpack.jpg</td>\n      <td>backpack, back pack, knapsack, packsack, ruck...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>n02769748_3207_backpack.jpg</td>\n      <td>backpack, back pack, knapsack, packsack, ruck...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>n02799071_5092_baseball.jpg</td>\n      <td>baseball</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>n02802426_5133_basketball.jpg</td>\n      <td>basketball</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>n02815834_4632_beaker.jpg</td>\n      <td>beaker</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>n02828884_8228_bench.jpg</td>\n      <td>park bench</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>n02834778_5255_bicycle.jpg</td>\n      <td>mountain bike, all-terrain bike, off-roader</td>\n    </tr>\n  </tbody>\n</table>\n</div>","textData":"<div class=\"ansiout\">Prediction has  110  rows\nOut[58]: </div>","removedWidgets":[],"addedWidgets":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Filename</th>\n      <th>Prediction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>n02691156_5992_airplane.jpg</td>\n      <td>rapeseed</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>n02764044_41120_axe.jpg</td>\n      <td>\"plane, carpenters plane, woodworking plane\"</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>n02766320_8764_baby_bed.jpg</td>\n      <td>crib, cot</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>n02769748_23541_backpack.jpg</td>\n      <td>backpack, back pack, knapsack, packsack, ruck...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>n02769748_3207_backpack.jpg</td>\n      <td>backpack, back pack, knapsack, packsack, ruck...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>n02799071_5092_baseball.jpg</td>\n      <td>baseball</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>n02802426_5133_basketball.jpg</td>\n      <td>basketball</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>n02815834_4632_beaker.jpg</td>\n      <td>beaker</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>n02828884_8228_bench.jpg</td>\n      <td>park bench</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>n02834778_5255_bicycle.jpg</td>\n      <td>mountain bike, all-terrain bike, off-roader</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Publish and run from REST endpoint"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"72e10fd4-c175-4bb8-bca2-590efd911a60"}}},{"cell_type":"markdown","source":["Run the following code to publish the pipeline to your workspace. In your workspace in the portal, you can see metadata for the pipeline including run history and durations. You can also run the pipeline manually from the portal.\n\nAdditionally, publishing the pipeline enables a REST endpoint to rerun the pipeline from any HTTP library on any platform."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1bd5f6f3-e373-43ec-978f-10a8ac4084dc"}}},{"cell_type":"code","source":["published_pipeline = pipeline_run.publish_pipeline(\n    name=\"Inception_v3_scoring\", description=\"Batch scoring using Inception v3 model\", version=\"1.0\")\n\npublished_pipeline"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6c3cd358-9251-4e67-ab19-22500f814d03"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<table style=\"width:100%\"><tr><th>Name</th><th>Id</th><th>Status</th><th>Endpoint</th></tr><tr><td>Inception_v3_scoring</td><td><a href=\"https://ml.azure.com/pipelines/a7a79c4c-6056-4a29-8720-6dd86969271c?wsid=/subscriptions/d30d76c0-804c-4f4e-ab7b-509d06a49550/resourcegroups/vlk-workshop/workspaces/vlk-workspace\" target=\"_blank\" rel=\"noopener\">a7a79c4c-6056-4a29-8720-6dd86969271c</a></td><td>Active</td><td><a href=\"https://westeurope.api.azureml.ms/pipelines/v1.0/subscriptions/d30d76c0-804c-4f4e-ab7b-509d06a49550/resourceGroups/vlk-workshop/providers/Microsoft.MachineLearningServices/workspaces/vlk-workspace/PipelineRuns/PipelineSubmit/a7a79c4c-6056-4a29-8720-6dd86969271c\" target=\"_blank\" rel=\"noopener\">REST Endpoint</a></td></tr></table>","textData":"<div class=\"ansiout\">Out[59]: </div>","removedWidgets":[],"addedWidgets":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<table style=\"width:100%\"><tr><th>Name</th><th>Id</th><th>Status</th><th>Endpoint</th></tr><tr><td>Inception_v3_scoring</td><td><a href=\"https://ml.azure.com/pipelines/a7a79c4c-6056-4a29-8720-6dd86969271c?wsid=/subscriptions/d30d76c0-804c-4f4e-ab7b-509d06a49550/resourcegroups/vlk-workshop/workspaces/vlk-workspace\" target=\"_blank\" rel=\"noopener\">a7a79c4c-6056-4a29-8720-6dd86969271c</a></td><td>Active</td><td><a href=\"https://westeurope.api.azureml.ms/pipelines/v1.0/subscriptions/d30d76c0-804c-4f4e-ab7b-509d06a49550/resourceGroups/vlk-workshop/providers/Microsoft.MachineLearningServices/workspaces/vlk-workspace/PipelineRuns/PipelineSubmit/a7a79c4c-6056-4a29-8720-6dd86969271c\" target=\"_blank\" rel=\"noopener\">REST Endpoint</a></td></tr></table>"]}}],"execution_count":0},{"cell_type":"markdown","source":["To run the pipeline from the REST endpoint, you first need an OAuth2 Bearer-type authentication header. This example uses interactive authentication for illustration purposes, but for most production scenarios requiring automated or headless authentication, use service principle authentication as [described in this notebook](https://aka.ms/pl-restep-auth).\n\nService principle authentication involves creating an **App Registration** in **Azure Active Directory**, generating a client secret, and then granting your service principal **role access** to your machine learning workspace. You then use the [`ServicePrincipalAuthentication`](https://docs.microsoft.com/python/api/azureml-core/azureml.core.authentication.serviceprincipalauthentication?view=azure-ml-py) class to manage your auth flow. \n\nBoth `InteractiveLoginAuthentication` and `ServicePrincipalAuthentication` inherit from `AbstractAuthentication`, and in both cases you use the `get_authentication_header()` function in the same way to fetch the header."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d6fb0874-2880-4999-9aa8-ef53ef35bbe2"}}},{"cell_type":"code","source":["from azureml.core.authentication import InteractiveLoginAuthentication\n\ninteractive_auth = InteractiveLoginAuthentication()\nauth_header = interactive_auth.get_authentication_header()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"dac499cd-d8ce-4a9b-b021-5f06fc79bb6a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Get the REST url from the `endpoint` property of the published pipeline object. You can also find the REST url in your workspace in the portal. Build an HTTP POST request to the endpoint, specifying your authentication header. Additionally, add a JSON payload object with the experiment name and the batch size parameter. As a reminder, the `process_count_per_node` is passed through to `ParallelRunStep` because you defined it is defined as a `PipelineParameter` object in the step configuration.\n\nMake the request to trigger the run. Access the `Id` key from the response dict to get the value of the run id."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"22e2041c-d0ca-4ae7-8021-bfe7369b2cbe"}}},{"cell_type":"code","source":["import requests\n\nrest_endpoint = published_pipeline.endpoint\nresponse = requests.post(rest_endpoint, \n                         headers=auth_header, \n                         json={\"ExperimentName\": \"batch_scoring\",\n                               \"ParameterAssignments\": {\"process_count_per_node\": 6}})"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e4fe94f5-58bc-4c28-a77b-13f9f317a74f"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["try:\n    response.raise_for_status()\nexcept Exception:    \n    raise Exception(\"Received bad response from the endpoint: {}\\n\"\n                    \"Response Code: {}\\n\"\n                    \"Headers: {}\\n\"\n                    \"Content: {}\".format(rest_endpoint, response.status_code, response.headers, response.content))\n\nrun_id = response.json().get('Id')\nprint('Submitted pipeline run: ', run_id)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7ec4be89-c0cc-41ce-90d9-b604225132fc"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Submitted pipeline run:  a4390ca7-14c1-4d83-a940-2a63e6c5597c\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Submitted pipeline run:  a4390ca7-14c1-4d83-a940-2a63e6c5597c\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Use the run id to monitor the status of the new run. This will take another 10-15 min to run and will look similar to the previous pipeline run, so if you don't need to see another pipeline run, you can skip watching the full output."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b57da3d5-2bfe-4e49-bc17-a34807947d64"}}},{"cell_type":"code","source":["from azureml.pipeline.core.run import PipelineRun\n\npublished_pipeline_run = PipelineRun(ws.experiments[\"batch_scoring\"], run_id)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7676cf23-e4c1-48fa-a167-337e43c23750"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Show detail information of the run\npublished_pipeline_run"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"22bcef4c-7865-42c6-aa22-e84422118351"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>batch_scoring</td><td>a4390ca7-14c1-4d83-a940-2a63e6c5597c</td><td>azureml.PipelineRun</td><td>Running</td><td><a href=\"https://ml.azure.com/experiments/batch_scoring/runs/a4390ca7-14c1-4d83-a940-2a63e6c5597c?wsid=/subscriptions/d30d76c0-804c-4f4e-ab7b-509d06a49550/resourcegroups/vlk-workshop/workspaces/vlk-workspace\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>","textData":"<div class=\"ansiout\">Out[67]: </div>","removedWidgets":[],"addedWidgets":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>batch_scoring</td><td>a4390ca7-14c1-4d83-a940-2a63e6c5597c</td><td>azureml.PipelineRun</td><td>Running</td><td><a href=\"https://ml.azure.com/experiments/batch_scoring/runs/a4390ca7-14c1-4d83-a940-2a63e6c5597c?wsid=/subscriptions/d30d76c0-804c-4f4e-ab7b-509d06a49550/resourcegroups/vlk-workshop/workspaces/vlk-workspace\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Clean up resources\n\nDo not complete this section if you plan on running other Azure Machine Learning service tutorials.\n\n### Stop the notebook VM\n\nIf you used a cloud notebook server, stop the VM when you are not using it to reduce cost.\n\n1. In your workspace, select **Compute**.\n1. Select the **Notebook VMs** tab in the compute page.\n1. From the list, select the VM.\n1. Select **Stop**.\n1. When you're ready to use the server again, select **Start**.\n\n### Delete everything\n\nIf you don't plan to use the resources you created, delete them, so you don't incur any charges.\n\n1. In the Azure portal, select **Resource groups** on the far left.\n1. From the list, select the resource group you created.\n1. Select **Delete resource group**.\n1. Enter the resource group name. Then select **Delete**.\n\nYou can also keep the resource group but delete a single workspace. Display the workspace properties and select **Delete**."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"217bb426-99ed-49a9-9553-5e0531e69f1f"}}},{"cell_type":"markdown","source":["## Next steps\n\nIn this machine learning pipelines tutorial, you did the following tasks:\n\n> * Built a pipeline with environment dependencies to run on a remote GPU compute resource\n> * Created a scoring script to run batch predictions with a pre-trained Tensorflow model\n> * Published a pipeline and enabled it to be run from a REST endpoint\n\nSee the [how-to](https://docs.microsoft.com/azure/machine-learning/service/how-to-create-your-first-pipeline?view=azure-devops) for additional detail on building pipelines with the machine learning SDK."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b7a006e2-bd29-419f-88f8-aab93c3d71b2"}}},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"af74970c-f452-4be8-9c79-c7a7645c1496"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[29]: [FileInfo(path=&#39;dbfs:/FileStore/import-stage/&#39;, name=&#39;import-stage/&#39;, size=0)]</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[29]: [FileInfo(path=&#39;dbfs:/FileStore/import-stage/&#39;, name=&#39;import-stage/&#39;, size=0)]</div>"]}}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bf184d0e-7ef0-4642-858b-19db779b548a"}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"tutorial-pipeline-batch-scoring-classification","dashboards":[],"language":"python","widgets":{},"notebookOrigID":3981079154799652}},"nbformat":4,"nbformat_minor":0}
